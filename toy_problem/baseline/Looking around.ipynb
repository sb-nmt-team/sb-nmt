{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "use_cuda = True\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_utils import pad_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "BOS_TOKEN = 1\n",
    "NAN_TOKEN = 2\n",
    "EOS_TOKEN = 3\n",
    "SPECIAL_TOKENS = 4\n",
    "OCCURING_SPECIAL_TOKENS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class DatasetFilesLocation:\n",
    "#     def __init__(self, train, dev, test, tokens):\n",
    "#         self.train = train\n",
    "#         self.dev = dev\n",
    "#         self.test = test\n",
    "#         self.tokens = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# src_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/src.train.txt',\n",
    "#     dev='../preprocessed/he-en/src.dev.txt',\n",
    "#     test='../preprocessed/he-en/src.test.txt',\n",
    "#     tokens='../preprocessed/he-en/src.tokens.txt')\n",
    "\n",
    "# trg_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/tgt.train.txt',\n",
    "#     dev='../preprocessed/he-en/tgt.dev.txt',\n",
    "#     test='../preprocessed/he-en/tgt.test.txt',\n",
    "#     tokens='../preprocessed/he-en/tgt.tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, tokens_file_path):\n",
    "        self.idx2word = defaultdict(lambda: \"<NAN/>\")\n",
    "        self.word2idx = defaultdict(lambda: NAN_TOKEN)\n",
    "        with open(tokens_file_path) as tokens_file:\n",
    "            tokens = tokens_file.readlines()\n",
    "            for word, idx in map(lambda x: x.strip().split(), tokens):\n",
    "                idx = int(idx) + SPECIAL_TOKENS\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "            assert PAD_TOKEN not in self.idx2word\n",
    "            assert BOS_TOKEN not in self.idx2word\n",
    "            assert EOS_TOKEN not in self.idx2word\n",
    "            for word, idx in [('<PAD/>', PAD_TOKEN), ('<S>', BOS_TOKEN),\n",
    "                              ('</S>', EOS_TOKEN), ('<NAN/>', NAN_TOKEN)]:\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "    \n",
    "    def convert(self, sentence):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.strip().split()\n",
    "        return [BOS_TOKEN] + list(map(lambda word: self.word2idx[word], sentence)) + [EOS_TOKEN]\n",
    "    \n",
    "    def convert_batch(self, sents):\n",
    "        \n",
    "        batch_max_length = 0\n",
    "        for sent in sents:\n",
    "            batch_max_length = max(batch_max_length, len(sent))\n",
    "            \n",
    "#         print(batch_max_length)\n",
    "        \n",
    "        result = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        mask = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        \n",
    "        for sent_id, sent in enumerate(sents):\n",
    "            sent = sent[:batch_max_length]\n",
    "            current = self.convert(sent)\n",
    "            result[sent_id, :len(current)] = current\n",
    "            mask[sent_id, :len(current)] = 1.0\n",
    "            \n",
    "        return result, mask\n",
    "    \n",
    "    def input_size(self):\n",
    "        return len(self.idx2word.keys())\n",
    "    \n",
    "    def output_size(self):\n",
    "        return len(self.idx2word.keys())# - SPECIAL_TOKENS + OCCURING_SPECIAL_TOKENS\n",
    "    \n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]# + SPECIAL_TOKENS - OCCURING_SPECIAL_TOKENS]\n",
    "    \n",
    "    def get_eos(self):\n",
    "        return EOS_TOKEN #OCCURING_SPECIAL_TOKENS - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as file:\n",
    "        return list(map(lambda s: s.strip().split(\" \"), file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_problem(path, n_sents=None):\n",
    "    modes = [\"train\",  \"dev\", \"test\"]\n",
    "    datasets = [\"src\", \"tgt\"]\n",
    "    file_template = \"{}.{}.txt\"\n",
    "    \n",
    "    result = {}\n",
    "    for mode in modes:\n",
    "        src = read_file(os.path.join(path, file_template.format(\"src\", mode)))\n",
    "        tgt = read_file(os.path.join(path, file_template.format(\"tgt\", mode)))\n",
    "        \n",
    "        assert len(src) == len(tgt)\n",
    "        \n",
    "#         result[mode] = list(zip(src, tgt))\n",
    "        if n_sents is not None:\n",
    "            result[mode] = (src[:n_sents], tgt[:n_sents])\n",
    "        else:\n",
    "            result[mode] = (src, tgt)\n",
    "        \n",
    "    src_lang = Lang(os.path.join(path, file_template.format(\"src\", \"tokens\")))\n",
    "    tgt_lang = Lang(os.path.join(path, file_template.format(\"tgt\", \"tokens\")))\n",
    "    return result, src_lang, tgt_lang\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d, src, tgt = read_problem(\"../preprocessed/he-en/\", n_sents=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183050"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183050"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = self.train[0][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "y = self.train[1][self.train_indices[self.position:self.position + self.batch_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['l', 'm', 'l', 'y', 'h', 'w', 'n_'],\n",
       " ['l', 'm', 'i', 'l', 'e', 'h', 'o', 'n'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[23], y[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class BatchSampler:\n",
    "    def __init__(self, dataset, src_lang, tgt_lang, batch_size):\n",
    "        self.train = np.array(dataset[\"train\"])\n",
    "        self.dev = np.array(dataset[\"dev\"])\n",
    "        self.test = np.array(dataset[\"test\"])\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        self.train_indices = np.random.permutation(np.arange(len(self.train[0]), dtype=np.int32))\n",
    "        \n",
    "        \n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train)//self.batch_size + 1\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.position = 0\n",
    "        return self\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = 0\n",
    "        \n",
    "    \n",
    "    def get_batch(self, x, y):\n",
    "        x, x_mask = self.src_lang.convert_batch(x)\n",
    "        y, y_mask = self.tgt_lang.convert_batch(y)\n",
    "        \n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        y = Variable(torch.from_numpy(y.astype(np.int64))).contiguous()\n",
    "        y_mask = Variable(torch.from_numpy(y_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        return (x, x_mask), (y, y_mask)\n",
    "    \n",
    "        \n",
    "    def __next__(self):\n",
    "            if self.position >= len(self.train[0]):\n",
    "                raise StopIteration()\n",
    "                \n",
    "            x = self.train[0][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "            y = self.train[1][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "            \n",
    "            self.position += self.batch_size\n",
    "            return self.get_batch(x, y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def form_batch_variable(lang, sentences):\n",
    "#     sentences = list(map(lang.convert, sentences))\n",
    "#     sentences = sorted(sentences, key=len, reverse=True)\n",
    "#     lengths = list(map(len, sentences))\n",
    "#     sentences = list(map(lambda sentence: Variable(torch.LongTensor(sentence)), sentences))\n",
    "#     batch = pad_sequence(sentences, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#     if use_cuda:\n",
    "#         batch = batch.cuda()\n",
    "#     return torch.nn.utils.rnn.pack_padded_sequence(batch, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.max_length = 100\n",
    "        self.enc_hidden_size = 128\n",
    "        self.enc_emb_size = 128\n",
    "        self.enc_layers = 1\n",
    "        self.enc_dropout = 0.1\n",
    "        self.enc_bidirectional = True\n",
    "        \n",
    "        self.dec_hidden_size = 128\n",
    "        self.dec_emb_size = self.enc_emb_size\n",
    "        self.dec_layers = 1\n",
    "        self.dec_dropout = 0.1\n",
    "        self.dec_bidirectional = True\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.learning_rate = 0.001\n",
    "        self.clip = 0.25\n",
    "     \n",
    "    def get_enc_output_size(self):\n",
    "        return self.enc_hidden_size * (int(self.enc_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_output_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_state_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1) * self.dec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,\n",
    "                                      embedding_dim=hp.enc_emb_size,\n",
    "                                      padding_idx=PAD_TOKEN)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=hp.enc_emb_size,\n",
    "                          hidden_size=hp.enc_hidden_size,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.enc_dropout,\n",
    "                          num_layers=hp.enc_layers,\n",
    "                          bidirectional=hp.enc_bidirectional)\n",
    "        self.num_directions = (int(hp.enc_bidirectional) + 1)\n",
    "        self.num_layers = hp.enc_layers\n",
    "        self.hidden_size = hp.enc_hidden_size\n",
    "\n",
    "    def forward(self, input_batch, hidden=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        if (hidden is None):\n",
    "            hidden = self.init_hidden(input_batch.size(0))\n",
    "        embedded = self.embedding(input_batch).contiguous()\n",
    "#         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, _ = self.gru(embedded, hidden)\n",
    "#         outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             outputs, padding_value=PAD_TOKEN, batch_first=True)\n",
    "#         print(outputs.size())\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mask(lengths):\n",
    "#     batch_size = lengths.size(0)\n",
    "#     max_len = lengths[0]\n",
    "#     time = torch.arange(max_len).repeat(batch_size, 1)\n",
    "#     lengths = lengths.view(-1, 1).type(torch.FloatTensor)\n",
    "#     if (use_cuda):\n",
    "#         time = time.cuda()\n",
    "#         lengths = lengths.cuda()\n",
    "\n",
    "#     mask = Variable((time < lengths).type(torch.FloatTensor))\n",
    "#     if (use_cuda):\n",
    "#         return mask.cuda()\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hp.get_enc_output_size() + hp.get_dec_state_size(), 1)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers * directions, B, HD)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (B, T, HE)\n",
    "        :param encoder_output_lengths:\n",
    "            lengths of encoded sentences, in shape (B,)\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        max_len = encoder_outputs.size(1)\n",
    "\n",
    "        hidden = hidden.transpose(0, 1).contiguous() # [B, l * d, HD]\n",
    "        hidden = hidden.view(batch_size, -1) # [B, HD * layers * directions]\n",
    "        hidden = hidden.repeat(max_len, 1, 1).transpose(0, 1) # [B, T, HD * layers * directions]\n",
    "        \n",
    "        energies = self.attn(torch.cat((hidden, encoder_outputs), -1)).view(batch_size, max_len) # [B, T, 1]\n",
    "\n",
    "        \n",
    "        energies = energies * mask\n",
    "        energies = F.softmax(energies)\n",
    "        energies = energies * mask\n",
    "        energies = energies / energies.sum(1).view(-1, 1) # [B, T]\n",
    "        \n",
    "        return (energies.view(batch_size, max_len, 1) * encoder_outputs).sum(1) #[B, HE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hp):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hp.dec_emb_size, padding_idx=PAD_TOKEN)\n",
    "        self.attn = Attn(hp)\n",
    "        self.gru = nn.GRU(input_size=hp.dec_emb_size + hp.get_enc_output_size(),\n",
    "                          hidden_size=hp.dec_hidden_size,\n",
    "                          num_layers=hp.dec_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.dec_dropout,\n",
    "                          bidirectional=hp.dec_bidirectional)\n",
    "        self.out = nn.Linear(hp.get_dec_output_size(), output_size)\n",
    "\n",
    "        self.num_layers = hp.dec_layers\n",
    "        self.num_directions = int(hp.dec_bidirectional) + 1\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hp.dec_hidden_size\n",
    "\n",
    "\n",
    "    def forward(self, input, encoder_outputs, mask, hidden=None):\n",
    "        \"\"\"\n",
    "            input: [B,]\n",
    "            encoder_outputs: [B, T, HE]\n",
    "            hidden: [B, layers * directions, HD]\n",
    "        \"\"\"\n",
    "        batch_size = input.size(0)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "#         embedded = self.embedding(input.view(-1, 1))\n",
    "        embedded = self.embedding(input)\n",
    "#         print(embedded.size())\n",
    "        context = self.attn(hidden, encoder_outputs, mask).view(batch_size, -1)\n",
    "#         print(context.size())\n",
    "        rnn_input = torch.cat((embedded, context), -1).view(batch_size, 1, -1)\n",
    "        \n",
    "#         print(\"RNN input\", rnn_input.size())\n",
    "        output, next_hidden = self.gru(rnn_input, hidden)\n",
    "        output = self.out(output).view(batch_size, self.output_size)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        \n",
    "        return output, next_hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, source_lang, target_lang, hp):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.encoder = EncoderRNN(source_lang.input_size(), hp)\n",
    "        self.decoder = DecoderRNN(target_lang.input_size(), target_lang.input_size(), hp)\n",
    "        self.max_length = hp.max_length\n",
    "        self.criterion = nn.NLLLoss(reduce=False, size_average=False)\n",
    "        \n",
    "#     def translate(self, input_seq):\n",
    "\n",
    "# #         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "# #             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "# #         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "# #         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "# #         mask = get_mask(encoder_output_lengths)\n",
    "        \n",
    "# #         batch_size = input_batch.size(0)\n",
    "        \n",
    "#         dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "#         if use_cuda:\n",
    "#             dec_input = dec_input.cuda()\n",
    "# #         max_length = min(self.max_length, 2 * encoder_output_lengths[0])\n",
    "#         hidden = None\n",
    "#         translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "#         for i in range(max_length):\n",
    "#             output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "#             _, output_idx = torch.max(output, -1)\n",
    "#             for j in range(batch_size):\n",
    "#                 if translations[j][-1] != target_lang.get_eos():\n",
    "#                     translations[j].append(output_idx[j].data[0])\n",
    "#             dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "#             if use_cuda:\n",
    "#                 dec_input = dec_input.cuda()\n",
    "#         return [' '.join(map(target_lang.get_word, elem)) for elem in translations]\n",
    "\n",
    "    def translate(self, input_batch, mask):\n",
    "        batch_size = input_batch.size()[0]\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "        word_indices = []\n",
    "#         outputs = []\n",
    "        \n",
    "        dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "        \n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        MAX_LENGTH = 100\n",
    "        translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "        converged = np.zeros(shape=(batch_size, ))\n",
    "        for i in range(MAX_LENGTH):     \n",
    "            output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "            _, output_idx = torch.max(output, -1)\n",
    "                \n",
    "            for j in range(batch_size):\n",
    "                if translations[j][-1] != self.target_lang.get_eos():\n",
    "                    translations[j].append(output_idx[j].data[0])\n",
    "                else:\n",
    "                    converged[j] = True\n",
    "            dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "            \n",
    "            if use_cuda:\n",
    "                dec_input = dec_input.cuda()\n",
    "            \n",
    "            \n",
    "            if np.all(converged):\n",
    "                break\n",
    "            \n",
    "         \n",
    "            \n",
    "#         return translations\n",
    "        return [' '.join(map(self.target_lang.get_word, elem)) for elem in translations]\n",
    "    \n",
    "    def forward(self, input_batch, mask, output_batch, out_mask):\n",
    "#         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "#         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "#         mask = get_mask(encoder_output_lengths)\n",
    "#         batch_size = input_batch.size(0)\n",
    "\n",
    "        \n",
    "#         if use_cuda:\n",
    "#             dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "#         output_batch, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(output_seq,\n",
    "#                                                                               batch_first=True,\n",
    "#                                                                               padding_value=PAD_TOKEN)\n",
    "#         output_lengths = torch.LongTensor(output_lengths)\n",
    "#         out_mask = get_mask(output_lengths)\n",
    "        loss = 0\n",
    "        outputs = []\n",
    "        for i in range(out_mask.size()[1] - 1):\n",
    "           \n",
    "            output, hidden = self.decoder(output_batch[:, i], encoder_outputs, mask=mask, hidden=hidden)\n",
    "            loss += (self.criterion(output, output_batch[:, i + 1]) * out_mask[:, i + 1]).sum()\n",
    "        \n",
    "        loss /= out_mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import gc\n",
    "def trainS2S(s2s, batch_sampler, hp):\n",
    "    s2s.train()\n",
    "#     losses = []\n",
    "#     hp.batch_size = 100\n",
    "#     assert(len(src) == len(trg))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(s2s.parameters(), lr=hp.learning_rate)\n",
    "    \n",
    "    for epoch_id in range(hp.n_epochs):\n",
    "#         batch_sampler.reset()\n",
    "        for batch_id, ((input, input_mask), (output, output_mask)) in tqdm.tqdm(enumerate(batch_sampler)):\n",
    "#         for i in tqdm.tqdm(range(0, len(src), hp.batch_size)):\n",
    "#             src_batch = form_batch_variable(source_lang, src[i : i + hp.batch_size])\n",
    "#             trg_batch = form_batch_variable(target_lang, trg[i : i + hp.batch_size])\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                input_mask = input_mask.cuda()\n",
    "                output = output.cuda()\n",
    "                output_mask = output_mask.cuda()\n",
    "\n",
    "\n",
    "            loss = s2s(input, input_mask, output, output_mask)\n",
    "#             if (batch_id // hp.batch_size) % 100 == 0:\n",
    "#                 print(loss.data[0])\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(s2s.parameters(), hp.clip)\n",
    "            optimizer.step()\n",
    "            if use_cuda:\n",
    "                losses.append(loss.cpu().data[0])\n",
    "            else:\n",
    "                 losses.append(loss.data[0])\n",
    "            \n",
    "            if (batch_id * batch_sampler.batch_size) % 1000 == 0:\n",
    "                display.clear_output(wait=True)\n",
    "                print(\"Last 10 loses mean\", np.mean(losses[-10:]))\n",
    "                plt.plot(losses)\n",
    "                plt.show()\n",
    "        \n",
    "        torch.save(s2s.state_dict(), \"last_state.ckpt\")\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_dataset = {\n",
    "    \"train\": ( [\"'a 'a d y r\", \"'a 'a h b ckh\"], [\"a a d i r\", \"e a h a v k h a\"]),\n",
    "    \"test\":None,\n",
    "    \"dev\":None\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(dummy_dataset, src, tgt, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 10 loses mean 0.46150257587432864\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f02c0b6c9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.88it/s]\n"
     ]
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.batch_size = 100\n",
    "hp.n_epochs = 20\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "if use_cuda:\n",
    "    s2s = s2s.cuda()\n",
    "losses = []\n",
    "losses = trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 128, padding_idx=0)\n",
       "    (gru): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 128, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(384, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch_sampler.train[batch_sampler.train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(d, src, tgt, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp = HyperParameters()\n",
    "hp.n_epochs = 5\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "if use_cuda:\n",
    "    s2s = s2s.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 10 loses mean 0.3808202654123306\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba28011898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1831it [05:13,  5.83it/s]\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "losses = trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s2s.load_state_dict(torch.load(\"last_state.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(s2s.state_dict(), \"last_state.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fba28011240>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba22dae2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 128, padding_idx=0)\n",
       "    (gru): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 128, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(384, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_translation(x, x_mask):\n",
    "    if not use_cuda:\n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "    else:\n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous().cuda()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous().cuda()\n",
    "    \n",
    "    \n",
    "    return x, x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> a a d i r </S>', '<S> a a h a v a k h </S>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> t i s m a m r h </S>', '<S> a a h a v a k h </S>']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"t sh m m r h\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     1     6     6    17    88    49     3\n",
       "     1     6     6    24    14    15     3\n",
       " [torch.cuda.LongTensor of size 2x7 (GPU 0)], Variable containing:\n",
       "     1     1     1     1     1     1     1\n",
       "     1     1     1     1     1     1     1\n",
       " [torch.cuda.FloatTensor of size 2x7 (GPU 0)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'e'],\n",
       " ['a', 'k', 'h'],\n",
       " ['i', 'k', 'e'],\n",
       " ['a', 'k', 'e', 'z'],\n",
       " ['a', 'e', 'o', 'i', 'e', 'e', 'a', 'a', 'o', 'a', 'a', 'h', 'o', 'a', 'h'],\n",
       " ['e', 'e', 'e', 'e', 'e'],\n",
       " ['a', 'a', 'a', 'm', 'a', 'r'],\n",
       " ['a', 'a', 'b', 'i', 'l'],\n",
       " ['a', 'a', 'k', 'e', 'n'],\n",
       " ['a', 'a', 'k', 'e', 'n'],\n",
       " ['e', 'a', 'd', 'm'],\n",
       " ['a', 'e', 'g', 'v'],\n",
       " ['a', 'e', 'g', 'y', 'n'],\n",
       " ['e', 'e', 'h', 'a', 'v'],\n",
       " ['a', 'a', 'k', 'e', 'l'],\n",
       " ['a', 'l', 'a', 'f'],\n",
       " ['e',\n",
       "  'e',\n",
       "  'l',\n",
       "  'e',\n",
       "  'l',\n",
       "  'e',\n",
       "  'a',\n",
       "  'h',\n",
       "  'e',\n",
       "  'y',\n",
       "  'e',\n",
       "  'y',\n",
       "  'e',\n",
       "  'm',\n",
       "  'a',\n",
       "  'm',\n",
       "  'h'],\n",
       " ['e', 'a', 'l', 'k'],\n",
       " ['a', 'e', 'l', 'y', 't'],\n",
       " ['a', 'i', 'm', 'a', 'm'],\n",
       " ['a', 'u', 'm', 'a', 'n', 'i', 'm'],\n",
       " ['a', 'a', 'm', 'a', 't', 'e', 'h'],\n",
       " ['a', 'a', 'm', 'i', 't', 's', 'c', 'h', 'e', 'm'],\n",
       " ['a', 'a', 'm', 'i', 'n', 'a'],\n",
       " ['a', 'm', 'i', 'c', 'h', 'e'],\n",
       " ['e', 'a', 'n'],\n",
       " ['a', 'i', 'n', 's', 'h', 'e'],\n",
       " ['e', 'e', 'f', 'e'],\n",
       " ['a', 'a', 'r', 'a'],\n",
       " ['a', 'a', 'r', 'd', 'm', 'n'],\n",
       " ['e', 'e', 'r', 'e'],\n",
       " ['a', 'e', 'r', 'm', 'a', 'k', 'i'],\n",
       " ['e', 'a', 'r', 'e', 'n', 'd', 'i', 'l'],\n",
       " ['a', 'e', 'r', 'o', 'g', 'a', 'u', 'v', 'y', 'o', 't', 'a'],\n",
       " ['a', 'e', 'r', 'o', 'l', 'y', 'n', 'e', 'a', 's'],\n",
       " ['a', 'a', 'r', 'o', 'n', 'o', 't', 'i', 'k', 'a'],\n",
       " ['a', 'e', 'r', 'o', 's', 't', 'a', 't'],\n",
       " ['a', 'a', 'r', 'i', 'k', 'h'],\n",
       " ['e', 'e', 'r', 'o', 'z'],\n",
       " ['a', 'a', 'r', 'z', 'a'],\n",
       " ['e', 'e', 's', 'o', 'f'],\n",
       " ['e', 'a', 's', 'e', 'r'],\n",
       " ['e', 'e', 's', 'u', 'r'],\n",
       " ['a', 'a', 's', 'i', 't', 'a'],\n",
       " ['a', 'a', 's', 'h', 'i', 'r', 'a'],\n",
       " ['a', 'e', 't', 'e', 's'],\n",
       " ['a', 'a', 'c', 'h', 'i'],\n",
       " ['a', 'u', 'e', 'r'],\n",
       " ['a', 'u', 'e', 'r', 'b', 'a', 'k', 'h'],\n",
       " ['e', 'u', 'e', 'r', 'g', 'e', 't', 'e', 's'],\n",
       " ['e', 'u', 'b', 'o', 'y', 'a'],\n",
       " ['e', 'u', 'd', 'o', 'k', 'i'],\n",
       " ['a', 'u', 'd', 'i'],\n",
       " ['e', 'u', 'j', 'e', 'n', 'y', 'o'],\n",
       " ['a', 'u', 'g', 'm', 'e', 'n', 't', 'i', 'n'],\n",
       " ['e', 'u', 'g', 'e', 'n', 'i', 'k', 'h'],\n",
       " ['a', 'u', 'g', 'r', 'a', 'y', 'h', 'u'],\n",
       " ['a', 'u', 'g', 'u', 's', 't', 'o'],\n",
       " ['a', 'u', 'g', 'u', 's', 'h', 't', 'a'],\n",
       " ['e', 'u', 'k', 'h', 'e', 'n', 'y', 'o'],\n",
       " ['e', 'u', 'l', 'a', 'r', 'i', 'h'],\n",
       " ['a', 'u', 'l', 'a', 'l', 'v'],\n",
       " ['e', 'o', 'l', 'y', 'i', 'm'],\n",
       " ['e', 'u', 'm', 'o', 'l', 'p', 'o', 's'],\n",
       " ['e', 'u', 'n', 'e', 'm', 'i'],\n",
       " ['e', 'o', 'n', 'o', 's'],\n",
       " ['a', 'u', 'f', 'b', 'a', 'u'],\n",
       " ['a', 'u', 'p', 'e', 'n'],\n",
       " ['a', 'o', 'f', 't', 'a', 'a'],\n",
       " ['e', 'u', 'p', 'o', 'l', 'i', 's'],\n",
       " ['a', 'u', 'f', 'u', 'i', 'v', 'y', 'd', 'r', 'a', 'o', 't'],\n",
       " ['e', 'o', 'k'],\n",
       " ['a', 'u', 'k', 't', 'o', 'r'],\n",
       " ['a', 'o', 'k', 'i'],\n",
       " ['a', 'u', 'r', 'e', 'l'],\n",
       " ['e', 'u', 'r', 'e', 'k', 'a', 'z'],\n",
       " ['a', 'o', 'r', 't', 'a'],\n",
       " ['a', 'u', 'r', 'o', 'b', 'i', 'n', 'd', 'o'],\n",
       " ['e', 'u', 'r', 'i', 'd', 'i', 'c', 'h', 'e'],\n",
       " ['e', 'u', 'r', 'i', 'k', 'a'],\n",
       " ['a', 'u', 'r', 'i', 'k', 'u', 'l', 'a', 'r', 'i', 'u', 's'],\n",
       " ['a', 'u', 'r', 'i', 's'],\n",
       " ['a', 'o', 's', 't', 'a'],\n",
       " ['a', 'u', 's', 't', 's', 'u', 'g'],\n",
       " ['a', 'u', 's', 't', 's', 'i', 'e', 'n'],\n",
       " ['a', 'u', 's', 'y', 'a'],\n",
       " ['e', 'o', 't'],\n",
       " ['a', 'u', 't', 'e', 'a', 'r', 'o'],\n",
       " ['a', 'u', 't', 's', 'o', 'r', 's', 'i', 'n', 'g'],\n",
       " ['a', 'a', 'v', 'u', 'a'],\n",
       " ['a', 'u', 'v', 'e', 'r', 'b', 'a', 'k', 'h'],\n",
       " ['e', 'u', 'z', 'e', 'b', 'y', 'o'],\n",
       " ['a', 'o', 'z', 'o', 'r', 'h'],\n",
       " ['a', 'u', 'z', 'i', 'a', 's'],\n",
       " ['a', 'i', 'i'],\n",
       " ['a', 'e', 'i', 'v', 'a', 'r'],\n",
       " ['a', 'i', 'g', 'r', 'a'],\n",
       " ['a', 'i', 'n', 's', 'h', 'e'],\n",
       " ['a', 'i', 's', 'd', 'a', 'n'],\n",
       " ['a', 'a', 'z', 'a', 'e', 'r', 'c', 'h', 'a'],\n",
       " ['a', 'a', 'z', 'i', 'n'],\n",
       " ['a', 'a', 'g', 'h'],\n",
       " ['a', 'a', 'a'],\n",
       " ['a', 'a', 'l', 'a'],\n",
       " ['a', 'a', 'a', 'n'],\n",
       " ['a', 'g', 'h', 'e', 'l', 'b', 'i', 'm'],\n",
       " ['i', 'a', 'b', 'i', 'l', 'i', 'n'],\n",
       " ['e', 'a', 'b', 'r', 'a', '-', 'n', 'a'],\n",
       " ['a', 'a', 'v', 'a', 'r', 'n', 'a'],\n",
       " ['a', 'a', 'b', 'r', 'e', 'y', 'h'],\n",
       " ['a', 'a', 'v', 'a', 'r', 'i', 't'],\n",
       " ['e', 'e', 'v', 'o', 'r'],\n",
       " ['a', 'a', 'v', 'i', 'r'],\n",
       " ['a', 'a', 'v', 'i', 'r', 'a', 'n', 'a'],\n",
       " ['a', 'a', 'k', 'a', 'n'],\n",
       " ['i', 'a', 'k', 'u', 'l'],\n",
       " ['a', 'e', 'd'],\n",
       " ['a', 'a', 'd', 'u'],\n",
       " ['a', 'a', 'd', 'i', 'a', 't'],\n",
       " ['a', 'a', 'd', 'i', 'u'],\n",
       " ['a', 'a', 'd', 'e', 'y', 'h'],\n",
       " ['a', 'e', 'd', 'i', 'm'],\n",
       " ['e', 'a', 'l', 'a', 'm'],\n",
       " ['u', 'a', 'l', 'a', 'v'],\n",
       " ['a', 'a', 'l', 'e', '-', 'l', 'a', 'k', 'h'],\n",
       " ['a', 'a', 'l', 'm', 'a'],\n",
       " ['a', 'a', 'l', 'n', 'a'],\n",
       " ['a', 'e', 'l', 'i', 'n', 'u', 'n'],\n",
       " ['a', 'a', 'l', 'a', 'n', 'i'],\n",
       " ['a', 'o', 'l', 'a', 't'],\n",
       " ['a', 'e', 'l', 't', 'u', 'n'],\n",
       " ['a', 'a', 'l', 'e', 'i', 'k', 'o', 'n'],\n",
       " ['a', 'a', 'l', 'i', 'm'],\n",
       " ['a', 'a', 'l', 'i', 'n'],\n",
       " ['a', 'a', 'l', 'i', 't'],\n",
       " ['e', 'a', 'l', 'o', 'z', 'a'],\n",
       " ['e', 'e', 'm', 'o', 'd', 'a'],\n",
       " ['a', 'a', 'm', 'a', 'l', 'n', 'a'],\n",
       " ['e', 'e', 'm', 'o', 'd'],\n",
       " ['e', 'e', 'n', 'd', 'e', 'n', 'u'],\n",
       " ['e', 'a', 'n', 's'],\n",
       " ['a', 'a', 'n', 'y', 'a'],\n",
       " ['a', 'a', 'n', 'y', 'n'],\n",
       " ['a', 'a', 'n', 'i', 'k'],\n",
       " ['a', 'a', 'n', 'i', 's', 'h'],\n",
       " ['a', 'a', 'n'],\n",
       " ['a', 'a', 'p', 'i', 'k', 'e'],\n",
       " ['a', 'a', 'p', 'i', 'l', 'a'],\n",
       " ['a', 'a', 'k', 'o', 'v'],\n",
       " ['a', 'a', 'k', 'a', 'm'],\n",
       " ['e', 'e', 'k', 'o', 'r', 'a'],\n",
       " ['a', 'a', 'k', 'r', 'u'],\n",
       " ['a', 'a', 'k', 'r', 'u', 't', 'a'],\n",
       " ['i', 'a', 'r', 'a', 'r', 'u'],\n",
       " ['i', 'a', 'r', 'a', 't'],\n",
       " ['e', 'e', 'r', 'b', 'e', 'n', 'u'],\n",
       " ['e', 'e', 'r', 'a', 'k', 'h'],\n",
       " ['e', 'e', 'r', 'a', 'k', 'h', '-', 'l', 'c', 'h', 'a'],\n",
       " ['e', 'e', 'r', 'k', 'a'],\n",
       " ['a', 'a', 'r', 'k', 't', 'a'],\n",
       " ['a', 'e', 'r', 'u', 'v'],\n",
       " ['a', 'a', 's', 'a'],\n",
       " ['e', 'e', 's', 'e', '-', 'k', 'h', 'e', 's', 'e', 'd'],\n",
       " ['e', 'e', 's', 'e', '-', 'z', 'a', 'o', 't'],\n",
       " ['e', 'e', 's', 'e', 'n', 'h'],\n",
       " ['e', 'e', 's', 'e', 'n', 'u'],\n",
       " ['a', 'a', 's', 'n'],\n",
       " ['i', 'a', 't', 'a', 'v', 'i'],\n",
       " ['a', 'a', 'h', 't', 'i', 'k', 'e', 'm'],\n",
       " ['i', 'a', 't', 'r', 'a'],\n",
       " ['a', 'a', 't', 'a', 'r', 'a', 't'],\n",
       " ['i', 'a', 't', 'i', 'n', 'i'],\n",
       " ['e', 'a', 't', 's', 'e', 'v'],\n",
       " ['e', 'e', 't', 's', 'o', 'r'],\n",
       " ['a', 'e', 't', 's'],\n",
       " ['a', 'u', 'o', 'v', 'e', 'd'],\n",
       " ['a', 'o', 'v', 'd', 'e'],\n",
       " ['a', 'o', 'h', 'i'],\n",
       " ['a', 'o', 'l', 'e', 'l'],\n",
       " ['a', 'a', 'u', 'f', 'a'],\n",
       " ['a', 'u', 't', 's'],\n",
       " ['a', 'e', 'i'],\n",
       " ['a', 'a', 'y', 'a'],\n",
       " ['a', 'a', 'y', 'k', 'h'],\n",
       " ['a', 'i', 'd'],\n",
       " ['a', 'i', 'l', 'u'],\n",
       " ['a', 'e', 'y', 'n', 'e', 'i', 'h'],\n",
       " ['a', 'i', 'n'],\n",
       " ['a', 'i', 'f'],\n",
       " ['a', 'e', 'i', 'k'],\n",
       " ['a', 'i', 'k', 'u'],\n",
       " ['a', 'a', 'i', 'r'],\n",
       " ['a', 'i', 'r', 'h'],\n",
       " ['a', 'i', 's', 'b', 'e', 'i'],\n",
       " ['a', 'a', 'y', 'a', 'y', 'a'],\n",
       " ['a', 'a', 'z'],\n",
       " ['e', 'e', 'z', 'o', 'v'],\n",
       " ['e', 'e', 'z', 'v', 'a'],\n",
       " ['e', 'e', 'z', 'b', 'e', 'm'],\n",
       " ['e', 'a', 'z', 'e', 'r'],\n",
       " ['e', 'e', 'z', 'a', 'r', 'c', 'h', 'a'],\n",
       " ['a', '-', 'd', 'v', 'e', 'v', 'y', 'r'],\n",
       " ['e', '-', 'd', 'i', 'n'],\n",
       " ['a', '-', 'h', 'a', '-', 'h', 'a'],\n",
       " ['e', '-', 'l'],\n",
       " ['e', '-', 'l', 'o', 'h', 'e', 'c', 'h', 'a'],\n",
       " ['e', '-', 'l', 'o', 'h', 'i', 'm'],\n",
       " ['a', '-', 'n', 'u'],\n",
       " ['a', '-', 'p', 'a', 'a', 'm'],\n",
       " ['a', '-', 'r', 'o', 'm', 'a', 'n', 't', 'i'],\n",
       " ['i', '-', 's'],\n",
       " ['a', '-', 's', 'a', 'r', 'k'],\n",
       " ['a', '-', 'z', 'a', 'h', 'r'],\n",
       " ['a', 'a', 's', 'e'],\n",
       " ['a', 'k', 'h'],\n",
       " ['i', 'l', 'i'],\n",
       " ['a', 'n', 'a'],\n",
       " ['e', 'k', 'h', 'a', 'd'],\n",
       " ['e', 'l', 'o', 'h', 'i', 'm'],\n",
       " ['e', 'l', 'o', 'h', 'e', 'n', 'u'],\n",
       " ['e', 'l', 'o', 'k', 'i', 'm'],\n",
       " ['a', 'l', 'a', 's', 'h', 'o', 'n'],\n",
       " ['e', 'l', 'i'],\n",
       " ['a', 'm', 'e', 'n'],\n",
       " ['i', 'm', 'r', 'e', 'i'],\n",
       " ['a', 'm', 'a', 'r', 'e', 'h', 'a'],\n",
       " ['a', 'f'],\n",
       " ['a', 'k', 'a', 'r', 'i'],\n",
       " ['a', 's', 'h', 'a', 'b', 'a', 't'],\n",
       " ['a', 's', 'h', 'f', 'i', 'k', 'h', 'u', 't'],\n",
       " ['e', 't'],\n",
       " ['a', 't', 'h', 'k', 'h', 'u', 'm', 'i', 'n'],\n",
       " ['a', 't', 'a', 'm', 'u', 'z'],\n",
       " ['a', 'v', 'h', 'e', 'v', 'e', 't', 'h'],\n",
       " ['a', 'o', 'h', 'a', 'r', 'a'],\n",
       " ['e', 'i'],\n",
       " ['e', 'i', 'k'],\n",
       " ['a', 'b', 'a'],\n",
       " ['a', 'v', 'i'],\n",
       " ['a', 'b', 'a', '-', 'p', 'i', 'l'],\n",
       " ['a', 'b', 'a', 'l', 'e'],\n",
       " ['a', 'v', 'o', 'h'],\n",
       " ['a', 'b', 'a', 'k', 'h'],\n",
       " ['a', 'b', 'a', 'n', 'o'],\n",
       " ['a', 'b', 'a', 'n', 'o', 't', 'u', 'b', 'a', 'n', 'i'],\n",
       " ['a', 'b', 'a', 'k', 'a', 'l', 'i', 'k', 'i'],\n",
       " ['e', 'b', 'a', 'r', 'a'],\n",
       " ['a', 'b', 'a', 'r', 'k', 'u'],\n",
       " ['a', 'v', 'a', 'r', 'v'],\n",
       " ['a', 'b', 'a', 's', 'u', 'b', 'o'],\n",
       " ['a', 'v', 'e', 's', 'h'],\n",
       " ['a', 'v', 'e', 's', 'h', 'h', 't', 'a'],\n",
       " ['a', 'v', 'e', 's', 'h', 't', 'u', 'n'],\n",
       " ['a', 'v', 'a', 's', 'h', 'i', 't'],\n",
       " ['a', 'b', 'a', 'o', 's', 'i', 'k'],\n",
       " ['a', 'b', 'a', 'i', 'a', 'n', 'g'],\n",
       " ['a', 'v', 'e', 'i', 's', 'h', 'a', 't'],\n",
       " ['a', 'v', 'e', 'i', 's', 'h', 't', 'u', 'n'],\n",
       " ['a', 'v', 'i', 's', 'h', 'u'],\n",
       " ['a', 'v', 'e', 'i', 's', 'h', 'i', 't'],\n",
       " ['a', 'v', 'a', 'z'],\n",
       " ['e', 'v', 'h', 'a', 'e'],\n",
       " ['e', 'v', 'h', 'a', 'e', '-', 'm', 'i', 'n', 'e', 'h'],\n",
       " ['a', 'v', 'a', 'b', 'u', 'a'],\n",
       " ['a', 'v', 'a', 'b', 'u', 'o', 't'],\n",
       " ['a', 'v', 'a', 'b', 'u', 'o', 't'],\n",
       " ['a', 'v', 'a', 'b', 'u', 'i', 'n'],\n",
       " ['a', 'v', 'a', 'b', 'u', 'a'],\n",
       " ['a', 'v', 'a', 'b', 'u', 'a', 'k', 'd', 'i'],\n",
       " ['a', 'v', 'a', 'b', 'u', 'i', 'n'],\n",
       " ['a', 'b', 'a', 'u', 'd'],\n",
       " ['i', 'v', 'u', 'n'],\n",
       " ['i', 'b', 'a', 'i', 't'],\n",
       " ['e', 'v', 'a', 'y', 'u', 't'],\n",
       " ['a', 'v', '-', 'b', 'e', 't', '-', 'd', 'i', 'n'],\n",
       " ['a', 'v', '-', 'h', 'a', 'm', 'o', 'n'],\n",
       " ['e', 'v', 'e', 'n'],\n",
       " ['a', 'v', 's', 'a', 'k', 's', 'h', 'o', 'm'],\n",
       " ['a', 'b', 'a', 'v', 'a', 's', 'h', 'k', 'i', 'v', 'u'],\n",
       " ['a', 'b', 'a', 'b', 'e', 'y', 'h'],\n",
       " ['a', 'v', 'v', 'y', 'n'],\n",
       " ['a', 'v', 'a', 'v', 'i', 't'],\n",
       " ['e', 'v', 'k', 'e', '-', 'l', 'a', 'k', 'h'],\n",
       " ['a', 'b', 'a', 'k', 'r'],\n",
       " ['a', 'b', 'k', 'i'],\n",
       " ['a', 'v', 'u', 'k', 'i', 'r'],\n",
       " ['a', 'b', 'a', 'd', 'a'],\n",
       " ['i', 'b', 'd', 'a', 'a'],\n",
       " ['a', 'b', 'd', 'a', 'l', 'a', 'k'],\n",
       " ['a', 'b', 'd', 'e', 'i', 'l'],\n",
       " ['a', 'b', 'a', 'd', 'a', 'i', 'm'],\n",
       " ['a', 'v', 'a', 'd', 'c', 'h', 'e', 'm'],\n",
       " ['a', 'v', 'a', 'd', 'n', 'a'],\n",
       " ['a', 'v', 'a', 'd', 'n', 'u', 'm'],\n",
       " ['e', 'v', 'd', 'o', 'k'],\n",
       " ['a', 'v', 'a', 'd', 'a', 'r'],\n",
       " ['a', 'b', 'd', 'e', 'r', 'o', 's'],\n",
       " ['i', 'b', 'a', 'd', 't', 'a', 'n', 'u'],\n",
       " ['a', 'v', 'a', 'd', 't', 'u', 'n'],\n",
       " ['a', 'v', 'd', 'a', '֖'],\n",
       " ['a', 'v', 'a', 'd', 'o', 'n'],\n",
       " ['e', 'v', 'd', 'o', 'k'],\n",
       " ['a', 'b', 'd', 'i'],\n",
       " ['a', 'v', 'd', 'i', 'l', 'u'],\n",
       " ['a', 'v', 'd', 'i', 'm', 'i'],\n",
       " ['a', 'v', 'd', 'i', 'n'],\n",
       " ['a', 'b', 'd', 'i', 'k', 'a'],\n",
       " ['i', 'v', 'd', 'i', 'k', 'a', 't'],\n",
       " ['e', 'v', 'g', 'e', 'n', 'i'],\n",
       " ['a', 'v', 'g', 'o', 'l', 'e', 'm', 'o', 'n', 'o'],\n",
       " ['a', 'v', 'g', 'u', 's', 't'],\n",
       " ['a', 'v', 'i', 'g', 'a', 'y', 'i', 'l'],\n",
       " ['a', 'v', 'g', 'i', 't', 'a'],\n",
       " ['a', 'b', 'h', 'a', 'r'],\n",
       " ['a', 'v', 'e', 'v', 'i', 'k', 'r'],\n",
       " ['e', 'b', 'a', 'h', 'e', 'l'],\n",
       " ['a', 'b', 'h', 'a', 'm', 'a'],\n",
       " ['a', 'b', 'h', 'a', 'r'],\n",
       " ['a', 'v', 'a', 'h', 'a', 't', 'i', 'n'],\n",
       " ['e', 'v', 'h', 'o', 'r'],\n",
       " ['a', 'v', 'h', 'u', 't'],\n",
       " ['a', 'b', 'h', 'y', 'a', 's', 'a', 't'],\n",
       " ['a', 'b', 'h', 'i', 'd', 'h', 'a', 'm', 'h'],\n",
       " ['a', 'b', 'h', 'a', 'y', 'a'],\n",
       " ['a', 'b', 'h', 'y', 'n', 'i', 'v', 'e', 's', 'h'],\n",
       " ['a', 'v', 'h', 'i', 'k', 'u'],\n",
       " ['a', 'b', 'h', 'i', 's', 'e', 'k', 'h'],\n",
       " ['i', 'v', 'k', 'h'],\n",
       " ['e', 'v', 'k', 'h', 'a', 'n', 'c', 'h', 'a'],\n",
       " ['a', 'v', 'k', 'h', 'a', 'n', 'a', 't'],\n",
       " ['e', 'v', 'k', 'h', 'a', 'r', '-', 'b', 'o'],\n",
       " ['e', 'v', 'k', 'h', 'a', 'r', 'a'],\n",
       " ['i', 'v', 'k', 'h', 'a', 't', '-', 'k', 'h', 'a', 'r', 'e', 'v'],\n",
       " ['a', 'v', 'k', 'h', 'i', 'n', 'a'],\n",
       " ['a', 'v', 'a', 'k', 'h', 'a', 'z', 'i', 'm'],\n",
       " ['i', 'b', 'a', 'l', 'a', 'd', 'u'],\n",
       " ['i', 'v', 'l', 'a', 'h'],\n",
       " ['a', 'b', 'l', 'e', 't', 'l'],\n",
       " ['e', 'v', 'e', 'l', '-', 'k', 'a', 'b', 'e', 'd'],\n",
       " ['a', 'v', 'e', 'l', 'v', 'h', 'r'],\n",
       " ['e', 'v', 'e', 'l', 'h', 'v', 't', 'n', 'v'],\n",
       " ['e', 'v', 'l', 'a', 'l', 'i'],\n",
       " ['a', 'b', 'e', 'l', 'a', 'r', 'd', 'o'],\n",
       " ['a', 'b', 'e', 'l', 'e', 's'],\n",
       " ['a', 'v', 'a', 'l', 't', 'a'],\n",
       " ['a', 'b', 'l', 'a', 't', 'i', 'v', 'u', 's'],\n",
       " ['e', 'v', 'e', 'l', 'v', 'l', 'e', 'v'],\n",
       " ['a', 'v', 'e', 'l', 'u', 't', 'a'],\n",
       " ['a', 'v', 'e', 'l', 'u', 't', 'a', 'h'],\n",
       " ['a', 'v', 'e', 'l', 'u', 't', 'a', 'm'],\n",
       " ['a', 'v', 'e', 'l', 'u', 't', 'a', 'n'],\n",
       " ['a', 'v', 'e', 'l', 'u', 't', 'o'],\n",
       " ['i', 'v', 'l', 'i', 'a', 't'],\n",
       " ['a', 'v', 'e', 'l', 'a', 'y', 'i', 'k', 'h'],\n",
       " ['a', 'v', 'e', 'l', 'e', 'y', 'h', 'e', 'm'],\n",
       " ['e', 'b', 'e', 'l', 'i', 'n', 'g'],\n",
       " ['e', 'v', 'l', 'i', 'n'],\n",
       " ['a', 'b', 'e', 'l', 'e', 'y', 'u', 's'],\n",
       " ['a', 'v', 'e', 'l', 'u', 'y', 'o', 't'],\n",
       " ['a', 'b', 'i', 'm'],\n",
       " ['a', 'b', 'i', 'm', 'a', 't', 'i', 'm'],\n",
       " ['i', 'v', 'n', 'i', 'a', 'd', 'u'],\n",
       " ['i', 'b', 'h', 'n', 'a', 'l'],\n",
       " ['e', 'v', 'a', 'n', 'g', 'i', 'l', 'y', 't'],\n",
       " ['a', 'v', 'n', 'a', 'a'],\n",
       " ['e', 'v', 'n', 'e', '-', 'l', 'a', 'k', 'h'],\n",
       " ['e', 'v', 'n', 'e', '-', 'l', 'o'],\n",
       " ['e', 'v', 'n', 'e', '-', 'l', 'i'],\n",
       " ['e', 'v', 'n', 'e', 'n', 'u'],\n",
       " ['i', 'b', 'n', 'e', 'n', 'i'],\n",
       " ['a', 'v', 'n', 'a', 'n'],\n",
       " ['a', 'v', 'n', 'e', 'r', 'i'],\n",
       " ['e', 'v', 'a', 'n', 's'],\n",
       " ['a', 'v', 'n', 'e', 't', 'i', 'm'],\n",
       " ['a', 'v', 'n', 'o'],\n",
       " ['a', 'v', 'n', 'o', 'h', 'i'],\n",
       " ['a', 'v', 'n', 'o', 'n'],\n",
       " ['a', 'v', 'n', 'e', 'i'],\n",
       " ['a', 'v', 'n', 'a', 'y', 'a'],\n",
       " ['a', 'v', 'n', 'e', 'i', '-', 'e', 's', 'h'],\n",
       " ['a', 'v', 'n', 'e', 'i', '-', 'k', 'o', 'd', 'e', 's', 'h'],\n",
       " ['a', 'v', 'n', 'e', 'i', '-', 's', 'h', 'o', 'h', 'a', 'm'],\n",
       " ['a', 'v', 'n', 'e', 'i', '-', 't', 's', 'e', 'd', 'e', 'k'],\n",
       " ['a', 'v', 'a', 'n', 'a', 'y', 'i', 'k', 'h'],\n",
       " ['a', 'v', 'a', 'n', 'e', 'i', 'h', 'a'],\n",
       " ['a', 'v', 'n', 'e', 'i', 'h', 'e', 'm'],\n",
       " ['a', 'v', 'n', 'i', 'm', 'v', 'a', 's', 'i', 't', 'h'],\n",
       " ['i', 'v', 'n', 'i', 'n', 'g'],\n",
       " ['e', 'v', 'n', 'i', 'k', 'a'],\n",
       " ['a', 'v', 'a', 'n', 'a', 'v'],\n",
       " ['a', 'v', 'n', 'a', 'y', 'a', 'y', 'a'],\n",
       " ['e', 'v', 'e', 'n', 'i', 'y', 'a', 'r', 'u'],\n",
       " ['e', 'b', 'e', 'n', 'e', 'z', 'e', 'r'],\n",
       " ['e', 'v', 'e', 'n'],\n",
       " ['e', 'v', 'e', 'n', '-', 'g', 'a', 'y', 'a'],\n",
       " ['e', 'v', 'e', 'n', '-', 'k', 'h', 'e', 'n'],\n",
       " ['e', 'v', 'e', 'n', '-', 's', 'a', 'p', 'i', 'r'],\n",
       " ['e', 'v', 'e', 'n', '-', 's', 'h', 'l', 'e', 'm', 'a'],\n",
       " ['a', 'v', 'a', 'k', 'a', 'm'],\n",
       " ['a', 'v', 'k', 'a', 'n'],\n",
       " ['a', 'v', 'a', 'k', 'a', 'e', 'r', 'c', 'h', 'e', 'm'],\n",
       " ['a', 'b', 'e', 'k', 'a', 's', 'i', 's'],\n",
       " ['a', 'v', 'a', 'k', 'a', 'e', 's', 'h', '-', 'l', 'a', 'k', 'h'],\n",
       " ['a', 'v', 'a', 'k', 'a', 'e', 's', 'h', 'k', 'h', 'a'],\n",
       " ['a', 'v', 'a', 'k', 's', 'h', 'e', 'n', 'u'],\n",
       " ['a', 'v', 'k', 'a', 't', '-', 'k', 'l', 'v'],\n",
       " ['e', 'v', 'k', 'o', 'a'],\n",
       " ['a', 'b', 'a', 'k', 'u', 'm', 'o', 'v'],\n",
       " ['a', 'b', 'a', 'k', 'u', 's'],\n",
       " ['a', 'v', 'k', 'o', 's', 'm', 'o', 's'],\n",
       " ['a', 'v', 'k', 'e', 'y', 'h'],\n",
       " ['a', 'v', 'k', 'i', 'l', 'a', 's'],\n",
       " ['a', 'b', 'a', 'k', 'y', 'o'],\n",
       " ['e', 'v', 'r', 'e', 'l', 'y', 's'],\n",
       " ['a', 'v', 'r', 'a', 'k', 's', 'i', 'o'],\n",
       " ['a', 'b', 'r', 'a', 's', 'h', 'h'],\n",
       " ['a', 'b', 'r', 'e', 'u'],\n",
       " ['a', 'v', 'r', 'a', 'v', 'a', 'y', 'a'],\n",
       " ['a', 'b', 'r', 'e', 'v', 'i', 't', 'o', 'r'],\n",
       " ['a', 'v', 'a', 'r', 'e', 'k', 'h', 'k', 'a'],\n",
       " ['a', 'v', 'a', 'r', 'c', 'h', 'e', 'm', 'h', 'v', 'r', 'k'],\n",
       " ['a', 'v', 'a', 'r', 'k', 'i', 'n', 'a', 'k', 'h'],\n",
       " ['a', 'v', 'a', 'r', 'e', 'k', 'i', 'n', 'u', 'n'],\n",
       " ['a', 'b', 'i', 'r', 'k', 'a', 't'],\n",
       " ['e', 'v', 'e', 'r', 'g', 'l', 'e', 'y', 'd', 'z'],\n",
       " ['e', 'b', 'e', 'r', 'h', 'a', 'r', 'd'],\n",
       " ['a', 'v', 'r', 'a', 'a', 'm', 't', 's', 'e', 'i'],\n",
       " ['a', 'v', 'r', 'a', 'h', 'a', 'm'],\n",
       " ['a', 'v', 'r', 'a', 'm'],\n",
       " ['a', 'v', 'r', 'a', 'a', 'm', 'v', 'a', 'y', 'a', 'g', 'a', 'r'],\n",
       " ['e', 'b', 'e', 'r', 'h', 'r', 'd', 't'],\n",
       " ['a', 'v', 'r', 'a', 'h', 'a', '֛', 'm'],\n",
       " ['e', 'v', 'r', 'a', 'k', 'h'],\n",
       " ['e', 'v', 'r', 'k', 'h', 'a'],\n",
       " ['a', 'v', 'r', 'a', 'l', 'a', 'n'],\n",
       " ['a', 'v', 'r', 'e', 'm', 'a', 'l', 'e'],\n",
       " ['a', 'b', 'r', 'a', 'm', 's'],\n",
       " ['a', 'v', 'r', 'e', 'm', 'i', 'l'],\n",
       " ['a', 'v', 'r', 'a', 'm'],\n",
       " ['a', 'b', 'r', 'a', 'n', 's', 'h', 'e', 's', 'h'],\n",
       " ['a', 'b', 'e', 'r', 'n', 'a', 't', 'i'],\n",
       " ['e', 'v', 'r', 'e', 'n'],\n",
       " ['a', 'v', 'e', 'r', 'f', 'e', 'l', 'd', 'i'],\n",
       " ['a', 'b', 'r', 's', 't', 'a', 'd', 't'],\n",
       " ['e', 'v', 'e', 'r', 's', 'u', 'a', 'l', 'd', 'e'],\n",
       " ['a', 'v', 'r', 'a', 's', 'h', 'i', 'y', 'i', 'm'],\n",
       " ['e', 'v', 'r', 'a', 't'],\n",
       " ['e', 'v', 'r', 'a', 't', 'o'],\n",
       " ['a', 'b', 'e', 'r', 't', 's', 'i'],\n",
       " ['a', 'b', 'r', 'a', 'v', 'a'],\n",
       " ['a', 'v', 'r', 'o', 'm'],\n",
       " ['e', 'b', 'e', 'r', 'u', 'n', 'i'],\n",
       " ['a', 'b', 'r', 'u', 's', 'y', 'o'],\n",
       " ['e', 'v', 'r', 'o', 't'],\n",
       " ['e', 'v', 'r', 'o', 't', 'e', 'y', 'c', 'h', 'a'],\n",
       " ['a', 'v', 'r', 'u', 't', 's', 'o'],\n",
       " ['e', 'v', 'r', 'a', 'y', 'a'],\n",
       " ['e', 'v', 'r', 'i', 'a', 'o'],\n",
       " ['a', 'b', 'r', 'e', 'i', 'k', 'h'],\n",
       " ['a', 'v', 'r', 'i', 'k', 'h', 'a'],\n",
       " ['a', 'v', 'r', 'e', 'm', 'i'],\n",
       " ['e', 'v', 'a', 'r', 'i', 'n'],\n",
       " ['e', 'v', 'ֿ', 'r', 'i', 'k', 'h'],\n",
       " ['i', 'v', 'r', 'i', 'r'],\n",
       " ['a', 'b', 'r', 'a', 'y', 't', 'a'],\n",
       " ['a', 'v', 'r', 'i', 't', 'e'],\n",
       " ['e', 'v', 'a', 'r', 'a', 'v'],\n",
       " ['e', 'v', 'r', 'a', 'y', 'i'],\n",
       " ['a', 'v', 'a', 'r', 'z', 'y', 'n'],\n",
       " ['a', 'b', 'i', 's', 'a', 'm', 'a'],\n",
       " ['a', 'b', 'i', 's', 'a', 'm', 'a', 's'],\n",
       " ['a', 'v', 's', 't', 'e', 'r', 'g', 'o'],\n",
       " ['a', 'b', 's', 't', 'r', 'a', 'k', 't'],\n",
       " ['a', 'b', 's', 't', 'r', 'a', 'k', 't', 's', 'y', 'a'],\n",
       " ['a', 'b', 's', 'o', 'l'],\n",
       " ['a', 'v', 's', 'o', 'l', 'u', 't', 'i'],\n",
       " ['a', 'b', 's', 'o', 'l', 'u', 't', 'i', 'u', 't'],\n",
       " ['a', 'b', 's', 'o', 'l', 'u', 't', 'i', 'z', 'm'],\n",
       " ['a', 'b', 's', 'u', 'r', 'd'],\n",
       " ['a', 'v', 's', 'i', 'm', 'u'],\n",
       " ['a', 'v', 'a', 's', 'h', 'e', 'l'],\n",
       " ['a', 'v', 's', 'h', 'a', 'l', 'o', 'm'],\n",
       " ['a', 'v', 's', 'h', 'a', 'l', 'o', 'm'],\n",
       " ['a', 'b', 'i', 's', 'r', 'a'],\n",
       " ['e', 'b', 's', 't', 'a', 'y', 'y', 'n'],\n",
       " ['a', 'b', 'o', 't', 'k', 'h'],\n",
       " ['a', 'v', 'o', 't', 'a', 'm'],\n",
       " ['a', 'v', 't', 'a', 'n', 'd', 'i', 'l'],\n",
       " ['a', 'v', 'a', 't', 'r', 'a', 'y', 'k', 'h'],\n",
       " ['a', 'v', 'a', 't', 'r', 'a', 'y', 'h', 'o', 'n'],\n",
       " ['a', 'b', 'a', 't', 'r', 'i', 'n'],\n",
       " ['a', 'b', 'a', 't', 'r', 'a', 'y', 'y', 'k', 'u'],\n",
       " ['i', 'v', 't', 'i', 's', 'a', 'm'],\n",
       " ['a', 'v', 't', 'e', 'i', 'k'],\n",
       " ['a', 'v', 'o', 't', 'e', 'y', 'h', 'e', 'm'],\n",
       " ['i', 'v', 't', 'i', 's', 'a', 'm'],\n",
       " ['a', 'v', 'o', 't', 'a', 'v'],\n",
       " ['a', 'v', 'a', '֣', 'k'],\n",
       " ['a', 'v', 'a', 't', 'a'],\n",
       " ['a',\n",
       "  'b',\n",
       "  'e',\n",
       "  't',\n",
       "  'a',\n",
       "  'l',\n",
       "  'i',\n",
       "  'p',\n",
       "  'o',\n",
       "  'p',\n",
       "  'r',\n",
       "  'o',\n",
       "  't',\n",
       "  'e',\n",
       "  'i',\n",
       "  'n',\n",
       "  'e',\n",
       "  'm',\n",
       "  'y',\n",
       "  'a'],\n",
       " ['u', 'v', 't', 'a', 'k', 'h'],\n",
       " ['e', 'v', 't', 'a', 'k', '-', 'b', 'a', 'k', 'h'],\n",
       " ['a', 'v', 't', 'a', 'k', 'h', 't', 'a', 'n', 'i'],\n",
       " ['a', 'v', 't', 'a', 'k', 'h', 'u', 't', 'a'],\n",
       " ['a', 'v', 't', 'a', 'l', 'a'],\n",
       " ['a',\n",
       "  'v',\n",
       "  't',\n",
       "  'o',\n",
       "  'e',\n",
       "  'i',\n",
       "  'm',\n",
       "  'a',\n",
       "  'n',\n",
       "  't',\n",
       "  's',\n",
       "  'i',\n",
       "  'p',\n",
       "  'a',\n",
       "  't',\n",
       "  's',\n",
       "  'i',\n",
       "  'a'],\n",
       " ['a', 'v', 't', 'o', 'b', 'u', 's'],\n",
       " ['a', 'v', 't', 'u', 'l', 'a', 's'],\n",
       " ['a', 'v', 't', 'o', 'm', 'a', 't', 'y', 't'],\n",
       " ['a', 'v', 't', 'o', 'm', 'o', 'b', 'u', 's'],\n",
       " ['a', 'v', 't', 'o', 'n'],\n",
       " ['a', 'v', 't', 'o', 'k', 'e', 'f', 'a', 'l', 'i'],\n",
       " ['a', 'v', 't', 'o', 'r', 'i', 't', 'a'],\n",
       " ['a', 'v', 't', 'o', 'r', 'y', 't', 't'],\n",
       " ['a', 'v', 'a', 't', 'a', 'i', 'a', 'k', 'a'],\n",
       " ['a', 'v', 'a', 't', 'a', 'i', 'k', 'h', 'i', 'm'],\n",
       " ['a', 'v', 't', 'i', 'l'],\n",
       " ['a', 'v', 't', 'i', 'l', 'a', 's'],\n",
       " ['a', 'v', 't', 'i', 'n', 'a', 's'],\n",
       " ['i', 'b', 't', 'i', 'n'],\n",
       " ['a', 'v', 't', 'y', 'f', 'u', 's', 'i', 'y', 'i', 'm'],\n",
       " ['a', 'b', 't', 'a', 'y', 'y', 'b', 'e', 'r', 'g'],\n",
       " ['a', 'v', 'a', 't', 's', 'a'],\n",
       " ['i', 'v', 't', 's', 'a', 'n'],\n",
       " ['a', 'b', 't', 's', 'e', 's'],\n",
       " ['a', 'b', 't', 's', 'u', 'g'],\n",
       " ['a', 'v', 'o', 'h'],\n",
       " ['a', 'b', 'u', 'e', 'l', 'a'],\n",
       " ['a', 'v', 'u', 'a', 'r'],\n",
       " ['o', 'b', 'u', 'o', 'i'],\n",
       " ['a', 'b', 'u', '-', 't', 'o', 'r'],\n",
       " ['a', 'b', 'u', 'v'],\n",
       " ['a', 'b', 'u', 'v', 'i', 't'],\n",
       " ['a', 'b', 'u', 'k'],\n",
       " ['a', 'v', 'u', 'k', 'e', 'n'],\n",
       " ['a', 'v', 'u', 'k', 'o', 'n'],\n",
       " ['i', 'v', 'u', 'd', 'a'],\n",
       " ['a', 'v', 'u', 'd', 'h'],\n",
       " ['a', 'v', 'u', 'd', 'h', 'o', 'n'],\n",
       " ['a', 'v', 'u', 'd', 'a', 'n', 'y', 'a'],\n",
       " ['a', 'b', 'u', 'd', 'a', 'r', 'h', 'a', 'm'],\n",
       " ['a', 'v', 'u', 'd', 'o', 't'],\n",
       " ['a', 'v', 'u', 'd', 'i', 'm'],\n",
       " ['e', 'v', 'o', 'd', 'v'],\n",
       " ['a', 'a', 'a', 'b', 'u', 'g'],\n",
       " ['a', 'b', 'u', 'j', 'a'],\n",
       " ['a', 'v', 'u', 'h', 'a'],\n",
       " ['a', 'v', 'u', 'h', 'e', 'n'],\n",
       " ['a', 'v', 'u', 'a', 'k', 'h', 't', 's', 'i', 'r', 'a'],\n",
       " ['a', 'v', 'u', 'l', 'a', 'a', 'f', 'i', 'h'],\n",
       " ['a', 'a', 'a', 'b', 'u', 'l', 'a', 'a', 'f', 'i'],\n",
       " ['e', 'v', 'o', 'l', 'u', 't', 's', 'y', 'o', 'n', 'i'],\n",
       " ['e', 'v', 'o', 'l', 'u', 't', 's', 'y', 'o', 'n', 'i', 'm'],\n",
       " ['a', 'v', 'u', 'l', 'i', 'y', 'a'],\n",
       " ['i', 'b', 'u', 'l', 'i', 'm'],\n",
       " ['a', 'v', 'o', 'l', 'i', 't', 's', 'y', 'a'],\n",
       " ['a', 'b', 'o', 'm', 'i', 'n', 'e', 'i', 's', 'h', 'e', 'n'],\n",
       " ['e', 'v', 'o', 'n', 'l', 'i'],\n",
       " ['a', 'v', 'u', 'n', 'a', 'n'],\n",
       " ['e', 'b', 'o', 'n', 'i'],\n",
       " ['a', 'v', 'u', 'k'],\n",
       " ['a', 'v', 'u', 'k', 'h'],\n",
       " ['a', 'b', 'u', 'k', 'a', 'r', 'a', 't'],\n",
       " ['a', 'v', 'u', 'k', 'o', 't'],\n",
       " ['a', 'v', 'u', 'k', 'o', 't', 'a', 'y', 'i', 'k', 'h'],\n",
       " ['a', 'v', 'u', 'r'],\n",
       " ['e', 'v', 'o', 'r', 'a'],\n",
       " ['a', 'b', 'o', 'r', 'e', 'r'],\n",
       " ['a', 'b', 'u', 'r', 'a', 'r', 'h', 'a', 'm'],\n",
       " ['a', 'v', 'o', 'r', 't'],\n",
       " ['a', 'b', 'u', 'r', 't', 'i', 'n'],\n",
       " ['a', 'v', 'u', 's', 'e', 'c', 'h', 'a'],\n",
       " ['e', 'v', 'u', 's', 'h'],\n",
       " ['a', 'v', 'u', 's', 'e', 'n', 'u'],\n",
       " ['a', 'v', 'u', 's', 'i', 'm'],\n",
       " ['a', 'v', 'u', 's', 'h', 'd', 'i', 'd'],\n",
       " ['e', 'v', 'o', 's', 'h', 'h'],\n",
       " ['a', 'b', 'o', 's', 'h', 'e', 'm', 'a', 'n'],\n",
       " ['a', 'v', 'o', 't', 'i', 's', 'h'],\n",
       " ['a', 'v', 'o', 't', 'a', 'v', 'o', 't', 'e', 'y', 'h', 'e', 'm'],\n",
       " ['a', 'v', 'o', 't', 'e', 'n', 'u'],\n",
       " ['a', 'v', 'o', 't', 'e', 'y', 'c', 'h', 'a'],\n",
       " ['a', 'v', 'o', 't', 'e', 'c', 'h', 'e', 'm'],\n",
       " ['a', 'v', 'o', 't', 'e', 'y', 'k', 'e', '֗', 'm'],\n",
       " ['a', 'v', 'o', 't', 'e', 'y', 'h', 'e', 'n'],\n",
       " ['e', 'v', 'u', 't', 'e', 'r', 'n'],\n",
       " ['a', 'b', 'u', 't', 'i', 'l', 'o', 'n'],\n",
       " ['a', 'b', 'u', 't', 's', 'i', 'n', 'a'],\n",
       " ['i', 'v', 'u', 't', 's'],\n",
       " ['a', 'v', 'u', 'i', 'a'],\n",
       " ['a', 'v', 'o', 'y', 'l', 'e', 'n'],\n",
       " ['a', 'v', 'i'],\n",
       " ['a', 'v', 'i', 'e', 'l'],\n",
       " ['a', 'v', 'i', 'e', 'm'],\n",
       " ['a', 'v', 'i', 'e', 'n', 'u'],\n",
       " ['a', 'v', 'i', 'a', 's', 'a', 'f'],\n",
       " ['a', 'v', 'i', 'o'],\n",
       " ['a', 'b', 'i', 'a'],\n",
       " ['a', 'v', 'i', 'a', 'd'],\n",
       " ['a', 'b', 'i', 'a'],\n",
       " ['a', 'v', 'i', 'a', 'e', 'l'],\n",
       " ['a', 'v', 'i', '-', 'a', 'b', 'a'],\n",
       " ['a', 'v', 'i', '-', 'a', 'v', 'n', 'e', 'r'],\n",
       " ['a', 'v', 'i', '-', 'a', 'd'],\n",
       " ['a', 'v', 'i', '-', 'a', 'l', 'v', 'o', 'n'],\n",
       " ['a', 'v', 'i', '-', 'g', 'i', 'v', 'o', 'n'],\n",
       " ['a', 'v', 'i', '-', 'g', 'i', 'l', 'a', 'd'],\n",
       " ['a', 'v', 'i', '-', 'm', 'i', 'l', 'k', 'h'],\n",
       " ['a', 'v', 'i', '-', 'm', 'o', 'a', 'v'],\n",
       " ['a', 'v', 'i', '-', 's', 'h', 'a', 'u', 'l'],\n",
       " ['a', 'v', 'i', '-', 's', 'h', 'h', 'c', 'h', 'e', 'm'],\n",
       " ['a', 'v', 'i', '-', 'y', 'i', 's', 'h', 'a', 'y'],\n",
       " ['a', 'v', 'i', '-', 'z', 'i', 'f'],\n",
       " ['a', 'v', 'i'],\n",
       " ['a', 'v', 'i', 'v', 'e', 'k', 'h'],\n",
       " ['a', 'v', 'i', 'v', 'a'],\n",
       " ['a', 'v', 'i', 'v', 'i', 'm'],\n",
       " ['a', 'b', 'i', 'v', 'i', 'n'],\n",
       " ['a', 'v', 'i', 'v', 'i', 't'],\n",
       " ['a', 'v', 'i', 'c', 'h', 'e', 'm'],\n",
       " ['a', 'v', 'i', 'k', 'e', 'n'],\n",
       " ['a', 'v', 'e', 'd', 'a'],\n",
       " ['a', 'v', 'i', 'd', 'a'],\n",
       " ['a', 'v', 'i', 'd', 'n', 'a'],\n",
       " ['a', 'v', 'e', 'd', 'a', 't'],\n",
       " ['a', 'v', 'i', 'd', 'e'],\n",
       " ['a', 'b', 'i', 'g', 'a'],\n",
       " ['a', 'v', 'i', 'g', 'a', 'l'],\n",
       " ['a', 'b', 'i', 'g', 'e', 'y', 'l'],\n",
       " ['a', 'v', 'i', 'h', 'a'],\n",
       " ['a', 'v', 'y', 'h', 'n', 'g', 'h'],\n",
       " ['a', 'v', 'i', 'h', 'e', 'n'],\n",
       " ['a', 'v', 'i', 'h', 'u'],\n",
       " ['a', 'v', 'i', 'h', 'u', 'd'],\n",
       " ['a', 'v', 'i', 'h', 'u', 't'],\n",
       " ['a', 'v', 'i', 'a', 'k', 'h', '֫', 'y', 'i', 'l'],\n",
       " ['a', 'v', 'i', 'l'],\n",
       " ['a', 'v', 'i', 'l', 'e', 'a'],\n",
       " ['a', 'v', 'e', 'l', 'n', 'a'],\n",
       " ['a', 'v', 'i', 'm', 'i'],\n",
       " ['a', 'v', 'i', 'n', 'a'],\n",
       " ['a', 'v', 'i', 'n', 'o', 'a', 'm'],\n",
       " ['e', 'v', 'y', 'o', 'n', 'k', 'h', 'a'],\n",
       " ['a', 'v', 'i', 'n', 'a', 'd', 'a', 'v'],\n",
       " ['a', 'v', 'i', 'n', 'g', 'o', 'n'],\n",
       " ['a', 'v', 'i', 'n', 'a'],\n",
       " ['a', 'v', 'i', 'n', 'e', 'r'],\n",
       " ['e', 'v', 'y', 'o', 'n', 'e', 'i'],\n",
       " ['e', 'v', 'y', 'o', 'n', 'i', 'm'],\n",
       " ['a', 'v', 'i', 'k'],\n",
       " ['a', 'v', 'i', 'k', 'a', 'n'],\n",
       " ['a', 'v', 'i', 'r', 'a', 'm'],\n",
       " ['a', 'b', 'i', 'r', 'u', 't'],\n",
       " ['a', 'b', 'i', 'r', 'o', 'i'],\n",
       " ['a', 'b', 'i', 'r', 'e', 'c', 'h', 'a'],\n",
       " ['a', 'b', 'i', 'r', 'e', 'h', 'e', 'm'],\n",
       " ['a', 'b', 'i', 'r', 'i', 'm'],\n",
       " ['a', 'b', 'i', 's'],\n",
       " ['a', 'b', 'i', 's', 'e', 'l', 'i'],\n",
       " ['a', 'v', 'y', 's', 'o', 's'],\n",
       " ['a', 'v', 'a', 'y', 'e', 's'],\n",
       " ['a', 'v', 'i', 's', 'h', 'a', 'l', 'o', 'm'],\n",
       " ['a', 'v', 'i', 's', 'h', 'u', 'a'],\n",
       " ['a', 'v', 'i', 's', 'h', 'u', 'r'],\n",
       " ['a', 'v', 'i', 't', 'e', 'm'],\n",
       " ['e', 'v', 'y', 'a', 't', 'a', 'r'],\n",
       " ['a', 'v', 'i', 't', 'u', 'n'],\n",
       " ['a', 'v', 'i', 't', 'i'],\n",
       " ['a', 'b', 'e', 't', 'e', 'h'],\n",
       " ['a', 'b', 'i', 't'],\n",
       " ['a', 'b', 'i', 't', 'e', 'l'],\n",
       " ['a', 'b', 'i', 't', 'a'],\n",
       " ['a', 'v', 'i', 't', 'a', 'l'],\n",
       " ['a', 'v', 'y', 't', 'a', 'r', 'e'],\n",
       " ['a', 'v', 'i', 't', 'u', 'v'],\n",
       " ['a', 'v', 'i', 't', 'o', 'l'],\n",
       " ['a', 'b', 'y', 'o', 'g', 'e', 'n', 'e', 'z', 'a'],\n",
       " ['e', 'v', 'y', 'o', 'n', 'c', 'h', 'a'],\n",
       " ['a', 'v', 'i', 'y', 'o', 'n', 'a'],\n",
       " ['e', 'v', 'y', 'o', 'n', 'o', 't'],\n",
       " ['e', 'v', 'y', 'o', 'n', 'e', 'i', 'h', 'a'],\n",
       " ['a', 'b', 'i', 'y', 'e', 'v'],\n",
       " ['i', 'b', 'a', 'y', 'y', 'h', 'u'],\n",
       " ['a', 'v', 'e', 'y', 'r', 'v'],\n",
       " ['a', 'v', 'y', 'a', 'y', 't'],\n",
       " ['a', 'v', 'i', 'z', 'a', 'r'],\n",
       " ['a', 'v', 'z', 'a', 'k', 'h'],\n",
       " ['e', 'v', 'z'],\n",
       " ['a', 'v', 'z', 'a', 'm'],\n",
       " ['a', 'v', 'z', 'a', 'k', 'a'],\n",
       " ['a', 'v', 'z', 'a', 'k', 'a'],\n",
       " ['a', 'v', 'z', 'a', 'r'],\n",
       " ['a', 'v', 'i', 'z', 'a', 'r', 'e', 'i'],\n",
       " ['a', 'v', 'z', 'u', 'd'],\n",
       " ['a', 'k', 'h', '-', 'e', 'l', 'o', 'h', 'i', 'm'],\n",
       " ['a', 'k', 'h', '-', 'a', 'n', 'a', 's', 'h', 'i', 'm'],\n",
       " ['a', 'k', 'h', '-', 'e', 'u', 'i', 'l', 'i', 'm'],\n",
       " ['a', 'k', 'h', '-', 'a', 'm', 'i'],\n",
       " ['a', 'k', 'h', '-', 'a', 't', 'h'],\n",
       " ['a', 'k', 'h', '-', 'b', 'k', 'h', 'o', 'r'],\n",
       " ['a', 'k', 'h', '-', 'b', 'm', 'i', 's', 'h', 'p', 'a', 't'],\n",
       " ['a', 'k', 'h', '-', 'b', 't', 's', 'e', 'l', 'e', 'm'],\n",
       " ['a', 'k', 'h', '-', 'b', 'y', 'a', 'm', 'e', 'i', 'c', 'h', 'a'],\n",
       " ['a', 'k', 'h', '-', 'b', 'z', 'o', 't'],\n",
       " ['a', 'k', 'h', '-', 'k', 'a', 'l', '-', 'k', 'h', 'e', 'r', 'e', 'm'],\n",
       " ['a',\n",
       "  'k',\n",
       "  'h',\n",
       "  '-',\n",
       "  'd',\n",
       "  'h',\n",
       "  'v',\n",
       "  'a',\n",
       "  'r',\n",
       "  '-',\n",
       "  's',\n",
       "  'h',\n",
       "  'f',\n",
       "  'a',\n",
       "  't',\n",
       "  'a',\n",
       "  'y',\n",
       "  'i',\n",
       "  'm'],\n",
       " ['a', 'k', 'h', '-', 'd', 'r', 'a', 'k', 'a', 'y'],\n",
       " ['a', 'k', 'h', '-', 'h', 'e', 'v', 'e', 'l'],\n",
       " ['a', 'k', 'h', '-', 'h', 'a', 'p', 'a', 'a', 'm'],\n",
       " ['a', 'k', 'h', '-', 'h', 'u'],\n",
       " ['a', 'k', 'h', '-', 'k', 'h', 'o', 's', 'h', 'e', 'k', 'h'],\n",
       " ['a', 'k', 'h', '-', 'l', 'h', 'a', 'r', 'e', 'a'],\n",
       " ['a', 'k', 'h', '-', 'l', 'm', 'o', 't', 'a', 'r'],\n",
       " ['a', 'k', 'h', '-', 'l', 'p', 'a', 's', 'h', 'e', 't'],\n",
       " ['a', 'k', 'h', '-', 'm', 'r', 'i'],\n",
       " ['a', 'k', 'h', '-', 'n', 'i', 'v', 'h', 'a', 'l', 'a'],\n",
       " ['a', 'k', 'h', '-', 'n', 'k', 'a', 'i', 'm'],\n",
       " ['a', 'k', 'h', '-', 'p', 'r', 'i'],\n",
       " ['a', 'k', 'h', '-', 's', 'h', 'm', 'a', '-', 'n', 'a'],\n",
       " ['a', 'k', 'h', '-', 's', 'h', 'm', 'a', 'r', 'e', 'h', 'a'],\n",
       " ['a', 'k', 'h', '-', 's', 'h', 'e', 'k', 'e', 'r'],\n",
       " ['a', 'k', 'h', '-', 's', 'h', 'h', 't', 'a', 'y', 'i', 'm'],\n",
       " ['a', 'k', 'h', '-', 's', 'h', 'a', 'v', 'a'],\n",
       " ['a', 'k', 'h', '-', 't', 'o', 'v'],\n",
       " ['a', 'k', 'h', '-', 'y', 'h', 'i'],\n",
       " ['a', 'k', 'h', '-', 'z', 'a', 'r', 'u'],\n",
       " ['e', 'k', 'a', 's'],\n",
       " ['e', 'k', 'o', 's'],\n",
       " ['a', 'k', 'i', 's', 'e', 'c', 'h', 'a'],\n",
       " ['a', 'k', 'i', 's', 'e', 'm'],\n",
       " ['a', 'k', 'i', 's', 'u'],\n",
       " ['a', 'k', 'a', 'v'],\n",
       " ['a', 'k', 'b', 'a', 'r'],\n",
       " ['a', 'k', 'a', 'b', 'e', 't', 'h'],\n",
       " ['a', 'k', 'a', 'b', 'e', 'd', 'k', 'h', 'a'],\n",
       " ['i', 'k', 'a', 'b', 'e', 'd', 'a'],\n",
       " ['a', 'k', 'b', 'a', 'r'],\n",
       " ['e', 'k', 'a', 'b', 'e', '֑', 'd'],\n",
       " ['a', 'k', 'b', 'i', 'd'],\n",
       " ['a', 'k', 'b', 'i', 'd', 'a', 't'],\n",
       " ['a', 'k', 'a', 'd'],\n",
       " ['e', 'k', 'd', 'e', 'n'],\n",
       " ['a', 'k', 'a', 'k', 'h', 'e', 'd'],\n",
       " ['a', 'k', 'k', 'h', 'i', 's', 'h'],\n",
       " ['u', 'k', 'a', 'l'],\n",
       " ['a', 'k', 'h', 'l', 'a', '-', 't', 'i', 'n', 'a'],\n",
       " ['e', 'k', 'h', 'a', 'l', '-', 'b', 'n', 'i'],\n",
       " ['e', 'k', 'h', 'a', 'l', '-', 'l', 'e', 'k', 'h', 'e', 'm'],\n",
       " ['a', 'k', 'a', 'l', 'b', 'e'],\n",
       " ['a', 'k', 'a', 'l', 'e', '-', 'b', 'a', 'm'],\n",
       " ['a', 'k', 'h', 'a', 'l', 'n', 'a'],\n",
       " ['a', 'k', 'h', 'a', 'l', 'n', 'u', 'm'],\n",
       " ['a', 'k', 'h', 'a', 'l', 'a', 't', 'c', 'h', 'a'],\n",
       " ['a', 'k', 'a', 'l', 't', 'e', 'h'],\n",
       " ['a', 'k', 'a', 'l', 'a', 't', 'u'],\n",
       " ['a', 'k', 'a', 'l', 't', 'u', 'n'],\n",
       " ['i', 'k', 'h', 'l', 'u', 'h', 'i'],\n",
       " ['i', 'k', 'h', 'l', 'u', 'l'],\n",
       " ['a', 'k', 'h', 'a', 'l', 'u', 'm'],\n",
       " ['a', 'k', 'h', 'a', 'l', 'u', 'n', 'i'],\n",
       " ['u', 'k', 'h', 'l', 'o', 's', 'a', 'k', 'h'],\n",
       " ['u', 'k', 'h', 'l', 'u', 's', 'i', 'y', 'h'],\n",
       " ['u', 'k', 'h', 'l', 'u', 's', 'e', 'h', 'e', 'n'],\n",
       " ['a', 'k', 'h', 'l', 'e', 'h'],\n",
       " ['a', 'k', 'h', 'l', 'e', 'h', 'o', 'n'],\n",
       " ['u', 'k', 'm', 'a', 'n', 'i', 'u', 't'],\n",
       " ['a', 'k', 'h', 'm', 'a', 'r'],\n",
       " ['u', 'k', 'h', 'm', 't', 'a'],\n",
       " ['u', 'k', 'a', 'm'],\n",
       " ['i', 'k', 'a', 'n', 'a', 'a'],\n",
       " ['a', 'k', 'a', 'n', 'k', 'h', 'a'],\n",
       " ['a', 'k', 'a', 'n', 'e', 'h', 'u'],\n",
       " ['a', 'k', 'h', 'n', 'a', 's', 'h', 'u'],\n",
       " ['a', 'k', 'e', 'n', 'u'],\n",
       " ['a', 'k', 'h', 'n', 'i', 'a'],\n",
       " ['a', 'k', 'h', 'n', 'i', 's'],\n",
       " ['e', 'k', 'p', 'l', 'e', 'm'],\n",
       " ['a', 'k', 'p', 'a', 'l', 'u'],\n",
       " ['e', 'k', 'p', 'r', 'e', 'n', 'u'],\n",
       " ['a', 'k', 'a', 'p', 'a', 'r', 'a', 't'],\n",
       " ['i', 'k', 'p', 'a', 't', 'i'],\n",
       " ['i', 'k', 'p', 'a', 't', 'i', 't'],\n",
       " ['a', 'k', 'p', 'e', 'y', 'h'],\n",
       " ['a', 'k', 'p', 'y', 'a', 'y', 'n'],\n",
       " ['a', 'k', 'a', 'r', 'a', 'i'],\n",
       " ['a', 'c', 'h', 'r', 'a', 'u'],\n",
       " ['a', 'k', 'r', 'a', 'u', 't', 'a'],\n",
       " ['a', 'k', 'a', 'r', 'e', 'y', 'h'],\n",
       " ['a', 'k', 'a', 'r', 'g', 'a'],\n",
       " ['a', 'k', 'r', 'e', 's', 'a'],\n",
       " ['a', 'c', 'h', 'r', 'o', 'm', 'a', 't', 'o', 'p', 's', 'y', 'a'],\n",
       " ['a', 'c', 'h', 'r', 'o', 'm', 'a', 't', 'i'],\n",
       " ['a', 'k', 'h', 'e', 'r', 'o', 'n'],\n",
       " ['a', 'c', 'h', 'r', 'u', 'z'],\n",
       " ['i', 'k', 'a', 'r', 'e', 'y', 'c', 'h', 'e', 'm'],\n",
       " ['a', 'c', 'h', 'r', 'i', 'a', 'k', 'e', 'n', 'u'],\n",
       " ['a', 'c', 'h', 'r', 'i', 'z', 'a', 't'],\n",
       " ['a', 'c', 'h', 'r', 'i', 'z', 'u'],\n",
       " ['i', 'k', 's', 'a', 'l'],\n",
       " ['a', 'k', 's', 'a', 'd', 'r', 'a', 'o', 't'],\n",
       " ['a', 'k', 's', 'a', 'd', 'r', 'a', 'i', 'n'],\n",
       " ['a', 'k', 's', 'a', 'd', 'r', 'a', 't'],\n",
       " ['a', 'k', 's', 'a', 'd', 'r', 'o', 't'],\n",
       " ['a', 'k', 's', 'a', 'd', 'r', 'i', 'n'],\n",
       " ['a', 'k', 'a', 's', 'e'],\n",
       " ['e', 'k', 's', 'e', 'l', 'a', 'n', 't', 's'],\n",
       " ['a', 'k', 's', 'n', 'a', 'i'],\n",
       " ['a', 'k', 's', 'n', 'a', 'i', 'm'],\n",
       " ['a', 'k', 's', 'a', 'n', 'a', 'i', 'n'],\n",
       " ['a', 'k', 'a', 's', 'e', 'n', 'u'],\n",
       " ['a', 'k', 's', 'a', 'n', 'y', 'a'],\n",
       " ['a', 'k', 's', 'a', 'n', 'y', 'a'],\n",
       " ['a', 'k', 'h', 's', 'a', 'n', 'y', 'u', 't'],\n",
       " ['i', 'k', 's', 'e', 'n'],\n",
       " ['e', 'k', 's', 'p', 'l', 'o', 'a', 't', 'a', 't', 's', 'i', 'y', 'h'],\n",
       " ['e', 'k', 's', 'p', 'r', 'e', 's'],\n",
       " ['e', 'k', 's', 'p', 'r', 'o', 'm', 't'],\n",
       " ['a', 'k', 'h', 's', 'a', 'r', 'h'],\n",
       " ['i', 'k', 's', 'u', 'n'],\n",
       " ['e', 'k', 's', 'o', 'f'],\n",
       " ['e', 'k', 's', 'o', 't', 'i'],\n",
       " ['e', 'k', 's', 'o', 't', 'y', 'i', 'm'],\n",
       " ['a', 'k', 's', 'i', 'p', 'a'],\n",
       " ['a', 'k', 's', 'i', 'f', 'n', 'a'],\n",
       " ['a', 'k', 's', 'i', 'f', 't', 'a', 'e', 'h'],\n",
       " ['a', 'k', 's', 'y', 'o', 'm'],\n",
       " ['a', 'k', 's', 'y', 'o', 'm', 'o', 't'],\n",
       " ['a', 'k', 'h', 's', 'h', 'l', 'e', 'y', 'h'],\n",
       " ['a', 'k', 'h', 's', 'h', 'a', 'f'],\n",
       " ['a', 'k', 'h', 's', 'h', 'i', 'l', 'u'],\n",
       " ['a', 'k', 'h', 'e', 't'],\n",
       " ['e', 'k', 'h', 't', 'a', 'a', 'v', '-'],\n",
       " ['i', 'k', 'h', 't', 'a', 'v', 'u'],\n",
       " ['a', 'k', 't', 'e', 'f', 'a'],\n",
       " ['a', 'k', 'i', 't', 'p', 'a', 'i'],\n",
       " ['a', 'k', 'i', 't', 'p', 'e'],\n",
       " ['a', 'k', 'a', 't', 'p', 'i', 'k', 'h'],\n",
       " ['a', 'k', 'i', 't', 'r', 'a'],\n",
       " ['a', 'k', 'a', 't', 'r', 'e', 'h'],\n",
       " ['a', 'k', 'h', 't', 'a', 'r', 'i', 'e'],\n",
       " ['a', 'k', 'a', 't', 'r', 'i', 'e', 'l'],\n",
       " ['e', 'k', 'h', 't', 'a', 'o', 't'],\n",
       " ['a', 'k', 't', 'o'],\n",
       " ['a', 'k', 't', 'i', 'v', 'a'],\n",
       " ['a', 'k', 'h', 't', 'a', 'i', 'v', 'u'],\n",
       " ['a', 'k', 't', 'l'],\n",
       " ['a', 'k', 't', 'y', 'r', 'k', 'h'],\n",
       " ['a', 'k', 'a', 't', 'i', 's'],\n",
       " ['i', 'k', 't', 'i', 'o', 's'],\n",
       " ['a', 'k', 'o', 'v', 'e', 's'],\n",
       " ['a', 'k', 'u', 'l', 'a'],\n",
       " ['a', 'k', 'h', 'o', 'l', 'k', 'h'],\n",
       " ['a', 'k', 'h', 'o', 'l', 'c', 'h', 'e', 'm'],\n",
       " ['a', 'k', 'u', 'l', 'h', 'u'],\n",
       " ['a', 'k', 'h', 'o', 'l', 'e', 'k', 'h', 'o', 'n'],\n",
       " ['a', 'k', 'h', 'u', 'f'],\n",
       " ['a', 'k', 'o', 's'],\n",
       " ['a', 'k', 'h', 'o', 't'],\n",
       " ['a', 'k', 'v', 'u', 'n'],\n",
       " ['a', 'k', 'h', 'u', 'a', 'v', 'n'],\n",
       " ['a', 'k', 'e'],\n",
       " ['a', 'k', 'a', 'y', 'a'],\n",
       " ['e', 'k', 'i', 'd', 'n', 'a'],\n",
       " ['a', 'k', 'y', 'a'],\n",
       " ['a', 'k', 'h', 'i', 'l', 'n', 'a'],\n",
       " ['a', 'k', 'h', 'i', 'l', 'a', 't', 'a', 'h'],\n",
       " ['a', 'k', 'i', 'l', 'a', 't', 'o'],\n",
       " ['a', 'k', 'h', 'i', 'l', 'u'],\n",
       " ['a', 'k', 'h', 'i', 'l', 'o', 't', 'a', 'v'],\n",
       " ['a', 'k', 'h', 'i', 'n', 'a'],\n",
       " ['a', 'k', 'i', 'r'],\n",
       " ['a', 'k', 'h', 'z'],\n",
       " ['a', 'k', 'h', 'z', 'r', 'a', 'i', 'n'],\n",
       " ['a', 'k', 'h', 'z', 'a', 'r', 'i', 't'],\n",
       " ['a', 'k', 'h', 'z', 'r', 'i', 'i'],\n",
       " ['a', 'k', 'h', 'z', 'a', 'v', 'a', 'y', 'a'],\n",
       " ['a', 'k', 'a', 'z', 'y', 'a'],\n",
       " ['a', 'k', 'h', 'z', 'i', 'v'],\n",
       " ['a', 'k', 'h', 'z', 'i', 'v', 'a'],\n",
       " ['a', 'd', 'a'],\n",
       " ['e', 'd', 'a', 'g'],\n",
       " ['a', 'd', 'a', 'l', 'f'],\n",
       " ['a', 'd', 'a', 'm', 'o'],\n",
       " ['a', 'd', 'a', 'n', 'e', 'i'],\n",
       " ['a', 'd', 'a', 'r', 'l', 'y', 'a'],\n",
       " ['a', 'd', 'a', 't', 'a'],\n",
       " ['a', 'd', 'u', 'e', 'l', 'a'],\n",
       " ['a', 'd', 'u', 'k', 'm', 'i', 'n', 'a'],\n",
       " ['a', 'd', 'o', 'r', 'a', 'y', 't', 'a'],\n",
       " ['a', 'd', 'e', 'i', 'n'],\n",
       " ['e', 'd', 'a', 'a', 's', 'n', 'i'],\n",
       " ['e', 'd', 'a', 'e', 'n', 'a'],\n",
       " ['a', 'd', 'e', 'r', 'n'],\n",
       " ['a', 'd', 'a', 't', 'i', 'k', 'h'],\n",
       " ['a', 'd', 'a', 't', 'a', 'y', 'h', 'u'],\n",
       " ['a', 'd', 'a', 't', 'i', 'n'],\n",
       " ['i', 't', 'h', 'a'],\n",
       " ['a', 'd', 'v', 'a', 'i', 't', 'a'],\n",
       " ['a', 'd', 'b', 'h', 'e', 'y', 'h'],\n",
       " ['e', 'd', 'e', 'b', 'e'],\n",
       " ['i', 'd', 'a', 'b', 'k', 'a', 'n'],\n",
       " ['a', 'd', 'b', 'k', 'u', 't', 'a'],\n",
       " ['i', 'd', 'b', 'a', 'k', 'i', 'n'],\n",
       " ['a', 'd', 'v', 'e', 'r', 'b', 'y', 'a', 'l', 'i'],\n",
       " ['e', 'd', 'b', 'e', 'r', 'g'],\n",
       " ['a', 'd', 'a', 'b', 'r', 'a', '-', 'n', 'a'],\n",
       " ['a', 'd', 'i', 'v', 'r', 'e', 'i'],\n",
       " ['a', 'd', 'b', 'r', 'e', 'y', 'h'],\n",
       " ['a', 'd', 'a', 'b', 'r', 'i', 'n', 'a', 'k', 'h'],\n",
       " ['a', 'd', 'h', 'v', 'a', 'r', 'a', 'v'],\n",
       " ['a', 'd', 'b', 'u', 'r', 'e', 'i'],\n",
       " ['a', 'd', 'k', 'a', 'r', 't', 'a', 'n'],\n",
       " ['a', 'd', 'k', 'r', 'e', 'y', 'h'],\n",
       " ['a', 'd', 'i', 'k', 'h', 't', 'u', 'v', 'e'],\n",
       " ['i', 'd', 'a', 'k', 'u'],\n",
       " ['e', 'd', 'k', 'o', 'r'],\n",
       " ['a', 'd', 'k', 'i', 'r'],\n",
       " ['i', 'd', 'a', 'k', 'a', 'y', 'u'],\n",
       " ['a', 'd', 'a', 'd'],\n",
       " ['e', 'd', 'a', 'd', 'e'],\n",
       " ['a', 'd', 'u', 'd', 'u', 'r', 'i'],\n",
       " ['a', 'd', 'a', 'g', 'h'],\n",
       " ['e', 'd', 'g', 'a', 'r'],\n",
       " ['e', 'd', 'j', 'a', 'a', 'g'],\n",
       " ['e', 'd', 'j', 'v', 'e', 'u', 'r'],\n",
       " ['e', 'd', 'g', 'a'],\n",
       " ['e', 'd', 'g', 'a', 'r'],\n",
       " ['a', 'd', 'h', 'a', 'm'],\n",
       " ['e', 'd', 'h', 'a', 'r'],\n",
       " ['e', 'd', 'h', 'a', 'r', 'a'],\n",
       " ['a', 'd', 'h', 'o'],\n",
       " ['a', 'd', 'h', 'a', 'v', 'a'],\n",
       " ['a', 'd', 'h', 'v', 'a', 'r', 'y', 'u'],\n",
       " ['a', 'd', 'h', 'a', 'v', 'o'],\n",
       " ['a', 'd', 'h', 'i', 'c', 'h', 'i', 'y', 't', 'a', 'h'],\n",
       " ['a', 'd', 'k', 'h', 'a', 'l', 'a'],\n",
       " ['a', 'd', 'k', 'h', 'a', 'n', 'a', 'n', 'i'],\n",
       " ['i', 'd', 'a', 'k', 'h', 'y', 'e', 'h'],\n",
       " ['i', 'd', 'a', 'k', 'h', 'y', 'a', 'y', 'a'],\n",
       " ['i', 'd', 'a', 'k', 'h', 'y', 'a', 'y', 'n'],\n",
       " ['a', 'd', 'l', 'a'],\n",
       " ['i', 'd', 'l', 'e', 'v'],\n",
       " ['a', 'd', 'a', 'l', 'b', 'e', 'r', 'o', 'n'],\n",
       " ['a', 'd', 'e', 'l', 'f', 'i', 'n', 'a'],\n",
       " ['a', 'd', 'l', 'e', 'k'],\n",
       " ['a', 'd', 'l', 'k', 'u', 't', 'a'],\n",
       " ['a', 'd', 'l', 'a', 'k', 'u', 't', 'a', 'k', 'h'],\n",
       " ['a', 'd', 'l', 'r', 'i', 'a', 'n', 'i'],\n",
       " ['a', 'd', 'a', 'l', 's', 'e', 'n', 'i'],\n",
       " ['e', 'd', 'e', 'l', 't', 'e', 'k'],\n",
       " ['a', 'd', 'l', 'v', 'a', 'y', 's'],\n",
       " ['a', 'd', 'a', 'l', 'y', 'a'],\n",
       " ['i', 'd', 'l', 'i', 'b'],\n",
       " ['a', 'd', 'e', 'l', 'y', 'n', 'u', 't'],\n",
       " ['a', 'd', 'l', 'i', 'k', 'a'],\n",
       " ['a', 'd', 'l', 'i', 'k', 'a', 't'],\n",
       " ['a', 'd', 'l', 'i', 'k', 'u'],\n",
       " ['e', 'd', 'e', 'l', 'i', 's', 't'],\n",
       " ['a', 'd', 'm', 'a'],\n",
       " ['i', 'd', 'm', 'a', 'k', 'u'],\n",
       " ['a', 'd', 'm', 'a', 'd', 'a'],\n",
       " ['a', 'd', 'a', 'm', 'd', 'a', 'm', 'o', 't'],\n",
       " ['a', 'd', 'a', 'm', 'd', 'a', 'm', 'i', 'm'],\n",
       " ['a', 'd', 'm', 'g', 'a', 'r', 'm', 'i', 't', 'u'],\n",
       " ['a', 'd', 'a', 'm', 'a', '-', 'a', 'd', 'm', 'a', 't', 'i'],\n",
       " ['a', 'd', 'a', 'm', 'e', '-', 'l', 'a', 'k', 'h'],\n",
       " ['e', 'd', 'a', 'm', 'e', 'h'],\n",
       " ['a', 'd', 'm', 'h', 'o', 'n'],\n",
       " ['a', 'd', 'a', 'm', 'a', 'k', 'h', 's', 'e', 'v'],\n",
       " ['a', 'd', 'a', 'm', 'i', 'l', 'h'],\n",
       " ['e', 'd', 'a', 'm', 'a', 'm', 'e'],\n",
       " ['a', 'd', 'm', 'e', 'm', 'e', 't'],\n",
       " ['e', 'd', 'm', 'e', 'n', 'd', 's'],\n",
       " ['a', 'd', 'm', 'e', 'n', 'e', 't'],\n",
       " ['a', 'd', 'm', 'o', 'n', 'i'],\n",
       " ['a', 'd', 'i', 'm', 'r', 'a', 'k', 'a', 'k'],\n",
       " ['i', 'd', 'a', 'm', 'a', 'r', 'a', 't', 's'],\n",
       " ['a', 'd', 'a', 'm', 's'],\n",
       " ['a', 'd', 'm', 'a', 't', '-', 'a', 'f', 'a', 'r'],\n",
       " ['a', 'd', 'm', 'a', 't', 'a', 'h'],\n",
       " ['a', 'd', 'm', 'a', 't', 'e', 'h', 'u'],\n",
       " ['a', 'd', 'm', 'a', 't', 'h', 'o', 'n'],\n",
       " ['a', 'd', 'm', 'a', 't', 'e', 'n', 'u'],\n",
       " ['a', 'd', 'm', 'a', 't', 'i'],\n",
       " ['a', 'd', 'm', 'a', '֣', 't', 'c', 'h', 'a', '֔'],\n",
       " ['a', 'd', 'm', 'a', 't', 'z', 'l', 'i', 'n', 'a'],\n",
       " ['a', 'd', 'a', 'm', 'e', 't', 's'],\n",
       " ['a', 'd', 'm', 'o', 'r'],\n",
       " ['a', 'd', 'a', 'm', 'o', 'v'],\n",
       " ['a', 'd', 'a', 'm', 'u', 'o', 'v', 'y', 't', 's'],\n",
       " ['a', 'd', 'm', 'u', 'm', 'i', 't'],\n",
       " ['a', 'd', 'm', 'o', 'n', 'i'],\n",
       " ['a', 'd', 'm', 'o', 'n', 'i', 'y', 'h'],\n",
       " ['a', 'd', 'm', 'o', 'n', 'i', 'm'],\n",
       " ['a',\n",
       "  'd',\n",
       "  'm',\n",
       "  'o',\n",
       "  'n',\n",
       "  'i',\n",
       "  't',\n",
       "  'u',\n",
       "  'd',\n",
       "  'h',\n",
       "  'l',\n",
       "  'n',\n",
       "  't',\n",
       "  'y',\n",
       "  'u',\n",
       "  't'],\n",
       " ['a', 'd', 'm', 'o', 'k', 'd', 'a', 'k', 'h'],\n",
       " ['a', 'd', 'm', 'u', 't', 'h', 'o', 'n'],\n",
       " ['a', 'd', 'm', 'o', 't', 'a', 'y', 'i', 'k', 'h'],\n",
       " ['a', 'd', 'm', 'y', 'a'],\n",
       " ['a', 'd', 'u', 'm', 'e', '-', 'z', 'a', 'k', 'a', 'n'],\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"train\"][1][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_translation(model, test_data, batch_size):\n",
    "#     batch_size = \n",
    "    result = []\n",
    "    for pos in range(0, test_data.shape[0], batch_size):\n",
    "        batch, mask = for_translation(*src.convert_batch(test_data[pos:pos + batch_size]))\n",
    "        translated = model.translate(batch, mask)\n",
    "        result.extend(translated)\n",
    "    \n",
    "    \n",
    "    real_result = []\n",
    "    for sent in result:\n",
    "        sent = sent.split(\" \")[1:-1]\n",
    "        real_result.append(\" \".join(sent))\n",
    "    return real_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "translated = run_translation(s2s, batch_sampler.test[0], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"translated_test.txt\", \"w\") as f:\n",
    "    for sent in translated:\n",
    "        f.write(sent + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([\"'a\", '\"', 'h', 'y', 'm_']),\n",
       "       list([\"'a\", \"'a\", \"'a\", 'q', 'th', 'l']),\n",
       "       list([\"'a\", \"'a\", 'b', 'd']), list([\"'a\", \"'a\", 'b', 'w', 'h']),\n",
       "       list([\"'a\", \"'a\", 'kh', 'r']),\n",
       "       list([\"'a\", \"'a\", 'm', 'l', 'q', 'y']), list([\"'a\", \"'a\", 'n']),\n",
       "       list([\"'a\", \"'a\", 'r', 'w', 'g']),\n",
       "       list([\"'a\", \"'a\", 'r', 'w', 'q', 'l', 'y', 'n', 'w', 'sh', 'q', 'w', 'ph_']),\n",
       "       list([\"'a\", \"'a\", 't', 'm', \"'a\", 'r', \"'a\", 'm', 'h'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sampler.test[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [torch]",
   "language": "python",
   "name": "Python [torch]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
