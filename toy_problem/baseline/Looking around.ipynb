{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "use_cuda = True\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_utils import pad_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "BOS_TOKEN = 1\n",
    "NAN_TOKEN = 2\n",
    "EOS_TOKEN = 3\n",
    "SPECIAL_TOKENS = 4\n",
    "OCCURING_SPECIAL_TOKENS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class DatasetFilesLocation:\n",
    "#     def __init__(self, train, dev, test, tokens):\n",
    "#         self.train = train\n",
    "#         self.dev = dev\n",
    "#         self.test = test\n",
    "#         self.tokens = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# src_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/src.train.txt',\n",
    "#     dev='../preprocessed/he-en/src.dev.txt',\n",
    "#     test='../preprocessed/he-en/src.test.txt',\n",
    "#     tokens='../preprocessed/he-en/src.tokens.txt')\n",
    "\n",
    "# trg_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/tgt.train.txt',\n",
    "#     dev='../preprocessed/he-en/tgt.dev.txt',\n",
    "#     test='../preprocessed/he-en/tgt.test.txt',\n",
    "#     tokens='../preprocessed/he-en/tgt.tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, tokens_file_path):\n",
    "        self.idx2word = defaultdict(lambda: \"<NAN/>\")\n",
    "        self.word2idx = defaultdict(lambda: NAN_TOKEN)\n",
    "        with open(tokens_file_path) as tokens_file:\n",
    "            tokens = tokens_file.readlines()\n",
    "            for word, idx in map(lambda x: x.strip().split(), tokens):\n",
    "                idx = int(idx) + SPECIAL_TOKENS\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "            assert PAD_TOKEN not in self.idx2word\n",
    "            assert BOS_TOKEN not in self.idx2word\n",
    "            assert EOS_TOKEN not in self.idx2word\n",
    "            for word, idx in [('<PAD/>', PAD_TOKEN), ('<S>', BOS_TOKEN),\n",
    "                              ('</S>', EOS_TOKEN), ('<NAN/>', NAN_TOKEN)]:\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "    \n",
    "    def convert(self, sentence):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.strip().split()\n",
    "        return [BOS_TOKEN] + list(map(lambda word: self.word2idx[word], sentence)) + [EOS_TOKEN]\n",
    "    \n",
    "    def convert_batch(self, sents):\n",
    "        \n",
    "        batch_max_length = 0\n",
    "        for sent in sents:\n",
    "            batch_max_length = max(batch_max_length, len(sent))\n",
    "            \n",
    "#         print(batch_max_length)\n",
    "        \n",
    "        result = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        mask = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        \n",
    "        for sent_id, sent in enumerate(sents):\n",
    "            sent = sent[:batch_max_length]\n",
    "            current = self.convert(sent)\n",
    "            result[sent_id, :len(current)] = current\n",
    "            mask[sent_id, :len(current)] = 1.0\n",
    "            \n",
    "        return result, mask\n",
    "    \n",
    "    def input_size(self):\n",
    "        return len(self.idx2word.keys())\n",
    "    \n",
    "    def output_size(self):\n",
    "        return len(self.idx2word.keys())# - SPECIAL_TOKENS + OCCURING_SPECIAL_TOKENS\n",
    "    \n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]# + SPECIAL_TOKENS - OCCURING_SPECIAL_TOKENS]\n",
    "    \n",
    "    def get_eos(self):\n",
    "        return EOS_TOKEN #OCCURING_SPECIAL_TOKENS - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as file:\n",
    "        return list(map(lambda s: s.strip().split(\" \"), file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_problem(path, n_sents=None):\n",
    "    modes = [\"train\",  \"dev\", \"test\"]\n",
    "    datasets = [\"src\", \"tgt\"]\n",
    "    file_template = \"{}.{}.txt\"\n",
    "    \n",
    "    result = {}\n",
    "    for mode in modes:\n",
    "        src = read_file(os.path.join(path, file_template.format(\"src\", mode)))\n",
    "        tgt = read_file(os.path.join(path, file_template.format(\"tgt\", mode)))\n",
    "        \n",
    "        assert len(src) == len(tgt)\n",
    "        \n",
    "#         result[mode] = list(zip(src, tgt))\n",
    "        if n_sents is not None:\n",
    "            result[mode] = (src[:n_sents], tgt[:n_sents])\n",
    "        else:\n",
    "            result[mode] = (src, tgt)\n",
    "        \n",
    "    src_lang = Lang(os.path.join(path, file_template.format(\"src\", \"tokens\")))\n",
    "    tgt_lang = Lang(os.path.join(path, file_template.format(\"tgt\", \"tokens\")))\n",
    "    return result, src_lang, tgt_lang\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d, src, tgt = read_problem(\"../preprocessed/he-en/\", n_sents=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183050"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183050"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  x = self.train[0][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "# y = self.train[1][self.train_indices[self.position:self.position + self.batch_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class BatchSampler:\n",
    "    def __init__(self, dataset, src_lang, tgt_lang, batch_size):\n",
    "        self.train = np.array(dataset[\"train\"])\n",
    "        self.dev = np.array(dataset[\"dev\"])\n",
    "        self.test = np.array(dataset[\"test\"])\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        self.train_indices = np.random.permutation(np.arange(len(self.train[0]), dtype=np.int32))\n",
    "        \n",
    "        \n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train)//self.batch_size + 1\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.position = 0\n",
    "        return self\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = 0\n",
    "        \n",
    "    \n",
    "    def get_batch(self, x, y):\n",
    "        x, x_mask = self.src_lang.convert_batch(x)\n",
    "        y, y_mask = self.tgt_lang.convert_batch(y)\n",
    "        \n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        y = Variable(torch.from_numpy(y.astype(np.int64))).contiguous()\n",
    "        y_mask = Variable(torch.from_numpy(y_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        return (x, x_mask), (y, y_mask)\n",
    "    \n",
    "        \n",
    "    def __next__(self):\n",
    "            if self.position >= len(self.train[0]):\n",
    "                raise StopIteration()\n",
    "                \n",
    "            x = self.train[0][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "            y = self.train[1][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "            \n",
    "            self.position += self.batch_size\n",
    "            return self.get_batch(x, y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def form_batch_variable(lang, sentences):\n",
    "#     sentences = list(map(lang.convert, sentences))\n",
    "#     sentences = sorted(sentences, key=len, reverse=True)\n",
    "#     lengths = list(map(len, sentences))\n",
    "#     sentences = list(map(lambda sentence: Variable(torch.LongTensor(sentence)), sentences))\n",
    "#     batch = pad_sequence(sentences, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#     if use_cuda:\n",
    "#         batch = batch.cuda()\n",
    "#     return torch.nn.utils.rnn.pack_padded_sequence(batch, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.max_length = 100\n",
    "        self.enc_hidden_size = 128\n",
    "        self.enc_emb_size = 128\n",
    "        self.enc_layers = 1\n",
    "        self.enc_dropout = 0.1\n",
    "        self.enc_bidirectional = True\n",
    "        \n",
    "        self.dec_hidden_size = 128\n",
    "        self.dec_emb_size = self.enc_emb_size\n",
    "        self.dec_layers = 1\n",
    "        self.dec_dropout = 0.1\n",
    "        self.dec_bidirectional = True\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.learning_rate = 0.001\n",
    "        self.clip = 0.25\n",
    "     \n",
    "    def get_enc_output_size(self):\n",
    "        return self.enc_hidden_size * (int(self.enc_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_output_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_state_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1) * self.dec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,\n",
    "                                      embedding_dim=hp.enc_emb_size,\n",
    "                                      padding_idx=PAD_TOKEN)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=hp.enc_emb_size,\n",
    "                          hidden_size=hp.enc_hidden_size,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.enc_dropout,\n",
    "                          num_layers=hp.enc_layers,\n",
    "                          bidirectional=hp.enc_bidirectional)\n",
    "        self.num_directions = (int(hp.enc_bidirectional) + 1)\n",
    "        self.num_layers = hp.enc_layers\n",
    "        self.hidden_size = hp.enc_hidden_size\n",
    "\n",
    "    def forward(self, input_batch, hidden=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        if (hidden is None):\n",
    "            hidden = self.init_hidden(input_batch.size(0))\n",
    "        embedded = self.embedding(input_batch).contiguous()\n",
    "#         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, _ = self.gru(embedded, hidden)\n",
    "#         outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             outputs, padding_value=PAD_TOKEN, batch_first=True)\n",
    "#         print(outputs.size())\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mask(lengths):\n",
    "#     batch_size = lengths.size(0)\n",
    "#     max_len = lengths[0]\n",
    "#     time = torch.arange(max_len).repeat(batch_size, 1)\n",
    "#     lengths = lengths.view(-1, 1).type(torch.FloatTensor)\n",
    "#     if (use_cuda):\n",
    "#         time = time.cuda()\n",
    "#         lengths = lengths.cuda()\n",
    "\n",
    "#     mask = Variable((time < lengths).type(torch.FloatTensor))\n",
    "#     if (use_cuda):\n",
    "#         return mask.cuda()\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hp.get_enc_output_size() + hp.get_dec_state_size(), 1)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers * directions, B, HD)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (B, T, HE)\n",
    "        :param encoder_output_lengths:\n",
    "            lengths of encoded sentences, in shape (B,)\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        max_len = encoder_outputs.size(1)\n",
    "\n",
    "        hidden = hidden.transpose(0, 1).contiguous() # [B, l * d, HD]\n",
    "        hidden = hidden.view(batch_size, -1) # [B, HD * layers * directions]\n",
    "        hidden = hidden.repeat(max_len, 1, 1).transpose(0, 1) # [B, T, HD * layers * directions]\n",
    "        \n",
    "        energies = self.attn(torch.cat((hidden, encoder_outputs), -1)).view(batch_size, max_len) # [B, T, 1]\n",
    "\n",
    "        \n",
    "        energies = energies * mask\n",
    "        energies = F.softmax(energies)\n",
    "        energies = energies * mask\n",
    "        energies = energies / energies.sum(1).view(-1, 1) # [B, T]\n",
    "        \n",
    "        return (energies.view(batch_size, max_len, 1) * encoder_outputs).sum(1) #[B, HE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hp):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hp.dec_emb_size, padding_idx=PAD_TOKEN)\n",
    "        self.attn = Attn(hp)\n",
    "        self.gru = nn.GRU(input_size=hp.dec_emb_size + hp.get_enc_output_size(),\n",
    "                          hidden_size=hp.dec_hidden_size,\n",
    "                          num_layers=hp.dec_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.dec_dropout,\n",
    "                          bidirectional=hp.dec_bidirectional)\n",
    "        self.out = nn.Linear(hp.get_dec_output_size(), output_size)\n",
    "\n",
    "        self.num_layers = hp.dec_layers\n",
    "        self.num_directions = int(hp.dec_bidirectional) + 1\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hp.dec_hidden_size\n",
    "\n",
    "\n",
    "    def forward(self, input, encoder_outputs, mask, hidden=None):\n",
    "        \"\"\"\n",
    "            input: [B,]\n",
    "            encoder_outputs: [B, T, HE]\n",
    "            hidden: [B, layers * directions, HD]\n",
    "        \"\"\"\n",
    "        batch_size = input.size(0)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "#         embedded = self.embedding(input.view(-1, 1))\n",
    "        embedded = self.embedding(input)\n",
    "#         print(embedded.size())\n",
    "        context = self.attn(hidden, encoder_outputs, mask).view(batch_size, -1)\n",
    "#         print(context.size())\n",
    "        rnn_input = torch.cat((embedded, context), -1).view(batch_size, 1, -1)\n",
    "        \n",
    "#         print(\"RNN input\", rnn_input.size())\n",
    "        output, next_hidden = self.gru(rnn_input, hidden)\n",
    "        output = self.out(output).view(batch_size, self.output_size)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        \n",
    "        return output, next_hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, source_lang, target_lang, hp):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.encoder = EncoderRNN(source_lang.input_size(), hp)\n",
    "        self.decoder = DecoderRNN(target_lang.input_size(), target_lang.input_size(), hp)\n",
    "        self.max_length = hp.max_length\n",
    "        self.criterion = nn.NLLLoss(reduce=False, size_average=False)\n",
    "        \n",
    "#     def translate(self, input_seq):\n",
    "\n",
    "# #         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "# #             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "# #         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "# #         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "# #         mask = get_mask(encoder_output_lengths)\n",
    "        \n",
    "# #         batch_size = input_batch.size(0)\n",
    "        \n",
    "#         dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "#         if use_cuda:\n",
    "#             dec_input = dec_input.cuda()\n",
    "# #         max_length = min(self.max_length, 2 * encoder_output_lengths[0])\n",
    "#         hidden = None\n",
    "#         translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "#         for i in range(max_length):\n",
    "#             output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "#             _, output_idx = torch.max(output, -1)\n",
    "#             for j in range(batch_size):\n",
    "#                 if translations[j][-1] != target_lang.get_eos():\n",
    "#                     translations[j].append(output_idx[j].data[0])\n",
    "#             dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "#             if use_cuda:\n",
    "#                 dec_input = dec_input.cuda()\n",
    "#         return [' '.join(map(target_lang.get_word, elem)) for elem in translations]\n",
    "\n",
    "    def translate(self, input_batch, mask):\n",
    "        batch_size = input_batch.size()[0]\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "        word_indices = []\n",
    "#         outputs = []\n",
    "        \n",
    "        dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "        \n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        MAX_LENGTH = 100\n",
    "        translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "        converged = np.zeros(shape=(batch_size, ))\n",
    "        for i in range(MAX_LENGTH):     \n",
    "            output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "            _, output_idx = torch.max(output, -1)\n",
    "                \n",
    "            for j in range(batch_size):\n",
    "                if translations[j][-1] != self.target_lang.get_eos():\n",
    "                    translations[j].append(output_idx[j].data[0])\n",
    "                else:\n",
    "                    converged[j] = True\n",
    "            dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "            \n",
    "            if use_cuda:\n",
    "                dec_input = dec_input.cuda()\n",
    "            \n",
    "            \n",
    "            if np.all(converged):\n",
    "                break\n",
    "            \n",
    "         \n",
    "            \n",
    "#         return translations\n",
    "        return [' '.join(map(self.target_lang.get_word, elem)) for elem in translations]\n",
    "    \n",
    "    def forward(self, input_batch, mask, output_batch, out_mask):\n",
    "#         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "#         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "#         mask = get_mask(encoder_output_lengths)\n",
    "#         batch_size = input_batch.size(0)\n",
    "\n",
    "        \n",
    "#         if use_cuda:\n",
    "#             dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "#         output_batch, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(output_seq,\n",
    "#                                                                               batch_first=True,\n",
    "#                                                                               padding_value=PAD_TOKEN)\n",
    "#         output_lengths = torch.LongTensor(output_lengths)\n",
    "#         out_mask = get_mask(output_lengths)\n",
    "        loss = 0\n",
    "        outputs = []\n",
    "        for i in range(out_mask.size()[1] - 1):\n",
    "           \n",
    "            output, hidden = self.decoder(output_batch[:, i], encoder_outputs, mask=mask, hidden=hidden)\n",
    "            loss += (self.criterion(output, output_batch[:, i + 1]) * out_mask[:, i + 1]).sum()\n",
    "        \n",
    "        loss /= out_mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import gc\n",
    "def trainS2S(s2s, batch_sampler, hp):\n",
    "    s2s.train()\n",
    "#     losses = []\n",
    "#     hp.batch_size = 100\n",
    "#     assert(len(src) == len(trg))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(s2s.parameters(), lr=hp.learning_rate)\n",
    "    \n",
    "    for epoch_id in range(hp.n_epochs):\n",
    "#         batch_sampler.reset()\n",
    "        for batch_id, ((input, input_mask), (output, output_mask)) in tqdm.tqdm(enumerate(batch_sampler)):\n",
    "#         for i in tqdm.tqdm(range(0, len(src), hp.batch_size)):\n",
    "#             src_batch = form_batch_variable(source_lang, src[i : i + hp.batch_size])\n",
    "#             trg_batch = form_batch_variable(target_lang, trg[i : i + hp.batch_size])\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                input_mask = input_mask.cuda()\n",
    "                output = output.cuda()\n",
    "                output_mask = output_mask.cuda()\n",
    "\n",
    "\n",
    "            loss = s2s(input, input_mask, output, output_mask)\n",
    "#             if (batch_id // hp.batch_size) % 100 == 0:\n",
    "#                 print(loss.data[0])\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(s2s.parameters(), hp.clip)\n",
    "            optimizer.step()\n",
    "            if use_cuda:\n",
    "                losses.append(loss.cpu().data[0])\n",
    "            else:\n",
    "                 losses.append(loss.data[0])\n",
    "            \n",
    "            if (batch_id * batch_sampler.batch_size) % 1000 == 0:\n",
    "                display.clear_output(wait=True)\n",
    "                print(\"Last 10 loses mean\", np.mean(losses[-10:]))\n",
    "                plt.plot(losses)\n",
    "                plt.show()\n",
    "        \n",
    "        torch.save(s2s.state_dict(), \"last_state.ckpt\")\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_dataset = {\n",
    "    \"train\": ( [\"'a 'a d y r\", \"'a 'a h b ckh\"], [\"a a d i r\", \"e a h a v k h a\"]),\n",
    "    \"test\":None,\n",
    "    \"dev\":None\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(dummy_dataset, src, tgt, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 10 loses mean 0.46150257587432864\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f02c0b6c9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.88it/s]\n"
     ]
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.batch_size = 100\n",
    "hp.n_epochs = 20\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "if use_cuda:\n",
    "    s2s = s2s.cuda()\n",
    "losses = []\n",
    "losses = trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 128, padding_idx=0)\n",
       "    (gru): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 128, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(384, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch_sampler.train[batch_sampler.train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(d, src, tgt, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp = HyperParameters()\n",
    "hp.n_epochs = 5\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "if use_cuda:\n",
    "    s2s = s2s.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 10 loses mean 1.3611367106437684\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba2804f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "107it [00:21,  5.01it/s]"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "losses = trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s2s.load_state_dict(torch.load(\"last_state.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(s2s.state_dict(), \"last_state.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1f71c63ba2d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 128, padding_idx=0)\n",
       "    (gru): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 128, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(384, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_translation(x, x_mask):\n",
    "    if not use_cuda:\n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "    else:\n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous().cuda()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous().cuda()\n",
    "    \n",
    "    \n",
    "    return x, x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> a d i r </S>', '<S> a h a v a k h </S>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> t a s h e m a r - b a k h a n a t j a </S>', '<S> a h a v a k h </S>']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"k t v m - sh r ckh n k t v m\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     1     6     6    17    88    49     3\n",
       "     1     6     6    24    14    15     3\n",
       " [torch.cuda.LongTensor of size 2x7 (GPU 0)], Variable containing:\n",
       "     1     1     1     1     1     1     1\n",
       "     1     1     1     1     1     1     1\n",
       " [torch.cuda.FloatTensor of size 2x7 (GPU 0)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a a d i r', 'e a h a v k h a']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [torch]",
   "language": "python",
   "name": "Python [torch]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
