{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_utils import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "BOS_TOKEN = 1\n",
    "NAN_TOKEN = 2\n",
    "EOS_TOKEN = 3\n",
    "SPECIAL_TOKENS = 4\n",
    "OCCURING_SPECIAL_TOKENS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DatasetFilesLocation:\n",
    "    def __init__(self, train, dev, test, tokens):\n",
    "        self.train = train\n",
    "        self.dev = dev\n",
    "        self.test = test\n",
    "        self.tokens = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_files = DatasetFilesLocation(\n",
    "    train='../preprocessed/he-en/src.train.txt',\n",
    "    dev='../preprocessed/he-en/src.dev.txt',\n",
    "    test='../preprocessed/he-en/src.test.txt',\n",
    "    tokens='../preprocessed/he-en/src.tokens.txt')\n",
    "\n",
    "trg_files = DatasetFilesLocation(\n",
    "    train='../preprocessed/he-en/tgt.train.txt',\n",
    "    dev='../preprocessed/he-en/tgt.dev.txt',\n",
    "    test='../preprocessed/he-en/tgt.test.txt',\n",
    "    tokens='../preprocessed/he-en/tgt.tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, tokens_file_path):\n",
    "        self.idx2word = defaultdict(lambda: \"<NAN/>\")\n",
    "        self.word2idx = defaultdict(lambda: NAN_TOKEN)\n",
    "        with open(tokens_file_path) as tokens_file:\n",
    "            tokens = tokens_file.readlines()\n",
    "            for word, idx in map(lambda x: x.strip().split(), tokens):\n",
    "                idx = int(idx) + SPECIAL_TOKENS\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "            assert PAD_TOKEN not in self.idx2word\n",
    "            assert BOS_TOKEN not in self.idx2word\n",
    "            assert EOS_TOKEN not in self.idx2word\n",
    "            for word, idx in [('<PAD/>', PAD_TOKEN), ('<S>', BOS_TOKEN),\n",
    "                              ('</S>', EOS_TOKEN), ('<NAN/>', NAN_TOKEN)]:\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "    \n",
    "    def convert(self, sentence):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.strip().split()\n",
    "        return [BOS_TOKEN] + list(map(lambda word: self.word2idx[word], sentence)) + [EOS_TOKEN]\n",
    "    \n",
    "    def input_size(self):\n",
    "        return len(self.idx2word.keys())\n",
    "    \n",
    "    def output_size(self):\n",
    "        return len(self.idx2word.keys())# - SPECIAL_TOKENS + OCCURING_SPECIAL_TOKENS\n",
    "    \n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]# + SPECIAL_TOKENS - OCCURING_SPECIAL_TOKENS]\n",
    "    \n",
    "    def get_eos(self):\n",
    "        return EOS_TOKEN #OCCURING_SPECIAL_TOKENS - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def form_batch_variable(lang, sentences):\n",
    "    sentences = list(map(lang.convert, sentences))\n",
    "    sentences = sorted(sentences, key=len, reverse=True)\n",
    "    lengths = list(map(len, sentences))\n",
    "    sentences = list(map(lambda sentence: Variable(torch.LongTensor(sentence)), sentences))\n",
    "    batch = pad_sequence(sentences, batch_first=True, padding_value=PAD_TOKEN)\n",
    "    if use_cuda:\n",
    "        batch = batch.cuda()\n",
    "    return torch.nn.utils.rnn.pack_padded_sequence(batch, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.max_length = 100\n",
    "        self.enc_hidden_size = 128\n",
    "        self.enc_emb_size = 32\n",
    "        self.enc_layers = 1\n",
    "        self.enc_dropout = 0.1\n",
    "        self.enc_bidirectional = True\n",
    "        \n",
    "        self.dec_hidden_size = 128\n",
    "        self.dec_emb_size = 32\n",
    "        self.dec_layers = 1\n",
    "        self.dec_dropout = 0.1\n",
    "        self.dec_bidirectional = True\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.learning_rate = 0.001\n",
    "        self.clip = 0.25\n",
    "     \n",
    "    def get_enc_output_size(self):\n",
    "        return self.enc_hidden_size * (int(self.enc_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_output_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_state_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1) * self.dec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,\n",
    "                                      embedding_dim=hp.enc_emb_size,\n",
    "                                      padding_idx=PAD_TOKEN)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=hp.enc_emb_size,\n",
    "                          hidden_size=hp.enc_hidden_size,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.enc_dropout,\n",
    "                          num_layers=hp.enc_layers,\n",
    "                          bidirectional=hp.enc_bidirectional)\n",
    "        self.num_directions = (int(hp.enc_bidirectional) + 1)\n",
    "        self.num_layers = hp.enc_layers\n",
    "        self.hidden_size = hp.enc_hidden_size\n",
    "\n",
    "    def forward(self, input_batch, input_lengths, hidden=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        if (hidden is None):\n",
    "            hidden = self.init_hidden(input_batch.size(0))\n",
    "        embedded = self.embedding(input_batch)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, _ = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            outputs, padding_value=PAD_TOKEN, batch_first=True)\n",
    "        return outputs, output_lengths\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mask(lengths):\n",
    "    batch_size = lengths.size(0)\n",
    "    max_len = lengths[0]\n",
    "    time = torch.arange(max_len).repeat(batch_size, 1)\n",
    "    lengths = lengths.view(-1, 1).type(torch.FloatTensor)\n",
    "    if (use_cuda):\n",
    "        time = time.cuda()\n",
    "        lengths = lengths.cuda()\n",
    "\n",
    "    mask = Variable((time < lengths).type(torch.FloatTensor))\n",
    "    if (use_cuda):\n",
    "        return mask.cuda()\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hp.get_enc_output_size() + hp.get_dec_state_size(), 1)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers * directions, B, HD)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (B, T, HE)\n",
    "        :param encoder_output_lengths:\n",
    "            lengths of encoded sentences, in shape (B,)\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        max_len = encoder_outputs.size(1)\n",
    "\n",
    "        hidden = hidden.transpose(0, 1).contiguous() # [B, l * d, HD]\n",
    "        hidden = hidden.view(batch_size, -1) # [B, HD * layers * directions]\n",
    "        hidden = hidden.repeat(max_len, 1, 1).transpose(0, 1) # [B, T, HD * layers * directions]\n",
    "        \n",
    "        energies = self.attn(torch.cat((hidden, encoder_outputs), -1)).view(batch_size, max_len) # [B, T, 1]\n",
    "\n",
    "        \n",
    "        energies = energies * mask\n",
    "        energies = F.softmax(energies)\n",
    "        energies = energies * mask\n",
    "        energies = energies / energies.sum(1).view(-1, 1) # [B, T]\n",
    "        \n",
    "        return (energies.view(batch_size, max_len, 1) * encoder_outputs).sum(1) #[B, HE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hp):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hp.dec_emb_size, padding_idx=PAD_TOKEN)\n",
    "        self.attn = Attn(hp)\n",
    "        self.gru = nn.GRU(input_size=hp.dec_emb_size + hp.get_enc_output_size(),\n",
    "                          hidden_size=hp.dec_hidden_size,\n",
    "                          num_layers=hp.dec_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.dec_dropout,\n",
    "                          bidirectional=hp.dec_bidirectional)\n",
    "        self.out = nn.Linear(hp.get_dec_output_size(), output_size)\n",
    "\n",
    "        self.num_layers = hp.dec_layers\n",
    "        self.num_directions = int(hp.dec_bidirectional) + 1\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hp.dec_hidden_size\n",
    "\n",
    "\n",
    "    def forward(self, input, encoder_outputs, mask, hidden=None):\n",
    "        \"\"\"\n",
    "            input: [B,]\n",
    "            encoder_outputs: [B, T, HE]\n",
    "            hidden: [B, layers * directions, HD]\n",
    "        \"\"\"\n",
    "        batch_size = input.size(0)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "        embedded = self.embedding(input.view(-1, 1))\n",
    "        context = self.attn(hidden, encoder_outputs, mask).view(batch_size, 1, -1)\n",
    "        rnn_input = torch.cat((embedded, context), -1)\n",
    "    \n",
    "        output, next_hidden = self.gru(rnn_input, hidden)\n",
    "        output = self.out(output).view(batch_size, self.output_size)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        \n",
    "        return output, next_hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lang = Lang(tokens_file_path=src_files.tokens)\n",
    "target_lang = Lang(tokens_file_path=trg_files.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, source_lang, target_lang, hp):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.encoder = EncoderRNN(source_lang.input_size(), hp)\n",
    "        self.decoder = DecoderRNN(target_lang.input_size(), target_lang.output_size(), hp)\n",
    "        self.max_length = hp.max_length\n",
    "        self.criterion = nn.NLLLoss(reduce=False, size_average=False)\n",
    "        \n",
    "    def translate(self, input_seq):\n",
    "\n",
    "        input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "        encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "        encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "        mask = get_mask(encoder_output_lengths)\n",
    "        \n",
    "        batch_size = input_batch.size(0)\n",
    "        \n",
    "        dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        max_length = min(self.max_length, 2 * encoder_output_lengths[0])\n",
    "        hidden = None\n",
    "        translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "        for i in range(max_length):\n",
    "            output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "            _, output_idx = torch.max(output, -1)\n",
    "            for j in range(batch_size):\n",
    "                if translations[j][-1] != target_lang.get_eos():\n",
    "                    translations[j].append(output_idx[j].data[0])\n",
    "            dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "            if use_cuda:\n",
    "                dec_input = dec_input.cuda()\n",
    "        return [' '.join(map(target_lang.get_word, elem)) for elem in translations]\n",
    "    \n",
    "    def forward(self, input_seq, output_seq):\n",
    "        input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "        encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "        encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "        mask = get_mask(encoder_output_lengths)\n",
    "        batch_size = input_batch.size(0)\n",
    "        \n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "        output_batch, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(output_seq,\n",
    "                                                                              batch_first=True,\n",
    "                                                                              padding_value=PAD_TOKEN)\n",
    "        output_lengths = torch.LongTensor(output_lengths)\n",
    "        out_mask = get_mask(output_lengths)\n",
    "        loss = 0\n",
    "        outputs = []\n",
    "        for i in range(len(output_seq) - 1):\n",
    "            output, hidden = self.decoder(output_batch[:, i], encoder_outputs, mask=mask, hidden=hidden)\n",
    "            loss += (self.criterion(output, output_batch[:, i + 1]) * out_mask[:, i + 1]).sum()\n",
    "        \n",
    "        loss /= out_mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "def trainS2S(s2s, src, trg, hp):\n",
    "    s2s.train()\n",
    "    losses = []\n",
    "    hp.batch_size = 100\n",
    "    assert(len(src) == len(trg))\n",
    "    optimizer = torch.optim.Adam(s2s.parameters(), lr=hp.learning_rate)\n",
    "    for i in tqdm_notebook(range(0, len(src), hp.batch_size)):\n",
    "        src_batch = form_batch_variable(source_lang, src[i : i + hp.batch_size])\n",
    "        trg_batch = form_batch_variable(target_lang, trg[i : i + hp.batch_size])\n",
    "        loss = s2s(src_batch, trg_batch)\n",
    "        if (i // hp.batch_size) % 100 == 0:\n",
    "            print(loss.data[0])\n",
    "        losses.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm(s2s.parameters(), hp.clip)\n",
    "        optimizer.step()\n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d155a6175a4665bcd3217f9a6fa0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4028926193714142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thefacetakt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4028926193714142]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "s2s = Seq2Seq(source_lang, target_lang, hp)\n",
    "trainS2S(s2s, [\"'a 'a d y r\", \"'a 'a h b ckh\"], [\"a a d i r\", \"e a h a v k h a\"], hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as file:\n",
    "        return list(map(str.strip, file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cc58b8fbf04a71b471e70f6b7f2225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thefacetakt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41578713059425354\n",
      "0.29900214076042175\n",
      "3.941352133551845e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "s2s = Seq2Seq(source_lang, target_lang, hp)\n",
    "losses = trainS2S(s2s, read_file(src_files.train)[:30000], read_file(trg_files.train)[:30000], hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc430571080>]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc425be3320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 32, padding_idx=0)\n",
       "    (gru): GRU(32, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 32, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(288, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thefacetakt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> b b b b b b b b b b b b b b', '<S> b b b b b b b b b b b b b b']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(form_batch_variable(source_lang, [\"'a 'a d y r\", \"'a 'a h b ckh\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
