{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_utils import pad_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "BOS_TOKEN = 1\n",
    "NAN_TOKEN = 2\n",
    "EOS_TOKEN = 3\n",
    "SPECIAL_TOKENS = 4\n",
    "OCCURING_SPECIAL_TOKENS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class DatasetFilesLocation:\n",
    "#     def __init__(self, train, dev, test, tokens):\n",
    "#         self.train = train\n",
    "#         self.dev = dev\n",
    "#         self.test = test\n",
    "#         self.tokens = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# src_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/src.train.txt',\n",
    "#     dev='../preprocessed/he-en/src.dev.txt',\n",
    "#     test='../preprocessed/he-en/src.test.txt',\n",
    "#     tokens='../preprocessed/he-en/src.tokens.txt')\n",
    "\n",
    "# trg_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/tgt.train.txt',\n",
    "#     dev='../preprocessed/he-en/tgt.dev.txt',\n",
    "#     test='../preprocessed/he-en/tgt.test.txt',\n",
    "#     tokens='../preprocessed/he-en/tgt.tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, tokens_file_path):\n",
    "        self.idx2word = defaultdict(lambda: \"<NAN/>\")\n",
    "        self.word2idx = defaultdict(lambda: NAN_TOKEN)\n",
    "        with open(tokens_file_path) as tokens_file:\n",
    "            tokens = tokens_file.readlines()\n",
    "            for word, idx in map(lambda x: x.strip().split(), tokens):\n",
    "                idx = int(idx) + SPECIAL_TOKENS\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "            assert PAD_TOKEN not in self.idx2word\n",
    "            assert BOS_TOKEN not in self.idx2word\n",
    "            assert EOS_TOKEN not in self.idx2word\n",
    "            for word, idx in [('<PAD/>', PAD_TOKEN), ('<S>', BOS_TOKEN),\n",
    "                              ('</S>', EOS_TOKEN), ('<NAN/>', NAN_TOKEN)]:\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "    \n",
    "    def convert(self, sentence):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.strip().split()\n",
    "        return [BOS_TOKEN] + list(map(lambda word: self.word2idx[word], sentence)) + [EOS_TOKEN]\n",
    "    \n",
    "    def convert_batch(self, sents):\n",
    "        \n",
    "        batch_max_length = 0\n",
    "        for sent in sents:\n",
    "            batch_max_length = max(batch_max_length, len(sent))\n",
    "            \n",
    "#         print(batch_max_length)\n",
    "        \n",
    "        result = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        mask = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        \n",
    "        for sent_id, sent in enumerate(sents):\n",
    "            sent = sent[:batch_max_length]\n",
    "            current = self.convert(sent)\n",
    "            result[sent_id, :len(current)] = current\n",
    "            mask[sent_id, :len(current)] = 1.0\n",
    "            \n",
    "        return result, mask\n",
    "    \n",
    "    def input_size(self):\n",
    "        return len(self.idx2word.keys())\n",
    "    \n",
    "    def output_size(self):\n",
    "        return len(self.idx2word.keys())# - SPECIAL_TOKENS + OCCURING_SPECIAL_TOKENS\n",
    "    \n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]# + SPECIAL_TOKENS - OCCURING_SPECIAL_TOKENS]\n",
    "    \n",
    "    def get_eos(self):\n",
    "        return EOS_TOKEN #OCCURING_SPECIAL_TOKENS - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as file:\n",
    "        return list(map(lambda s: s.strip().split(\" \"), file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_problem(path, n_sents=None):\n",
    "    modes = [\"train\",  \"dev\", \"test\"]\n",
    "    datasets = [\"src\", \"tgt\"]\n",
    "    file_template = \"{}.{}.txt\"\n",
    "    \n",
    "    result = {}\n",
    "    for mode in modes:\n",
    "        src = read_file(os.path.join(path, file_template.format(\"src\", mode)))\n",
    "        tgt = read_file(os.path.join(path, file_template.format(\"tgt\", mode)))\n",
    "        \n",
    "        assert len(src) == len(tgt)\n",
    "        \n",
    "#         result[mode] = list(zip(src, tgt))\n",
    "        if n_sents is not None:\n",
    "            result[mode] = (src[:n_sents], tgt[:n_sents])\n",
    "        else:\n",
    "            result[mode] = (src, tgt)\n",
    "        \n",
    "    src_lang = Lang(os.path.join(path, file_template.format(\"src\", \"tokens\")))\n",
    "    tgt_lang = Lang(os.path.join(path, file_template.format(\"tgt\", \"tokens\")))\n",
    "    return result, src_lang, tgt_lang\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d, src, tgt = read_problem(\"../preprocessed/he-en/\", n_sents=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(d[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  6.,  4., 24., 88., 39.,  3.,  0.],\n",
       "        [ 1.,  6.,  6.,  6., 48., 80., 28.,  3.],\n",
       "        [ 1.,  6.,  6., 14., 17.,  3.,  0.,  0.]]),\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.convert_batch(d[\"test\"][0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class BatchSampler:\n",
    "    def __init__(self, dataset, src_lang, tgt_lang, batch_size):\n",
    "        self.train = dataset[\"train\"]\n",
    "        self.dev = dataset[\"dev\"]\n",
    "        self.test = dataset[\"test\"]\n",
    "        \n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train)//self.batch_size + 1\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.position = 0\n",
    "        return self\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = 0\n",
    "        \n",
    "    \n",
    "    def get_batch(self, x, y):\n",
    "        x, x_mask = self.src_lang.convert_batch(x)\n",
    "        y, y_mask = self.tgt_lang.convert_batch(y)\n",
    "        \n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        y = Variable(torch.from_numpy(y.astype(np.int64))).contiguous()\n",
    "        y_mask = Variable(torch.from_numpy(y_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        return (x, x_mask), (y, y_mask)\n",
    "    \n",
    "        \n",
    "    def __next__(self):\n",
    "            if self.position >= len(self.train[0]):\n",
    "                raise StopIteration()\n",
    "                \n",
    "            x = self.train[0][self.position:self.position + self.batch_size]\n",
    "            y = self.train[1][self.position:self.position + self.batch_size]\n",
    "            \n",
    "            self.position += self.batch_size\n",
    "            return self.get_batch(x, y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def form_batch_variable(lang, sentences):\n",
    "#     sentences = list(map(lang.convert, sentences))\n",
    "#     sentences = sorted(sentences, key=len, reverse=True)\n",
    "#     lengths = list(map(len, sentences))\n",
    "#     sentences = list(map(lambda sentence: Variable(torch.LongTensor(sentence)), sentences))\n",
    "#     batch = pad_sequence(sentences, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#     if use_cuda:\n",
    "#         batch = batch.cuda()\n",
    "#     return torch.nn.utils.rnn.pack_padded_sequence(batch, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.max_length = 100\n",
    "        self.enc_hidden_size = 128\n",
    "        self.enc_emb_size = 128\n",
    "        self.enc_layers = 1\n",
    "        self.enc_dropout = 0.1\n",
    "        self.enc_bidirectional = True\n",
    "        \n",
    "        self.dec_hidden_size = 128\n",
    "        self.dec_emb_size = self.enc_emb_size\n",
    "        self.dec_layers = 1\n",
    "        self.dec_dropout = 0.1\n",
    "        self.dec_bidirectional = True\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.learning_rate = 0.001\n",
    "        self.clip = 0.25\n",
    "     \n",
    "    def get_enc_output_size(self):\n",
    "        return self.enc_hidden_size * (int(self.enc_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_output_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_state_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1) * self.dec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,\n",
    "                                      embedding_dim=hp.enc_emb_size,\n",
    "                                      padding_idx=PAD_TOKEN)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=hp.enc_emb_size,\n",
    "                          hidden_size=hp.enc_hidden_size,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.enc_dropout,\n",
    "                          num_layers=hp.enc_layers,\n",
    "                          bidirectional=hp.enc_bidirectional)\n",
    "        self.num_directions = (int(hp.enc_bidirectional) + 1)\n",
    "        self.num_layers = hp.enc_layers\n",
    "        self.hidden_size = hp.enc_hidden_size\n",
    "\n",
    "    def forward(self, input_batch, hidden=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        if (hidden is None):\n",
    "            hidden = self.init_hidden(input_batch.size(0))\n",
    "        embedded = self.embedding(input_batch).contiguous()\n",
    "#         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, _ = self.gru(embedded, hidden)\n",
    "#         outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             outputs, padding_value=PAD_TOKEN, batch_first=True)\n",
    "#         print(outputs.size())\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mask(lengths):\n",
    "#     batch_size = lengths.size(0)\n",
    "#     max_len = lengths[0]\n",
    "#     time = torch.arange(max_len).repeat(batch_size, 1)\n",
    "#     lengths = lengths.view(-1, 1).type(torch.FloatTensor)\n",
    "#     if (use_cuda):\n",
    "#         time = time.cuda()\n",
    "#         lengths = lengths.cuda()\n",
    "\n",
    "#     mask = Variable((time < lengths).type(torch.FloatTensor))\n",
    "#     if (use_cuda):\n",
    "#         return mask.cuda()\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hp.get_enc_output_size() + hp.get_dec_state_size(), 1)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers * directions, B, HD)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (B, T, HE)\n",
    "        :param encoder_output_lengths:\n",
    "            lengths of encoded sentences, in shape (B,)\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        max_len = encoder_outputs.size(1)\n",
    "\n",
    "        hidden = hidden.transpose(0, 1).contiguous() # [B, l * d, HD]\n",
    "        hidden = hidden.view(batch_size, -1) # [B, HD * layers * directions]\n",
    "        hidden = hidden.repeat(max_len, 1, 1).transpose(0, 1) # [B, T, HD * layers * directions]\n",
    "        \n",
    "        energies = self.attn(torch.cat((hidden, encoder_outputs), -1)).view(batch_size, max_len) # [B, T, 1]\n",
    "\n",
    "        \n",
    "        energies = energies * mask\n",
    "        energies = F.softmax(energies)\n",
    "        energies = energies * mask\n",
    "        energies = energies / energies.sum(1).view(-1, 1) # [B, T]\n",
    "        \n",
    "        return (energies.view(batch_size, max_len, 1) * encoder_outputs).sum(1) #[B, HE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hp):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hp.dec_emb_size, padding_idx=PAD_TOKEN)\n",
    "        self.attn = Attn(hp)\n",
    "        self.gru = nn.GRU(input_size=hp.dec_emb_size + hp.get_enc_output_size(),\n",
    "                          hidden_size=hp.dec_hidden_size,\n",
    "                          num_layers=hp.dec_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.dec_dropout,\n",
    "                          bidirectional=hp.dec_bidirectional)\n",
    "        self.out = nn.Linear(hp.get_dec_output_size(), output_size)\n",
    "\n",
    "        self.num_layers = hp.dec_layers\n",
    "        self.num_directions = int(hp.dec_bidirectional) + 1\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hp.dec_hidden_size\n",
    "\n",
    "\n",
    "    def forward(self, input, encoder_outputs, mask, hidden=None):\n",
    "        \"\"\"\n",
    "            input: [B,]\n",
    "            encoder_outputs: [B, T, HE]\n",
    "            hidden: [B, layers * directions, HD]\n",
    "        \"\"\"\n",
    "        batch_size = input.size(0)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "#         embedded = self.embedding(input.view(-1, 1))\n",
    "        embedded = self.embedding(input)\n",
    "#         print(embedded.size())\n",
    "        context = self.attn(hidden, encoder_outputs, mask).view(batch_size, -1)\n",
    "#         print(context.size())\n",
    "        rnn_input = torch.cat((embedded, context), -1).view(batch_size, 1, -1)\n",
    "        \n",
    "#         print(\"RNN input\", rnn_input.size())\n",
    "        output, next_hidden = self.gru(rnn_input, hidden)\n",
    "        output = self.out(output).view(batch_size, self.output_size)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        \n",
    "        return output, next_hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, source_lang, target_lang, hp):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.encoder = EncoderRNN(source_lang.input_size(), hp)\n",
    "        self.decoder = DecoderRNN(target_lang.input_size(), target_lang.input_size(), hp)\n",
    "        self.max_length = hp.max_length\n",
    "        self.criterion = nn.NLLLoss(reduce=False, size_average=False)\n",
    "        \n",
    "#     def translate(self, input_seq):\n",
    "\n",
    "# #         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "# #             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "# #         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "# #         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "# #         mask = get_mask(encoder_output_lengths)\n",
    "        \n",
    "# #         batch_size = input_batch.size(0)\n",
    "        \n",
    "#         dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "#         if use_cuda:\n",
    "#             dec_input = dec_input.cuda()\n",
    "# #         max_length = min(self.max_length, 2 * encoder_output_lengths[0])\n",
    "#         hidden = None\n",
    "#         translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "#         for i in range(max_length):\n",
    "#             output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "#             _, output_idx = torch.max(output, -1)\n",
    "#             for j in range(batch_size):\n",
    "#                 if translations[j][-1] != target_lang.get_eos():\n",
    "#                     translations[j].append(output_idx[j].data[0])\n",
    "#             dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "#             if use_cuda:\n",
    "#                 dec_input = dec_input.cuda()\n",
    "#         return [' '.join(map(target_lang.get_word, elem)) for elem in translations]\n",
    "\n",
    "    def translate(self, input_batch, mask):\n",
    "        batch_size = input_batch.size()[0]\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "        word_indices = []\n",
    "#         outputs = []\n",
    "        \n",
    "        dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "        \n",
    "        MAX_LENGTH = 100\n",
    "        translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "        converged = np.zeros(shape=(batch_size, ))\n",
    "        for i in range(MAX_LENGTH):     \n",
    "            output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "            _, output_idx = torch.max(output, -1)\n",
    "                \n",
    "            for j in range(batch_size):\n",
    "                if translations[j][-1] != self.target_lang.get_eos():\n",
    "                    translations[j].append(output_idx[j].data[0])\n",
    "                else:\n",
    "                    converged[j] = True\n",
    "            dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "            \n",
    "            \n",
    "            if np.all(converged):\n",
    "                break\n",
    "            \n",
    "         \n",
    "            \n",
    "#         return translations\n",
    "        return [' '.join(map(self.target_lang.get_word, elem)) for elem in translations]\n",
    "    \n",
    "    def forward(self, input_batch, mask, output_batch, out_mask):\n",
    "#         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "#         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "#         mask = get_mask(encoder_output_lengths)\n",
    "#         batch_size = input_batch.size(0)\n",
    "        \n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "#         output_batch, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(output_seq,\n",
    "#                                                                               batch_first=True,\n",
    "#                                                                               padding_value=PAD_TOKEN)\n",
    "#         output_lengths = torch.LongTensor(output_lengths)\n",
    "#         out_mask = get_mask(output_lengths)\n",
    "        loss = 0\n",
    "        outputs = []\n",
    "        for i in range(out_mask.size()[1] - 1):\n",
    "           \n",
    "            output, hidden = self.decoder(output_batch[:, i], encoder_outputs, mask=mask, hidden=hidden)\n",
    "            loss += (self.criterion(output, output_batch[:, i + 1]) * out_mask[:, i + 1]).sum()\n",
    "        \n",
    "        loss /= out_mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def trainS2S(s2s, batch_sampler, hp):\n",
    "    s2s.train()\n",
    "    losses = []\n",
    "#     hp.batch_size = 100\n",
    "#     assert(len(src) == len(trg))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(s2s.parameters(), lr=hp.learning_rate)\n",
    "    \n",
    "    for epoch_id in range(hp.n_epochs):\n",
    "#         batch_sampler.reset()\n",
    "        for batch_id, ((input, input_mask), (output, output_mask)) in tqdm.tqdm(enumerate(batch_sampler)):\n",
    "#         for i in tqdm.tqdm(range(0, len(src), hp.batch_size)):\n",
    "#             src_batch = form_batch_variable(source_lang, src[i : i + hp.batch_size])\n",
    "#             trg_batch = form_batch_variable(target_lang, trg[i : i + hp.batch_size])\n",
    "\n",
    "\n",
    "            loss = s2s(input, input_mask, output, output_mask)\n",
    "#             if (batch_id // hp.batch_size) % 100 == 0:\n",
    "#                 print(loss.data[0])\n",
    "            losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(s2s.parameters(), hp.clip)\n",
    "            optimizer.step()\n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_dataset = {\n",
    "    \"train\": ( [\"'a 'a d y r\", \"'a 'a h b ckh\"], [\"a a d i r\", \"e a h a v k h a\"]),\n",
    "    \"test\":None,\n",
    "    \"dev\":None\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(dummy_dataset, src, tgt, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "1it [00:00, 11.31it/s]\n",
      "1it [00:00,  9.46it/s]\n",
      "1it [00:00,  9.57it/s]\n",
      "1it [00:00,  9.44it/s]\n",
      "1it [00:00, 10.97it/s]\n",
      "1it [00:00,  9.48it/s]\n",
      "1it [00:00,  8.72it/s]\n",
      "1it [00:00, 10.21it/s]\n",
      "1it [00:00,  9.98it/s]\n",
      "1it [00:00,  9.55it/s]\n",
      "1it [00:00,  9.13it/s]\n",
      "1it [00:00,  9.98it/s]\n",
      "1it [00:00, 10.38it/s]\n",
      "1it [00:00, 10.30it/s]\n",
      "1it [00:00,  9.91it/s]\n",
      "1it [00:00,  9.63it/s]\n",
      "1it [00:00,  9.30it/s]\n",
      "1it [00:00, 10.33it/s]\n",
      "1it [00:00, 10.37it/s]\n",
      "1it [00:00, 10.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.002084732055664,\n",
       " 2.6538538932800293,\n",
       " 2.3275082111358643,\n",
       " 2.0254383087158203,\n",
       " 1.7580164670944214,\n",
       " 1.5345267057418823,\n",
       " 1.3483034372329712,\n",
       " 1.1852436065673828,\n",
       " 1.0418860912322998,\n",
       " 0.919980525970459,\n",
       " 0.8147149085998535,\n",
       " 0.7196149826049805,\n",
       " 0.632966160774231,\n",
       " 0.5549482703208923,\n",
       " 0.48462098836898804,\n",
       " 0.42104572057724,\n",
       " 0.3653680384159088,\n",
       " 0.3198111057281494,\n",
       " 0.2834157645702362,\n",
       " 0.250639945268631]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.batch_size = 100\n",
    "hp.n_epochs = 20\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 128, padding_idx=0)\n",
       "    (gru): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 128, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(384, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(d, src, tgt, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "33it [00:05,  5.93it/s]\n",
      "33it [00:04,  6.63it/s]\n",
      "33it [00:05,  6.11it/s]\n",
      "33it [00:05,  6.06it/s]\n",
      "33it [00:05,  6.59it/s]\n",
      "33it [00:05,  6.09it/s]\n",
      "33it [00:05,  6.15it/s]\n",
      "33it [00:05,  6.00it/s]\n",
      "33it [00:05,  6.04it/s]\n",
      "33it [00:05,  6.19it/s]\n",
      "33it [00:05,  5.84it/s]\n",
      "33it [00:07,  4.59it/s]\n",
      "33it [00:05,  5.88it/s]\n",
      "33it [00:05,  6.18it/s]\n",
      "33it [00:05,  6.02it/s]\n",
      "33it [00:05,  6.06it/s]\n",
      "33it [00:05,  6.23it/s]\n",
      "33it [00:05,  5.92it/s]\n",
      "33it [00:05,  6.10it/s]\n",
      "33it [00:05,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.n_epochs = 20\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "losses = trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f291336b320>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f297944c4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 32, padding_idx=0)\n",
       "    (gru): GRU(32, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 32, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(288, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> a d i r </S>', '<S> a v h a k h </S>']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> a k h - s h a m a t s h a k h - n i t s h </S>', '<S> a v h a k h </S>']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"k t v m - sh r ckh n k t v m\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     1     6     6    17    88    49     3\n",
       "     1     6     6    24    14    15     3\n",
       " [torch.LongTensor of size 2x7], Variable containing:\n",
       "     1     1     1     1     1     1     1\n",
       "     1     1     1     1     1     1     1\n",
       " [torch.FloatTensor of size 2x7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_translation(x, x_mask):\n",
    "    x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "    x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "    \n",
    "    \n",
    "    return x, x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a a d i r', 'e a h a v k h a']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [torch]",
   "language": "python",
   "name": "Python [torch]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
