{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_utils import pad_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "BOS_TOKEN = 1\n",
    "NAN_TOKEN = 2\n",
    "EOS_TOKEN = 3\n",
    "SPECIAL_TOKENS = 4\n",
    "OCCURING_SPECIAL_TOKENS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class DatasetFilesLocation:\n",
    "#     def __init__(self, train, dev, test, tokens):\n",
    "#         self.train = train\n",
    "#         self.dev = dev\n",
    "#         self.test = test\n",
    "#         self.tokens = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# src_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/src.train.txt',\n",
    "#     dev='../preprocessed/he-en/src.dev.txt',\n",
    "#     test='../preprocessed/he-en/src.test.txt',\n",
    "#     tokens='../preprocessed/he-en/src.tokens.txt')\n",
    "\n",
    "# trg_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/tgt.train.txt',\n",
    "#     dev='../preprocessed/he-en/tgt.dev.txt',\n",
    "#     test='../preprocessed/he-en/tgt.test.txt',\n",
    "#     tokens='../preprocessed/he-en/tgt.tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, tokens_file_path):\n",
    "        self.idx2word = defaultdict(lambda: \"<NAN/>\")\n",
    "        self.word2idx = defaultdict(lambda: NAN_TOKEN)\n",
    "        with open(tokens_file_path) as tokens_file:\n",
    "            tokens = tokens_file.readlines()\n",
    "            for word, idx in map(lambda x: x.strip().split(), tokens):\n",
    "                idx = int(idx) + SPECIAL_TOKENS\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "            assert PAD_TOKEN not in self.idx2word\n",
    "            assert BOS_TOKEN not in self.idx2word\n",
    "            assert EOS_TOKEN not in self.idx2word\n",
    "            for word, idx in [('<PAD/>', PAD_TOKEN), ('<S>', BOS_TOKEN),\n",
    "                              ('</S>', EOS_TOKEN), ('<NAN/>', NAN_TOKEN)]:\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "    \n",
    "    def convert(self, sentence):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.strip().split()\n",
    "        return [BOS_TOKEN] + list(map(lambda word: self.word2idx[word], sentence)) + [EOS_TOKEN]\n",
    "    \n",
    "    def convert_batch(self, sents):\n",
    "        \n",
    "        batch_max_length = 0\n",
    "        for sent in sents:\n",
    "            batch_max_length = max(batch_max_length, len(sent))\n",
    "            \n",
    "#         print(batch_max_length)\n",
    "        \n",
    "        result = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        mask = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        \n",
    "        for sent_id, sent in enumerate(sents):\n",
    "            sent = sent[:batch_max_length]\n",
    "            current = self.convert(sent)\n",
    "            result[sent_id, :len(current)] = current\n",
    "            mask[sent_id, :len(current)] = 1.0\n",
    "            \n",
    "        return result, mask\n",
    "    \n",
    "    def input_size(self):\n",
    "        return len(self.idx2word.keys())\n",
    "    \n",
    "    def output_size(self):\n",
    "        return len(self.idx2word.keys())# - SPECIAL_TOKENS + OCCURING_SPECIAL_TOKENS\n",
    "    \n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]# + SPECIAL_TOKENS - OCCURING_SPECIAL_TOKENS]\n",
    "    \n",
    "    def get_eos(self):\n",
    "        return EOS_TOKEN #OCCURING_SPECIAL_TOKENS - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as file:\n",
    "        return list(map(lambda s: s.strip().split(\" \"), file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_problem(path, n_sents=None):\n",
    "    modes = [\"train\",  \"dev\", \"test\"]\n",
    "    datasets = [\"src\", \"tgt\"]\n",
    "    file_template = \"{}.{}.txt\"\n",
    "    \n",
    "    result = {}\n",
    "    for mode in modes:\n",
    "        src = read_file(os.path.join(path, file_template.format(\"src\", mode)))\n",
    "        tgt = read_file(os.path.join(path, file_template.format(\"tgt\", mode)))\n",
    "        \n",
    "        assert len(src) == len(tgt)\n",
    "        \n",
    "#         result[mode] = list(zip(src, tgt))\n",
    "        if n_sents is not None:\n",
    "            result[mode] = (src[:n_sents], tgt[:n_sents])\n",
    "        else:\n",
    "            result[mode] = (src, tgt)\n",
    "        \n",
    "    src_lang = Lang(os.path.join(path, file_template.format(\"src\", \"tokens\")))\n",
    "    tgt_lang = Lang(os.path.join(path, file_template.format(\"tgt\", \"tokens\")))\n",
    "    return result, src_lang, tgt_lang\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d, src, tgt = read_problem(\"../preprocessed/he-en/\", n_sents=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183050"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  6.,  4., 24., 88., 39.,  3.,  0.],\n",
       "        [ 1.,  6.,  6.,  6., 48., 80., 28.,  3.],\n",
       "        [ 1.,  6.,  6., 14., 17.,  3.,  0.,  0.]]),\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.convert_batch(d[\"test\"][0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class BatchSampler:\n",
    "    def __init__(self, dataset, src_lang, tgt_lang, batch_size):\n",
    "        self.train = np.array(dataset[\"train\"])\n",
    "        self.dev = np.array(dataset[\"dev\"])\n",
    "        self.test = np.array(dataset[\"test\"])\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        self.train_indices = np.random.permutation(np.arange(len(self.train[0]), dtype=np.int32))\n",
    "        \n",
    "        \n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train)//self.batch_size + 1\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.position = 0\n",
    "        return self\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = 0\n",
    "        \n",
    "    \n",
    "    def get_batch(self, x, y):\n",
    "        x, x_mask = self.src_lang.convert_batch(x)\n",
    "        y, y_mask = self.tgt_lang.convert_batch(y)\n",
    "        \n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        y = Variable(torch.from_numpy(y.astype(np.int64))).contiguous()\n",
    "        y_mask = Variable(torch.from_numpy(y_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        return (x, x_mask), (y, y_mask)\n",
    "    \n",
    "        \n",
    "    def __next__(self):\n",
    "            if self.position >= len(self.train[0]):\n",
    "                raise StopIteration()\n",
    "                \n",
    "            x = self.train[0][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "            y = self.train[1][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "            \n",
    "            self.position += self.batch_size\n",
    "            return self.get_batch(x, y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def form_batch_variable(lang, sentences):\n",
    "#     sentences = list(map(lang.convert, sentences))\n",
    "#     sentences = sorted(sentences, key=len, reverse=True)\n",
    "#     lengths = list(map(len, sentences))\n",
    "#     sentences = list(map(lambda sentence: Variable(torch.LongTensor(sentence)), sentences))\n",
    "#     batch = pad_sequence(sentences, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#     if use_cuda:\n",
    "#         batch = batch.cuda()\n",
    "#     return torch.nn.utils.rnn.pack_padded_sequence(batch, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.max_length = 100\n",
    "        self.enc_hidden_size = 128\n",
    "        self.enc_emb_size = 128\n",
    "        self.enc_layers = 1\n",
    "        self.enc_dropout = 0.1\n",
    "        self.enc_bidirectional = True\n",
    "        \n",
    "        self.dec_hidden_size = 128\n",
    "        self.dec_emb_size = self.enc_emb_size\n",
    "        self.dec_layers = 1\n",
    "        self.dec_dropout = 0.1\n",
    "        self.dec_bidirectional = True\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.learning_rate = 0.001\n",
    "        self.clip = 0.25\n",
    "     \n",
    "    def get_enc_output_size(self):\n",
    "        return self.enc_hidden_size * (int(self.enc_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_output_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_state_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1) * self.dec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,\n",
    "                                      embedding_dim=hp.enc_emb_size,\n",
    "                                      padding_idx=PAD_TOKEN)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=hp.enc_emb_size,\n",
    "                          hidden_size=hp.enc_hidden_size,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.enc_dropout,\n",
    "                          num_layers=hp.enc_layers,\n",
    "                          bidirectional=hp.enc_bidirectional)\n",
    "        self.num_directions = (int(hp.enc_bidirectional) + 1)\n",
    "        self.num_layers = hp.enc_layers\n",
    "        self.hidden_size = hp.enc_hidden_size\n",
    "\n",
    "    def forward(self, input_batch, hidden=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        if (hidden is None):\n",
    "            hidden = self.init_hidden(input_batch.size(0))\n",
    "        embedded = self.embedding(input_batch).contiguous()\n",
    "#         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, _ = self.gru(embedded, hidden)\n",
    "#         outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             outputs, padding_value=PAD_TOKEN, batch_first=True)\n",
    "#         print(outputs.size())\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mask(lengths):\n",
    "#     batch_size = lengths.size(0)\n",
    "#     max_len = lengths[0]\n",
    "#     time = torch.arange(max_len).repeat(batch_size, 1)\n",
    "#     lengths = lengths.view(-1, 1).type(torch.FloatTensor)\n",
    "#     if (use_cuda):\n",
    "#         time = time.cuda()\n",
    "#         lengths = lengths.cuda()\n",
    "\n",
    "#     mask = Variable((time < lengths).type(torch.FloatTensor))\n",
    "#     if (use_cuda):\n",
    "#         return mask.cuda()\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hp.get_enc_output_size() + hp.get_dec_state_size(), 1)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers * directions, B, HD)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (B, T, HE)\n",
    "        :param encoder_output_lengths:\n",
    "            lengths of encoded sentences, in shape (B,)\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        max_len = encoder_outputs.size(1)\n",
    "\n",
    "        hidden = hidden.transpose(0, 1).contiguous() # [B, l * d, HD]\n",
    "        hidden = hidden.view(batch_size, -1) # [B, HD * layers * directions]\n",
    "        hidden = hidden.repeat(max_len, 1, 1).transpose(0, 1) # [B, T, HD * layers * directions]\n",
    "        \n",
    "        energies = self.attn(torch.cat((hidden, encoder_outputs), -1)).view(batch_size, max_len) # [B, T, 1]\n",
    "\n",
    "        \n",
    "        energies = energies * mask\n",
    "        energies = F.softmax(energies)\n",
    "        energies = energies * mask\n",
    "        energies = energies / energies.sum(1).view(-1, 1) # [B, T]\n",
    "        \n",
    "        return (energies.view(batch_size, max_len, 1) * encoder_outputs).sum(1) #[B, HE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hp):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hp.dec_emb_size, padding_idx=PAD_TOKEN)\n",
    "        self.attn = Attn(hp)\n",
    "        self.gru = nn.GRU(input_size=hp.dec_emb_size + hp.get_enc_output_size(),\n",
    "                          hidden_size=hp.dec_hidden_size,\n",
    "                          num_layers=hp.dec_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.dec_dropout,\n",
    "                          bidirectional=hp.dec_bidirectional)\n",
    "        self.out = nn.Linear(hp.get_dec_output_size(), output_size)\n",
    "\n",
    "        self.num_layers = hp.dec_layers\n",
    "        self.num_directions = int(hp.dec_bidirectional) + 1\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hp.dec_hidden_size\n",
    "\n",
    "\n",
    "    def forward(self, input, encoder_outputs, mask, hidden=None):\n",
    "        \"\"\"\n",
    "            input: [B,]\n",
    "            encoder_outputs: [B, T, HE]\n",
    "            hidden: [B, layers * directions, HD]\n",
    "        \"\"\"\n",
    "        batch_size = input.size(0)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "#         embedded = self.embedding(input.view(-1, 1))\n",
    "        embedded = self.embedding(input)\n",
    "#         print(embedded.size())\n",
    "        context = self.attn(hidden, encoder_outputs, mask).view(batch_size, -1)\n",
    "#         print(context.size())\n",
    "        rnn_input = torch.cat((embedded, context), -1).view(batch_size, 1, -1)\n",
    "        \n",
    "#         print(\"RNN input\", rnn_input.size())\n",
    "        output, next_hidden = self.gru(rnn_input, hidden)\n",
    "        output = self.out(output).view(batch_size, self.output_size)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        \n",
    "        return output, next_hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, source_lang, target_lang, hp):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.encoder = EncoderRNN(source_lang.input_size(), hp)\n",
    "        self.decoder = DecoderRNN(target_lang.input_size(), target_lang.input_size(), hp)\n",
    "        self.max_length = hp.max_length\n",
    "        self.criterion = nn.NLLLoss(reduce=False, size_average=False)\n",
    "        \n",
    "#     def translate(self, input_seq):\n",
    "\n",
    "# #         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "# #             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "# #         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "# #         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "# #         mask = get_mask(encoder_output_lengths)\n",
    "        \n",
    "# #         batch_size = input_batch.size(0)\n",
    "        \n",
    "#         dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "#         if use_cuda:\n",
    "#             dec_input = dec_input.cuda()\n",
    "# #         max_length = min(self.max_length, 2 * encoder_output_lengths[0])\n",
    "#         hidden = None\n",
    "#         translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "#         for i in range(max_length):\n",
    "#             output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "#             _, output_idx = torch.max(output, -1)\n",
    "#             for j in range(batch_size):\n",
    "#                 if translations[j][-1] != target_lang.get_eos():\n",
    "#                     translations[j].append(output_idx[j].data[0])\n",
    "#             dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "#             if use_cuda:\n",
    "#                 dec_input = dec_input.cuda()\n",
    "#         return [' '.join(map(target_lang.get_word, elem)) for elem in translations]\n",
    "\n",
    "    def translate(self, input_batch, mask):\n",
    "        batch_size = input_batch.size()[0]\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "        word_indices = []\n",
    "#         outputs = []\n",
    "        \n",
    "        dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "        \n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        MAX_LENGTH = 100\n",
    "        translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "        converged = np.zeros(shape=(batch_size, ))\n",
    "        for i in range(MAX_LENGTH):     \n",
    "            output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "            _, output_idx = torch.max(output, -1)\n",
    "                \n",
    "            for j in range(batch_size):\n",
    "                if translations[j][-1] != self.target_lang.get_eos():\n",
    "                    translations[j].append(output_idx[j].data[0])\n",
    "                else:\n",
    "                    converged[j] = True\n",
    "            dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "            \n",
    "            if use_cuda:\n",
    "                dec_input = dec_input.cuda()\n",
    "            \n",
    "            \n",
    "            if np.all(converged):\n",
    "                break\n",
    "            \n",
    "         \n",
    "            \n",
    "#         return translations\n",
    "        return [' '.join(map(self.target_lang.get_word, elem)) for elem in translations]\n",
    "    \n",
    "    def forward(self, input_batch, mask, output_batch, out_mask):\n",
    "#         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "#         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "#         mask = get_mask(encoder_output_lengths)\n",
    "#         batch_size = input_batch.size(0)\n",
    "\n",
    "        \n",
    "#         if use_cuda:\n",
    "#             dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "#         output_batch, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(output_seq,\n",
    "#                                                                               batch_first=True,\n",
    "#                                                                               padding_value=PAD_TOKEN)\n",
    "#         output_lengths = torch.LongTensor(output_lengths)\n",
    "#         out_mask = get_mask(output_lengths)\n",
    "        loss = 0\n",
    "        outputs = []\n",
    "        for i in range(out_mask.size()[1] - 1):\n",
    "           \n",
    "            output, hidden = self.decoder(output_batch[:, i], encoder_outputs, mask=mask, hidden=hidden)\n",
    "            loss += (self.criterion(output, output_batch[:, i + 1]) * out_mask[:, i + 1]).sum()\n",
    "        \n",
    "        loss /= out_mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def trainS2S(s2s, batch_sampler, hp):\n",
    "    s2s.train()\n",
    "    losses = []\n",
    "#     hp.batch_size = 100\n",
    "#     assert(len(src) == len(trg))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(s2s.parameters(), lr=hp.learning_rate)\n",
    "    \n",
    "    for epoch_id in range(hp.n_epochs):\n",
    "#         batch_sampler.reset()\n",
    "        for batch_id, ((input, input_mask), (output, output_mask)) in tqdm.tqdm(enumerate(batch_sampler)):\n",
    "#         for i in tqdm.tqdm(range(0, len(src), hp.batch_size)):\n",
    "#             src_batch = form_batch_variable(source_lang, src[i : i + hp.batch_size])\n",
    "#             trg_batch = form_batch_variable(target_lang, trg[i : i + hp.batch_size])\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                input_mask = input_mask.cuda()\n",
    "                output = output.cuda()\n",
    "                output_mask = output_mask.cuda()\n",
    "\n",
    "\n",
    "            loss = s2s(input, input_mask, output, output_mask)\n",
    "#             if (batch_id // hp.batch_size) % 100 == 0:\n",
    "#                 print(loss.data[0])\n",
    "            \n",
    "           \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(s2s.parameters(), hp.clip)\n",
    "            optimizer.step()\n",
    "            if use_cuda:\n",
    "                losses.append(loss.cpu().data[0])\n",
    "            else:\n",
    "                 losses.append(loss.data[0])\n",
    "        \n",
    "        torch.save(s2s.state_dict(), \"last_state.ckpt\")\n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_dataset = {\n",
    "    \"train\": ( [\"'a 'a d y r\", \"'a 'a h b ckh\"], [\"a a d i r\", \"e a h a v k h a\"]),\n",
    "    \"test\":None,\n",
    "    \"dev\":None\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(dummy_dataset, src, tgt, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "\n",
      "1it [00:00,  5.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  8.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  6.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  8.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  9.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  9.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  6.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  8.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00, 10.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  7.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.10202693939209,\n",
       " 2.7183477878570557,\n",
       " 2.370561361312866,\n",
       " 2.053406238555908,\n",
       " 1.7732186317443848,\n",
       " 1.5384966135025024,\n",
       " 1.3453575372695923,\n",
       " 1.1782236099243164,\n",
       " 1.0289262533187866,\n",
       " 0.899949848651886,\n",
       " 0.7912749648094177,\n",
       " 0.6969727873802185,\n",
       " 0.611719012260437,\n",
       " 0.5334523320198059,\n",
       " 0.46234649419784546,\n",
       " 0.3996935188770294,\n",
       " 0.3469258248806,\n",
       " 0.3032667338848114,\n",
       " 0.26462629437446594,\n",
       " 0.2280382215976715]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.batch_size = 100\n",
    "hp.n_epochs = 20\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "if use_cuda:\n",
    "    s2s = s2s.cuda()\n",
    "trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 128, padding_idx=0)\n",
       "    (gru): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 128, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(384, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch_sampler.train[batch_sampler.train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(d, src, tgt, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp = HyperParameters()\n",
    "hp.n_epochs = 20\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "if use_cuda:\n",
    "    s2s = s2s.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "\n",
      "1it [00:00,  2.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  1.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  1.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:00,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:00,  2.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:01,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:01,  2.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "losses = trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s2s.load_state_dict(torch.load(\"last_state.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.save(s2s.state_dict(), \"last_state.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f58eacc16a0>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58e833cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 128, padding_idx=0)\n",
       "    (gru): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 128, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(384, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_translation(x, x_mask):\n",
    "    if not use_cuda:\n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "    else:\n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous().cuda()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous().cuda()\n",
    "    \n",
    "    \n",
    "    return x, x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> a d a r i </S>', '<S> a v a k h a </S>']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> a k h - r a m a t s h a </S>', '<S> a v a k h </S>']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"k t v m - sh r ckh n k t v m\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     1     6     6    17    88    49     3\n",
       "     1     6     6    24    14    15     3\n",
       " [torch.cuda.LongTensor of size 2x7 (GPU 0)], Variable containing:\n",
       "     1     1     1     1     1     1     1\n",
       "     1     1     1     1     1     1     1\n",
       " [torch.cuda.FloatTensor of size 2x7 (GPU 0)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a a d i r', 'e a h a v k h a']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [torch]",
   "language": "python",
   "name": "Python [torch]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
