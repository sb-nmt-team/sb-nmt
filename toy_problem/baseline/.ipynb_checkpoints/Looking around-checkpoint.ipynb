{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from bleu import bleu_from_lines\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_utils import pad_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "BOS_TOKEN = 1\n",
    "NAN_TOKEN = 2\n",
    "EOS_TOKEN = 3\n",
    "SPECIAL_TOKENS = 4\n",
    "OCCURING_SPECIAL_TOKENS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, tokens_file_path):\n",
    "        self.idx2word = defaultdict(lambda: \"<NAN/>\")\n",
    "        self.word2idx = defaultdict(lambda: NAN_TOKEN)\n",
    "        with open(tokens_file_path) as tokens_file:\n",
    "            tokens = tokens_file.readlines()\n",
    "            for word, idx in map(lambda x: x.strip().split(), tokens):\n",
    "                idx = int(idx) + SPECIAL_TOKENS\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "            assert PAD_TOKEN not in self.idx2word\n",
    "            assert BOS_TOKEN not in self.idx2word\n",
    "            assert EOS_TOKEN not in self.idx2word\n",
    "            for word, idx in [('<PAD/>', PAD_TOKEN), ('<S>', BOS_TOKEN),\n",
    "                              ('</S>', EOS_TOKEN), ('<NAN/>', NAN_TOKEN)]:\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "    \n",
    "    def convert(self, sentence):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.strip().split()\n",
    "        return [BOS_TOKEN] + list(map(lambda word: self.word2idx[word], sentence)) + [EOS_TOKEN]\n",
    "    \n",
    "    def convert_batch(self, sents):\n",
    "        \n",
    "        batch_max_length = 0\n",
    "        for sent in sents:\n",
    "            batch_max_length = max(batch_max_length, len(sent))\n",
    "\n",
    "        \n",
    "        result = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        mask = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        \n",
    "        for sent_id, sent in enumerate(sents):\n",
    "            sent = sent[:batch_max_length]\n",
    "            current = self.convert(sent)\n",
    "            result[sent_id, :len(current)] = current\n",
    "            mask[sent_id, :len(current)] = 1.0\n",
    "            \n",
    "        return result, mask\n",
    "    \n",
    "    def input_size(self):\n",
    "        return len(self.idx2word.keys())\n",
    "    \n",
    "    def output_size(self):\n",
    "        return len(self.idx2word.keys())\n",
    "    \n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]\n",
    "    \n",
    "    def get_eos(self):\n",
    "        return EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as file:\n",
    "        return list(map(lambda s: s.strip().split(\" \"), file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_problem(path, n_sents=None):\n",
    "    modes = [\"train\",  \"dev\", \"test\"]\n",
    "    datasets = [\"src\", \"tgt\"]\n",
    "    file_template = \"{}.{}.txt\"\n",
    "    \n",
    "    result = {}\n",
    "    for mode in modes:\n",
    "        src = read_file(os.path.join(path, file_template.format(\"src\", mode)))\n",
    "        tgt = read_file(os.path.join(path, file_template.format(\"tgt\", mode)))\n",
    "        \n",
    "        assert len(src) == len(tgt)\n",
    "\n",
    "        if n_sents is not None:\n",
    "            result[mode] = (src[:n_sents], tgt[:n_sents])\n",
    "        else:\n",
    "            result[mode] = (src, tgt)\n",
    "        \n",
    "    src_lang = Lang(os.path.join(path, file_template.format(\"src\", \"tokens\")))\n",
    "    tgt_lang = Lang(os.path.join(path, file_template.format(\"tgt\", \"tokens\")))\n",
    "    return result, src_lang, tgt_lang\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, src, tgt = read_problem(\"../preprocessed/he-en/\", n_sents=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchSampler:\n",
    "    def __init__(self, dataset, src_lang, tgt_lang, batch_size):\n",
    "        self.train = np.array(dataset[\"train\"])\n",
    "        self.dev = np.array(dataset[\"dev\"])\n",
    "        self.test = np.array(dataset[\"test\"])\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        self.train_indices = np.random.permutation(np.arange(len(self.train[0]), dtype=np.int32))\n",
    "        \n",
    "        \n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train) // self.batch_size + 1\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.position = 0\n",
    "        return self\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = 0\n",
    "        \n",
    "    \n",
    "    def get_batch(self, x, y):\n",
    "        x, x_mask = self.src_lang.convert_batch(x)\n",
    "        y, y_mask = self.tgt_lang.convert_batch(y)\n",
    "        \n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        y = Variable(torch.from_numpy(y.astype(np.int64))).contiguous()\n",
    "        y_mask = Variable(torch.from_numpy(y_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        return (x, x_mask), (y, y_mask)\n",
    "    \n",
    "        \n",
    "    def __next__(self):\n",
    "        if self.position >= len(self.train[0]):\n",
    "            raise StopIteration()\n",
    "\n",
    "        x = self.train[0][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "        y = self.train[1][self.train_indices[self.position:self.position + self.batch_size]]\n",
    "\n",
    "        self.position += self.batch_size\n",
    "        return self.get_batch(x, y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.max_length = 100\n",
    "        self.enc_hidden_size = 128\n",
    "        self.enc_emb_size = 128\n",
    "        self.enc_layers = 1\n",
    "        self.enc_dropout = 0.1\n",
    "        self.enc_bidirectional = True\n",
    "        \n",
    "        self.dec_hidden_size = 128\n",
    "        self.dec_emb_size = self.enc_emb_size\n",
    "        self.dec_layers = 1\n",
    "        self.dec_dropout = 0.1\n",
    "        self.dec_bidirectional = True\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.learning_rate = 0.001\n",
    "        self.clip = 0.25\n",
    "     \n",
    "    def get_enc_output_size(self):\n",
    "        return self.enc_hidden_size * (int(self.enc_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_output_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_state_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1) * self.dec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,\n",
    "                                      embedding_dim=hp.enc_emb_size,\n",
    "                                      padding_idx=PAD_TOKEN)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=hp.enc_emb_size,\n",
    "                          hidden_size=hp.enc_hidden_size,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.enc_dropout,\n",
    "                          num_layers=hp.enc_layers,\n",
    "                          bidirectional=hp.enc_bidirectional)\n",
    "        self.num_directions = (int(hp.enc_bidirectional) + 1)\n",
    "        self.num_layers = hp.enc_layers\n",
    "        self.hidden_size = hp.enc_hidden_size\n",
    "\n",
    "    def forward(self, input_batch, hidden=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        if (hidden is None):\n",
    "            hidden = self.init_hidden(input_batch.size(0))\n",
    "        embedded = self.embedding(input_batch).contiguous()\n",
    "        outputs, _ = self.gru(embedded, hidden)\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hp.get_enc_output_size() + hp.get_dec_state_size(), 1)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers * directions, B, HD)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (B, T, HE)\n",
    "        :param encoder_output_lengths:\n",
    "            lengths of encoded sentences, in shape (B,)\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        max_len = encoder_outputs.size(1)\n",
    "\n",
    "        hidden = hidden.transpose(0, 1).contiguous() # [B, l * d, HD]\n",
    "        hidden = hidden.view(batch_size, -1) # [B, HD * layers * directions]\n",
    "        hidden = hidden.repeat(max_len, 1, 1).transpose(0, 1) # [B, T, HD * layers * directions]\n",
    "        \n",
    "        energies = self.attn(torch.cat((hidden, encoder_outputs), -1)).view(batch_size, max_len) # [B, T, 1]\n",
    "\n",
    "        \n",
    "        energies = energies * mask\n",
    "        energies = F.softmax(energies)\n",
    "        energies = energies * mask\n",
    "        energies = energies / energies.sum(1).view(-1, 1) # [B, T]\n",
    "        \n",
    "        return (energies.view(batch_size, max_len, 1) * encoder_outputs).sum(1) #[B, HE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hp):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hp.dec_emb_size, padding_idx=PAD_TOKEN)\n",
    "        self.attn = Attn(hp)\n",
    "        self.gru = nn.GRU(input_size=hp.dec_emb_size + hp.get_enc_output_size(),\n",
    "                          hidden_size=hp.dec_hidden_size,\n",
    "                          num_layers=hp.dec_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.dec_dropout,\n",
    "                          bidirectional=hp.dec_bidirectional)\n",
    "        self.out = nn.Linear(hp.get_dec_output_size(), output_size)\n",
    "\n",
    "        self.num_layers = hp.dec_layers\n",
    "        self.num_directions = int(hp.dec_bidirectional) + 1\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hp.dec_hidden_size\n",
    "\n",
    "\n",
    "    def forward(self, input, encoder_outputs, mask, hidden=None):\n",
    "        \"\"\"\n",
    "            input: [B,]\n",
    "            encoder_outputs: [B, T, HE]\n",
    "            hidden: [B, layers * directions, HD]\n",
    "        \"\"\"\n",
    "        batch_size = input.size(0)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "        embedded = self.embedding(input)\n",
    "        context = self.attn(hidden, encoder_outputs, mask).view(batch_size, -1)\n",
    "        rnn_input = torch.cat((embedded, context), -1).view(batch_size, 1, -1)\n",
    "        \n",
    "        output, next_hidden = self.gru(rnn_input, hidden)\n",
    "        output = self.out(output).view(batch_size, self.output_size)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        \n",
    "        return output, next_hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, source_lang, target_lang, hp):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.encoder = EncoderRNN(source_lang.input_size(), hp)\n",
    "        self.decoder = DecoderRNN(target_lang.input_size(), target_lang.input_size(), hp)\n",
    "        self.max_length = hp.max_length\n",
    "        self.criterion = nn.NLLLoss(reduce=False, size_average=False)\n",
    "\n",
    "    def translate(self, input_batch, mask):\n",
    "        batch_size = input_batch.size()[0]\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "        word_indices = []\n",
    "        \n",
    "        dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "        \n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        MAX_LENGTH = 100\n",
    "        translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "        converged = np.zeros(shape=(batch_size, ))\n",
    "        for i in range(MAX_LENGTH):     \n",
    "            output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "            _, output_idx = torch.max(output, -1)\n",
    "                \n",
    "            for j in range(batch_size):\n",
    "                if translations[j][-1] != self.target_lang.get_eos():\n",
    "                    translations[j].append(output_idx[j].data[0])\n",
    "                else:\n",
    "                    converged[j] = True\n",
    "            dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "            \n",
    "            if use_cuda:\n",
    "                dec_input = dec_input.cuda()\n",
    "            \n",
    "            \n",
    "            if np.all(converged):\n",
    "                break\n",
    "        return [' '.join(map(self.target_lang.get_word, elem)) for elem in translations]\n",
    "    \n",
    "    def forward(self, input_batch, mask, output_batch, out_mask):\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "        loss = 0\n",
    "        outputs = []\n",
    "        for i in range(out_mask.size()[1] - 1):\n",
    "           \n",
    "            output, hidden = self.decoder(output_batch[:, i], encoder_outputs, mask=mask, hidden=hidden)\n",
    "            loss += (self.criterion(output, output_batch[:, i + 1]) * out_mask[:, i + 1]).sum()\n",
    "        \n",
    "        loss /= out_mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import gc\n",
    "def trainS2S(s2s, batch_sampler, hp):\n",
    "    s2s.train()\n",
    "    losses = []\n",
    "    optimizer = torch.optim.Adam(s2s.parameters(), lr=hp.learning_rate)\n",
    "    \n",
    "    for epoch_id in range(hp.n_epochs):\n",
    "        for batch_id, ((input, input_mask), (output, output_mask)) in tqdm.tqdm(enumerate(batch_sampler)):\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                input_mask = input_mask.cuda()\n",
    "                output = output.cuda()\n",
    "                output_mask = output_mask.cuda()\n",
    "\n",
    "\n",
    "            loss = s2s(input, input_mask, output, output_mask)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(s2s.parameters(), hp.clip)\n",
    "            optimizer.step()\n",
    "            if use_cuda:\n",
    "                losses.append(loss.cpu().data[0])\n",
    "            else:\n",
    "                 losses.append(loss.data[0])\n",
    "            \n",
    "            if (batch_id * batch_sampler.batch_size) % 1000 == 0:\n",
    "                display.clear_output(wait=True)\n",
    "                print(\"Last 10 loses mean\", np.mean(losses[-10:]))\n",
    "                plt.plot(losses)\n",
    "                plt.show()\n",
    "        \n",
    "        torch.save(s2s.state_dict(), \"last_state.ckpt\")\n",
    "        gc.collect()\n",
    "        if use_cuda:\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dataset = {\n",
    "    \"train\": ( [\"'a 'a d y r\", \"'a 'a h b ckh\"], [\"a a d i r\", \"e a h a v k h a\"]),\n",
    "    \"test\":None,\n",
    "    \"dev\":None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, s2s, batch_sampler, hp):\n",
    "        self.hp = hp\n",
    "        self.s2s = s2s\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.losses = []\n",
    "        self.bleu = []\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def for_translation(x, x_mask):\n",
    "        if not use_cuda:\n",
    "            x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "            x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "        else:\n",
    "            x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous().cuda()\n",
    "            x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous().cuda()\n",
    "\n",
    "        return x, x_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def run_translation(model, test_data, batch_size):\n",
    "        result = []\n",
    "        for pos in range(0, test_data.shape[0], batch_size):\n",
    "            batch, mask = Trainer.for_translation(*src.convert_batch(test_data[pos:pos + batch_size]))\n",
    "            translated = model.translate(batch, mask)\n",
    "            result.extend(translated)\n",
    "\n",
    "\n",
    "        real_result = []\n",
    "        for sent in result:\n",
    "            sent = sent.split(\" \")[1:-1]\n",
    "            real_result.append(\" \".join(sent))\n",
    "        return real_result\n",
    "    \n",
    "    def validate(self):\n",
    "        model = self.s2s\n",
    "        test_data = self.batch_sampler.dev[0]\n",
    "        translation = self.run_translation(model, test_data, hp.batch_size)\n",
    "        real_translation = [' '.join(x) for x in self.batch_sampler.dev[1]]\n",
    "        return bleu_from_lines(real_translation, translation)\n",
    "    \n",
    "    def train(self):\n",
    "        s2s = self.s2s\n",
    "        batch_sampler = self.batch_sampler\n",
    "        hp = self.hp\n",
    "        losses = self.losses\n",
    "        bleu = self.bleu\n",
    "        \n",
    "        s2s.train()\n",
    "        optimizer = torch.optim.Adam(s2s.parameters(), lr=hp.learning_rate)\n",
    "        for epoch_id in range(hp.n_epochs):\n",
    "            print(\"Len: \", len(batch_sampler))\n",
    "            for batch_id, ((input, input_mask), (output, output_mask)) in \\\n",
    "                tqdm.tqdm(enumerate(batch_sampler), total=len(batch_sampler)):\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "                    input_mask = input_mask.cuda()\n",
    "                    output = output.cuda()\n",
    "                    output_mask = output_mask.cuda()\n",
    "\n",
    "\n",
    "                loss = s2s(input, input_mask, output, output_mask)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm(s2s.parameters(), hp.clip)\n",
    "                optimizer.step()\n",
    "                if use_cuda:\n",
    "                    losses.append(loss.cpu().data[0])\n",
    "                else:\n",
    "                     losses.append(loss.data[0])\n",
    "\n",
    "                if (batch_id * batch_sampler.batch_size) % 1000 == 0:\n",
    "                    display.clear_output(wait=True)\n",
    "                    print(\"Last 10 loses mean\", np.mean(losses[-10:]))\n",
    "                    plt.plot(losses)\n",
    "                    plt.show()\n",
    "            s2s.eval()\n",
    "            bleu.append(self.validate())\n",
    "            print(\"Bleu: \", bleu[-1])\n",
    "            s2s.train()\n",
    "\n",
    "            torch.save(s2s.state_dict(), \"last_state.ckpt\")\n",
    "            gc.collect()\n",
    "            if use_cuda:\n",
    "                torch.cuda.empty_cache()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp.batch_size = 100\n",
    "batch_sampler = BatchSampler(d, src, tgt, hp.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.n_epochs = 5\n",
    "trainer = Trainer(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 10 loses mean 0.506020635366\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d194656a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:04,  3.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-21d21c7948cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-e5a575361ef1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-6af3192bff70>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_batch, mask, output_batch, out_mask)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-01ef9f46e4b6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, encoder_outputs, mask, hidden)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5329257566948042]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thefacetakt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28348408067920816"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
