{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_utils import pad_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "BOS_TOKEN = 1\n",
    "NAN_TOKEN = 2\n",
    "EOS_TOKEN = 3\n",
    "SPECIAL_TOKENS = 4\n",
    "OCCURING_SPECIAL_TOKENS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class DatasetFilesLocation:\n",
    "#     def __init__(self, train, dev, test, tokens):\n",
    "#         self.train = train\n",
    "#         self.dev = dev\n",
    "#         self.test = test\n",
    "#         self.tokens = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# src_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/src.train.txt',\n",
    "#     dev='../preprocessed/he-en/src.dev.txt',\n",
    "#     test='../preprocessed/he-en/src.test.txt',\n",
    "#     tokens='../preprocessed/he-en/src.tokens.txt')\n",
    "\n",
    "# trg_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/tgt.train.txt',\n",
    "#     dev='../preprocessed/he-en/tgt.dev.txt',\n",
    "#     test='../preprocessed/he-en/tgt.test.txt',\n",
    "#     tokens='../preprocessed/he-en/tgt.tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, tokens_file_path):\n",
    "        self.idx2word = defaultdict(lambda: \"<NAN/>\")\n",
    "        self.word2idx = defaultdict(lambda: NAN_TOKEN)\n",
    "        with open(tokens_file_path) as tokens_file:\n",
    "            tokens = tokens_file.readlines()\n",
    "            for word, idx in map(lambda x: x.strip().split(), tokens):\n",
    "                idx = int(idx) + SPECIAL_TOKENS\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "            assert PAD_TOKEN not in self.idx2word\n",
    "            assert BOS_TOKEN not in self.idx2word\n",
    "            assert EOS_TOKEN not in self.idx2word\n",
    "            for word, idx in [('<PAD/>', PAD_TOKEN), ('<S>', BOS_TOKEN),\n",
    "                              ('</S>', EOS_TOKEN), ('<NAN/>', NAN_TOKEN)]:\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "    \n",
    "    def convert(self, sentence):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.strip().split()\n",
    "        return [BOS_TOKEN] + list(map(lambda word: self.word2idx[word], sentence)) + [EOS_TOKEN]\n",
    "    \n",
    "    def convert_batch(self, sents):\n",
    "        \n",
    "        batch_max_length = 0\n",
    "        for sent in sents:\n",
    "            batch_max_length = max(batch_max_length, len(sent))\n",
    "            \n",
    "#         print(batch_max_length)\n",
    "        \n",
    "        result = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        mask = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        \n",
    "        for sent_id, sent in enumerate(sents):\n",
    "            sent = sent[:batch_max_length]\n",
    "            current = self.convert(sent)\n",
    "            result[sent_id, :len(current)] = current\n",
    "            mask[sent_id, :len(current)] = 1.0\n",
    "            \n",
    "        return result, mask\n",
    "    \n",
    "    def input_size(self):\n",
    "        return len(self.idx2word.keys())\n",
    "    \n",
    "    def output_size(self):\n",
    "        return len(self.idx2word.keys())# - SPECIAL_TOKENS + OCCURING_SPECIAL_TOKENS\n",
    "    \n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]# + SPECIAL_TOKENS - OCCURING_SPECIAL_TOKENS]\n",
    "    \n",
    "    def get_eos(self):\n",
    "        return EOS_TOKEN #OCCURING_SPECIAL_TOKENS - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as file:\n",
    "        return list(map(lambda s: s.strip().split(\" \"), file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_problem(path, n_sents=None):\n",
    "    modes = [\"train\",  \"dev\", \"test\"]\n",
    "    datasets = [\"src\", \"tgt\"]\n",
    "    file_template = \"{}.{}.txt\"\n",
    "    \n",
    "    result = {}\n",
    "    for mode in modes:\n",
    "        src = read_file(os.path.join(path, file_template.format(\"src\", mode)))\n",
    "        tgt = read_file(os.path.join(path, file_template.format(\"tgt\", mode)))\n",
    "        \n",
    "        assert len(src) == len(tgt)\n",
    "        \n",
    "#         result[mode] = list(zip(src, tgt))\n",
    "        if n_sents is not None:\n",
    "            result[mode] = (src[:n_sents], tgt[:n_sents])\n",
    "        else:\n",
    "            result[mode] = (src, tgt)\n",
    "        \n",
    "    src_lang = Lang(os.path.join(path, file_template.format(\"src\", \"tokens\")))\n",
    "    tgt_lang = Lang(os.path.join(path, file_template.format(\"tgt\", \"tokens\")))\n",
    "    return result, src_lang, tgt_lang\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d, src, tgt = read_problem(\"../preprocessed/he-en/\", n_sents=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(d[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  6.,  4., 24., 88., 39.,  3.,  0.],\n",
       "        [ 1.,  6.,  6.,  6., 48., 80., 28.,  3.],\n",
       "        [ 1.,  6.,  6., 14., 17.,  3.,  0.,  0.]]),\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.convert_batch(d[\"test\"][0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class BatchSampler:\n",
    "    def __init__(self, dataset, src_lang, tgt_lang, batch_size):\n",
    "        self.train = dataset[\"train\"]\n",
    "        self.dev = dataset[\"dev\"]\n",
    "        self.test = dataset[\"test\"]\n",
    "        \n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train)//self.batch_size + 1\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.position = 0\n",
    "        return self\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = 0\n",
    "        \n",
    "    \n",
    "    def get_batch(self, x, y):\n",
    "        x, x_mask = self.src_lang.convert_batch(x)\n",
    "        y, y_mask = self.tgt_lang.convert_batch(y)\n",
    "        \n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        y = Variable(torch.from_numpy(y.astype(np.int64))).contiguous()\n",
    "        y_mask = Variable(torch.from_numpy(y_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        return (x, x_mask), (y, y_mask)\n",
    "    \n",
    "        \n",
    "    def __next__(self):\n",
    "            if self.position >= len(self.train[0]):\n",
    "                raise StopIteration()\n",
    "                \n",
    "            x = self.train[0][self.position:self.position + self.batch_size]\n",
    "            y = self.train[1][self.position:self.position + self.batch_size]\n",
    "            \n",
    "            self.position += self.batch_size\n",
    "            return self.get_batch(x, y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def form_batch_variable(lang, sentences):\n",
    "#     sentences = list(map(lang.convert, sentences))\n",
    "#     sentences = sorted(sentences, key=len, reverse=True)\n",
    "#     lengths = list(map(len, sentences))\n",
    "#     sentences = list(map(lambda sentence: Variable(torch.LongTensor(sentence)), sentences))\n",
    "#     batch = pad_sequence(sentences, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#     if use_cuda:\n",
    "#         batch = batch.cuda()\n",
    "#     return torch.nn.utils.rnn.pack_padded_sequence(batch, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.max_length = 100\n",
    "        self.enc_hidden_size = 128\n",
    "        self.enc_emb_size = 128\n",
    "        self.enc_layers = 1\n",
    "        self.enc_dropout = 0.1\n",
    "        self.enc_bidirectional = True\n",
    "        \n",
    "        self.dec_hidden_size = 128\n",
    "        self.dec_emb_size = self.enc_emb_size\n",
    "        self.dec_layers = 1\n",
    "        self.dec_dropout = 0.1\n",
    "        self.dec_bidirectional = True\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.learning_rate = 0.001\n",
    "        self.clip = 0.25\n",
    "     \n",
    "    def get_enc_output_size(self):\n",
    "        return self.enc_hidden_size * (int(self.enc_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_output_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_state_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1) * self.dec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,\n",
    "                                      embedding_dim=hp.enc_emb_size,\n",
    "                                      padding_idx=PAD_TOKEN)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=hp.enc_emb_size,\n",
    "                          hidden_size=hp.enc_hidden_size,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.enc_dropout,\n",
    "                          num_layers=hp.enc_layers,\n",
    "                          bidirectional=hp.enc_bidirectional)\n",
    "        self.num_directions = (int(hp.enc_bidirectional) + 1)\n",
    "        self.num_layers = hp.enc_layers\n",
    "        self.hidden_size = hp.enc_hidden_size\n",
    "\n",
    "    def forward(self, input_batch, hidden=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        if (hidden is None):\n",
    "            hidden = self.init_hidden(input_batch.size(0))\n",
    "        embedded = self.embedding(input_batch).contiguous()\n",
    "#         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, _ = self.gru(embedded, hidden)\n",
    "#         outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             outputs, padding_value=PAD_TOKEN, batch_first=True)\n",
    "#         print(outputs.size())\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mask(lengths):\n",
    "#     batch_size = lengths.size(0)\n",
    "#     max_len = lengths[0]\n",
    "#     time = torch.arange(max_len).repeat(batch_size, 1)\n",
    "#     lengths = lengths.view(-1, 1).type(torch.FloatTensor)\n",
    "#     if (use_cuda):\n",
    "#         time = time.cuda()\n",
    "#         lengths = lengths.cuda()\n",
    "\n",
    "#     mask = Variable((time < lengths).type(torch.FloatTensor))\n",
    "#     if (use_cuda):\n",
    "#         return mask.cuda()\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hp.get_enc_output_size() + hp.get_dec_state_size(), 1)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers * directions, B, HD)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (B, T, HE)\n",
    "        :param encoder_output_lengths:\n",
    "            lengths of encoded sentences, in shape (B,)\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        max_len = encoder_outputs.size(1)\n",
    "\n",
    "        hidden = hidden.transpose(0, 1).contiguous() # [B, l * d, HD]\n",
    "        hidden = hidden.view(batch_size, -1) # [B, HD * layers * directions]\n",
    "        hidden = hidden.repeat(max_len, 1, 1).transpose(0, 1) # [B, T, HD * layers * directions]\n",
    "        \n",
    "        energies = self.attn(torch.cat((hidden, encoder_outputs), -1)).view(batch_size, max_len) # [B, T, 1]\n",
    "\n",
    "        \n",
    "        energies = energies * mask\n",
    "        energies = F.softmax(energies)\n",
    "        energies = energies * mask\n",
    "        energies = energies / energies.sum(1).view(-1, 1) # [B, T]\n",
    "        \n",
    "        return (energies.view(batch_size, max_len, 1) * encoder_outputs).sum(1) #[B, HE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hp):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hp.dec_emb_size, padding_idx=PAD_TOKEN)\n",
    "        self.attn = Attn(hp)\n",
    "        self.gru = nn.GRU(input_size=hp.dec_emb_size + hp.get_enc_output_size(),\n",
    "                          hidden_size=hp.dec_hidden_size,\n",
    "                          num_layers=hp.dec_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.dec_dropout,\n",
    "                          bidirectional=hp.dec_bidirectional)\n",
    "        self.out = nn.Linear(hp.get_dec_output_size(), output_size)\n",
    "\n",
    "        self.num_layers = hp.dec_layers\n",
    "        self.num_directions = int(hp.dec_bidirectional) + 1\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hp.dec_hidden_size\n",
    "\n",
    "\n",
    "    def forward(self, input, encoder_outputs, mask, hidden=None):\n",
    "        \"\"\"\n",
    "            input: [B,]\n",
    "            encoder_outputs: [B, T, HE]\n",
    "            hidden: [B, layers * directions, HD]\n",
    "        \"\"\"\n",
    "        batch_size = input.size(0)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "#         embedded = self.embedding(input.view(-1, 1))\n",
    "        embedded = self.embedding(input)\n",
    "#         print(embedded.size())\n",
    "        context = self.attn(hidden, encoder_outputs, mask).view(batch_size, -1)\n",
    "#         print(context.size())\n",
    "        rnn_input = torch.cat((embedded, context), -1).view(batch_size, 1, -1)\n",
    "        \n",
    "#         print(\"RNN input\", rnn_input.size())\n",
    "        output, next_hidden = self.gru(rnn_input, hidden)\n",
    "        output = self.out(output).view(batch_size, self.output_size)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        \n",
    "        return output, next_hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, source_lang, target_lang, hp):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.encoder = EncoderRNN(source_lang.input_size(), hp)\n",
    "        self.decoder = DecoderRNN(target_lang.input_size(), target_lang.input_size(), hp)\n",
    "        self.max_length = hp.max_length\n",
    "        self.criterion = nn.NLLLoss(reduce=False, size_average=False)\n",
    "        \n",
    "#     def translate(self, input_seq):\n",
    "\n",
    "# #         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "# #             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "# #         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "# #         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "# #         mask = get_mask(encoder_output_lengths)\n",
    "        \n",
    "# #         batch_size = input_batch.size(0)\n",
    "        \n",
    "#         dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "#         if use_cuda:\n",
    "#             dec_input = dec_input.cuda()\n",
    "# #         max_length = min(self.max_length, 2 * encoder_output_lengths[0])\n",
    "#         hidden = None\n",
    "#         translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "#         for i in range(max_length):\n",
    "#             output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "#             _, output_idx = torch.max(output, -1)\n",
    "#             for j in range(batch_size):\n",
    "#                 if translations[j][-1] != target_lang.get_eos():\n",
    "#                     translations[j].append(output_idx[j].data[0])\n",
    "#             dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "#             if use_cuda:\n",
    "#                 dec_input = dec_input.cuda()\n",
    "#         return [' '.join(map(target_lang.get_word, elem)) for elem in translations]\n",
    "\n",
    "    def translate(self, input_batch, mask):\n",
    "        batch_size = input_batch.size()[0]\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "        word_indices = []\n",
    "#         outputs = []\n",
    "        \n",
    "        dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "        \n",
    "        MAX_LENGTH = 100\n",
    "        translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "        converged = np.zeros(shape=(batch_size, ))\n",
    "        for i in range(MAX_LENGTH):     \n",
    "            output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "            _, output_idx = torch.max(output, -1)\n",
    "                \n",
    "            for j in range(batch_size):\n",
    "                if translations[j][-1] != self.target_lang.get_eos():\n",
    "                    translations[j].append(output_idx[j].data[0])\n",
    "                else:\n",
    "                    converged[j] = True\n",
    "            dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "            \n",
    "            \n",
    "            if np.all(converged):\n",
    "                break\n",
    "            \n",
    "         \n",
    "            \n",
    "#         return translations\n",
    "        return [' '.join(map(self.target_lang.get_word, elem)) for elem in translations]\n",
    "    \n",
    "    def forward(self, input_batch, mask, output_batch, out_mask):\n",
    "#         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "#         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "#         mask = get_mask(encoder_output_lengths)\n",
    "#         batch_size = input_batch.size(0)\n",
    "        \n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "#         output_batch, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(output_seq,\n",
    "#                                                                               batch_first=True,\n",
    "#                                                                               padding_value=PAD_TOKEN)\n",
    "#         output_lengths = torch.LongTensor(output_lengths)\n",
    "#         out_mask = get_mask(output_lengths)\n",
    "        loss = 0\n",
    "        outputs = []\n",
    "        for i in range(out_mask.size()[1] - 1):\n",
    "           \n",
    "            output, hidden = self.decoder(output_batch[:, i], encoder_outputs, mask=mask, hidden=hidden)\n",
    "            loss += (self.criterion(output, output_batch[:, i + 1]) * out_mask[:, i + 1]).sum()\n",
    "        \n",
    "        loss /= out_mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def trainS2S(s2s, batch_sampler, hp):\n",
    "    s2s.train()\n",
    "    losses = []\n",
    "#     hp.batch_size = 100\n",
    "#     assert(len(src) == len(trg))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(s2s.parameters(), lr=hp.learning_rate)\n",
    "    \n",
    "    for epoch_id in range(hp.n_epochs):\n",
    "#         batch_sampler.reset()\n",
    "        for batch_id, ((input, input_mask), (output, output_mask)) in tqdm.tqdm(enumerate(batch_sampler)):\n",
    "#         for i in tqdm.tqdm(range(0, len(src), hp.batch_size)):\n",
    "#             src_batch = form_batch_variable(source_lang, src[i : i + hp.batch_size])\n",
    "#             trg_batch = form_batch_variable(target_lang, trg[i : i + hp.batch_size])\n",
    "\n",
    "\n",
    "            loss = s2s(input, input_mask, output, output_mask)\n",
    "#             if (batch_id // hp.batch_size) % 100 == 0:\n",
    "#                 print(loss.data[0])\n",
    "            losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(s2s.parameters(), hp.clip)\n",
    "            optimizer.step()\n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_dataset = {\n",
    "    \"train\": ( [\"'a 'a d y r\", \"'a 'a h b ckh\"], [\"a a d i r\", \"e a h a v k h a\"]),\n",
    "    \"test\":None,\n",
    "    \"dev\":None\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(dummy_dataset, src, tgt, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "1it [00:00, 11.31it/s]\n",
      "1it [00:00,  9.46it/s]\n",
      "1it [00:00,  9.57it/s]\n",
      "1it [00:00,  9.44it/s]\n",
      "1it [00:00, 10.97it/s]\n",
      "1it [00:00,  9.48it/s]\n",
      "1it [00:00,  8.72it/s]\n",
      "1it [00:00, 10.21it/s]\n",
      "1it [00:00,  9.98it/s]\n",
      "1it [00:00,  9.55it/s]\n",
      "1it [00:00,  9.13it/s]\n",
      "1it [00:00,  9.98it/s]\n",
      "1it [00:00, 10.38it/s]\n",
      "1it [00:00, 10.30it/s]\n",
      "1it [00:00,  9.91it/s]\n",
      "1it [00:00,  9.63it/s]\n",
      "1it [00:00,  9.30it/s]\n",
      "1it [00:00, 10.33it/s]\n",
      "1it [00:00, 10.37it/s]\n",
      "1it [00:00, 10.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.002084732055664,\n",
       " 2.6538538932800293,\n",
       " 2.3275082111358643,\n",
       " 2.0254383087158203,\n",
       " 1.7580164670944214,\n",
       " 1.5345267057418823,\n",
       " 1.3483034372329712,\n",
       " 1.1852436065673828,\n",
       " 1.0418860912322998,\n",
       " 0.919980525970459,\n",
       " 0.8147149085998535,\n",
       " 0.7196149826049805,\n",
       " 0.632966160774231,\n",
       " 0.5549482703208923,\n",
       " 0.48462098836898804,\n",
       " 0.42104572057724,\n",
       " 0.3653680384159088,\n",
       " 0.3198111057281494,\n",
       " 0.2834157645702362,\n",
       " 0.250639945268631]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.batch_size = 100\n",
    "hp.n_epochs = 20\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 128, padding_idx=0)\n",
       "    (gru): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 128, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(384, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(d, src, tgt, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "33it [00:05,  6.02it/s]\n"
     ]
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.n_epochs = 1\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "losses = trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2913467940>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29138a91d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 32, padding_idx=0)\n",
       "    (gru): GRU(32, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 32, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(288, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> a k h a k h a </S>', '<S> a k h a k h a </S>']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> a k h a k h a </S>', '<S> a k h a k h a </S>']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"'l m d r d\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     1     6     6    17    88    49     3\n",
       "     1     6     6    24    14    15     3\n",
       " [torch.LongTensor of size 2x7], Variable containing:\n",
       "     1     1     1     1     1     1     1\n",
       "     1     1     1     1     1     1     1\n",
       " [torch.FloatTensor of size 2x7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_translation(x, x_mask):\n",
    "    x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "    x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "    \n",
    "    \n",
    "    return x, x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dummy_dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [torch]",
   "language": "python",
   "name": "Python [torch]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
