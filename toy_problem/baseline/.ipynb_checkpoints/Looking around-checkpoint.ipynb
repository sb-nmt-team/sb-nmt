{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch_utils import pad_sequence\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "BOS_TOKEN = 1\n",
    "NAN_TOKEN = 2\n",
    "EOS_TOKEN = 3\n",
    "SPECIAL_TOKENS = 4\n",
    "OCCURING_SPECIAL_TOKENS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class DatasetFilesLocation:\n",
    "#     def __init__(self, train, dev, test, tokens):\n",
    "#         self.train = train\n",
    "#         self.dev = dev\n",
    "#         self.test = test\n",
    "#         self.tokens = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# src_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/src.train.txt',\n",
    "#     dev='../preprocessed/he-en/src.dev.txt',\n",
    "#     test='../preprocessed/he-en/src.test.txt',\n",
    "#     tokens='../preprocessed/he-en/src.tokens.txt')\n",
    "\n",
    "# trg_files = DatasetFilesLocation(\n",
    "#     train='../preprocessed/he-en/tgt.train.txt',\n",
    "#     dev='../preprocessed/he-en/tgt.dev.txt',\n",
    "#     test='../preprocessed/he-en/tgt.test.txt',\n",
    "#     tokens='../preprocessed/he-en/tgt.tokens.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, tokens_file_path):\n",
    "        self.idx2word = defaultdict(lambda: \"<NAN/>\")\n",
    "        self.word2idx = defaultdict(lambda: NAN_TOKEN)\n",
    "        with open(tokens_file_path) as tokens_file:\n",
    "            tokens = tokens_file.readlines()\n",
    "            for word, idx in map(lambda x: x.strip().split(), tokens):\n",
    "                idx = int(idx) + SPECIAL_TOKENS\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "            assert PAD_TOKEN not in self.idx2word\n",
    "            assert BOS_TOKEN not in self.idx2word\n",
    "            assert EOS_TOKEN not in self.idx2word\n",
    "            for word, idx in [('<PAD/>', PAD_TOKEN), ('<S>', BOS_TOKEN),\n",
    "                              ('</S>', EOS_TOKEN), ('<NAN/>', NAN_TOKEN)]:\n",
    "                self.idx2word[idx] = word\n",
    "                self.word2idx[word] = idx\n",
    "    \n",
    "    def convert(self, sentence):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.strip().split()\n",
    "        return [BOS_TOKEN] + list(map(lambda word: self.word2idx[word], sentence)) + [EOS_TOKEN]\n",
    "    \n",
    "    def convert_batch(self, sents):\n",
    "        \n",
    "        batch_max_length = 0\n",
    "        for sent in sents:\n",
    "            batch_max_length = max(batch_max_length, len(sent))\n",
    "            \n",
    "#         print(batch_max_length)\n",
    "        \n",
    "        result = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        mask = np.zeros(shape=(len(sents), batch_max_length + 1 + 1))\n",
    "        \n",
    "        for sent_id, sent in enumerate(sents):\n",
    "            sent = sent[:batch_max_length]\n",
    "            current = self.convert(sent)\n",
    "            result[sent_id, :len(current)] = current\n",
    "            mask[sent_id, :len(current)] = 1.0\n",
    "            \n",
    "        return result, mask\n",
    "    \n",
    "    def input_size(self):\n",
    "        return len(self.idx2word.keys())\n",
    "    \n",
    "    def output_size(self):\n",
    "        return len(self.idx2word.keys())# - SPECIAL_TOKENS + OCCURING_SPECIAL_TOKENS\n",
    "    \n",
    "    def get_word(self, idx):\n",
    "        return self.idx2word[idx]# + SPECIAL_TOKENS - OCCURING_SPECIAL_TOKENS]\n",
    "    \n",
    "    def get_eos(self):\n",
    "        return EOS_TOKEN #OCCURING_SPECIAL_TOKENS - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename) as file:\n",
    "        return list(map(lambda s: s.strip().split(\" \"), file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_problem(path):\n",
    "    modes = [\"train\",  \"dev\", \"test\"]\n",
    "    datasets = [\"src\", \"tgt\"]\n",
    "    file_template = \"{}.{}.txt\"\n",
    "    \n",
    "    result = {}\n",
    "    for mode in modes:\n",
    "        src = read_file(os.path.join(path, file_template.format(\"src\", mode)))\n",
    "        tgt = read_file(os.path.join(path, file_template.format(\"tgt\", mode)))\n",
    "        \n",
    "        assert len(src) == len(tgt)\n",
    "        \n",
    "#         result[mode] = list(zip(src, tgt))\n",
    "        result[mode] = (src, tgt)\n",
    "        \n",
    "    src_lang = Lang(os.path.join(path, file_template.format(\"src\", \"tokens\")))\n",
    "    tgt_lang = Lang(os.path.join(path, file_template.format(\"tgt\", \"tokens\")))\n",
    "    return result, src_lang, tgt_lang\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d, src, tgt = read_problem(\"../preprocessed/he-en/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  6.,  4., 24., 88., 39.,  3.,  0.],\n",
       "        [ 1.,  6.,  6.,  6., 48., 80., 28.,  3.],\n",
       "        [ 1.,  6.,  6., 14., 17.,  3.,  0.,  0.]]),\n",
       " array([[1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.convert_batch(d[\"test\"][0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class BatchSampler:\n",
    "    def __init__(self, dataset, src_lang, tgt_lang, batch_size):\n",
    "        self.train = dataset[\"train\"]\n",
    "        self.dev = dataset[\"dev\"]\n",
    "        self.test = dataset[\"test\"]\n",
    "        \n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train)//self.batch_size + 1\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.position = 0\n",
    "        return self\n",
    "    \n",
    "    def reset(self):\n",
    "        self.position = 0\n",
    "        \n",
    "    \n",
    "    def get_batch(self, x, y):\n",
    "        x, x_mask = self.src_lang.convert_batch(x)\n",
    "        y, y_mask = self.tgt_lang.convert_batch(y)\n",
    "        \n",
    "        x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "        x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        y = Variable(torch.from_numpy(y.astype(np.int64))).contiguous()\n",
    "        y_mask = Variable(torch.from_numpy(y_mask.astype(np.float32))).contiguous()\n",
    "        \n",
    "        return (x, x_mask), (y, y_mask)\n",
    "    \n",
    "        \n",
    "    def __next__(self):\n",
    "            if self.position >= len(self.train[0]):\n",
    "                raise StopIteration()\n",
    "                \n",
    "            x = self.train[0][self.position:self.position + self.batch_size]\n",
    "            y = self.train[1][self.position:self.position + self.batch_size]\n",
    "            \n",
    "            self.position += self.batch_size\n",
    "            return self.get_batch(x, y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def form_batch_variable(lang, sentences):\n",
    "#     sentences = list(map(lang.convert, sentences))\n",
    "#     sentences = sorted(sentences, key=len, reverse=True)\n",
    "#     lengths = list(map(len, sentences))\n",
    "#     sentences = list(map(lambda sentence: Variable(torch.LongTensor(sentence)), sentences))\n",
    "#     batch = pad_sequence(sentences, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#     if use_cuda:\n",
    "#         batch = batch.cuda()\n",
    "#     return torch.nn.utils.rnn.pack_padded_sequence(batch, lengths, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self):\n",
    "        self.max_length = 100\n",
    "        self.enc_hidden_size = 128\n",
    "        self.enc_emb_size = 128\n",
    "        self.enc_layers = 1\n",
    "        self.enc_dropout = 0.1\n",
    "        self.enc_bidirectional = True\n",
    "        \n",
    "        self.dec_hidden_size = 128\n",
    "        self.dec_emb_size = self.enc_emb_size\n",
    "        self.dec_layers = 1\n",
    "        self.dec_dropout = 0.1\n",
    "        self.dec_bidirectional = True\n",
    "        \n",
    "        self.batch_size = 100\n",
    "        self.learning_rate = 0.001\n",
    "        self.clip = 0.25\n",
    "     \n",
    "    def get_enc_output_size(self):\n",
    "        return self.enc_hidden_size * (int(self.enc_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_output_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1)\n",
    "    \n",
    "    def get_dec_state_size(self):\n",
    "        return self.dec_hidden_size * (int(self.dec_bidirectional) + 1) * self.dec_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hp):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size,\n",
    "                                      embedding_dim=hp.enc_emb_size,\n",
    "                                      padding_idx=PAD_TOKEN)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=hp.enc_emb_size,\n",
    "                          hidden_size=hp.enc_hidden_size,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.enc_dropout,\n",
    "                          num_layers=hp.enc_layers,\n",
    "                          bidirectional=hp.enc_bidirectional)\n",
    "        self.num_directions = (int(hp.enc_bidirectional) + 1)\n",
    "        self.num_layers = hp.enc_layers\n",
    "        self.hidden_size = hp.enc_hidden_size\n",
    "\n",
    "    def forward(self, input_batch, hidden=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "\n",
    "        if (hidden is None):\n",
    "            hidden = self.init_hidden(input_batch.size(0))\n",
    "        embedded = self.embedding(input_batch).contiguous()\n",
    "#         packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths, batch_first=True)\n",
    "        outputs, _ = self.gru(embedded, hidden)\n",
    "#         outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             outputs, padding_value=PAD_TOKEN, batch_first=True)\n",
    "#         print(outputs.size())\n",
    "        return outputs\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_mask(lengths):\n",
    "#     batch_size = lengths.size(0)\n",
    "#     max_len = lengths[0]\n",
    "#     time = torch.arange(max_len).repeat(batch_size, 1)\n",
    "#     lengths = lengths.view(-1, 1).type(torch.FloatTensor)\n",
    "#     if (use_cuda):\n",
    "#         time = time.cuda()\n",
    "#         lengths = lengths.cuda()\n",
    "\n",
    "#     mask = Variable((time < lengths).type(torch.FloatTensor))\n",
    "#     if (use_cuda):\n",
    "#         return mask.cuda()\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hp):\n",
    "        super(Attn, self).__init__()\n",
    "        self.attn = nn.Linear(hp.get_enc_output_size() + hp.get_dec_state_size(), 1)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        '''\n",
    "        :param hidden: \n",
    "            previous hidden state of the decoder, in shape (layers * directions, B, HD)\n",
    "        :param encoder_outputs:\n",
    "            encoder outputs from Encoder, in shape (B, T, HE)\n",
    "        :param encoder_output_lengths:\n",
    "            lengths of encoded sentences, in shape (B,)\n",
    "        :return\n",
    "            attention energies in shape (B,T)\n",
    "        '''\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        max_len = encoder_outputs.size(1)\n",
    "\n",
    "        hidden = hidden.transpose(0, 1).contiguous() # [B, l * d, HD]\n",
    "        hidden = hidden.view(batch_size, -1) # [B, HD * layers * directions]\n",
    "        hidden = hidden.repeat(max_len, 1, 1).transpose(0, 1) # [B, T, HD * layers * directions]\n",
    "        \n",
    "        energies = self.attn(torch.cat((hidden, encoder_outputs), -1)).view(batch_size, max_len) # [B, T, 1]\n",
    "\n",
    "        \n",
    "        energies = energies * mask\n",
    "        energies = F.softmax(energies)\n",
    "        energies = energies * mask\n",
    "        energies = energies / energies.sum(1).view(-1, 1) # [B, T]\n",
    "        \n",
    "        return (energies.view(batch_size, max_len, 1) * encoder_outputs).sum(1) #[B, HE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hp):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hp.dec_emb_size, padding_idx=PAD_TOKEN)\n",
    "        self.attn = Attn(hp)\n",
    "        self.gru = nn.GRU(input_size=hp.dec_emb_size + hp.get_enc_output_size(),\n",
    "                          hidden_size=hp.dec_hidden_size,\n",
    "                          num_layers=hp.dec_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=hp.dec_dropout,\n",
    "                          bidirectional=hp.dec_bidirectional)\n",
    "        self.out = nn.Linear(hp.get_dec_output_size(), output_size)\n",
    "\n",
    "        self.num_layers = hp.dec_layers\n",
    "        self.num_directions = int(hp.dec_bidirectional) + 1\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hp.dec_hidden_size\n",
    "\n",
    "\n",
    "    def forward(self, input, encoder_outputs, mask, hidden=None):\n",
    "        \"\"\"\n",
    "            input: [B,]\n",
    "            encoder_outputs: [B, T, HE]\n",
    "            hidden: [B, layers * directions, HD]\n",
    "        \"\"\"\n",
    "        batch_size = input.size(0)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "#         embedded = self.embedding(input.view(-1, 1))\n",
    "        embedded = self.embedding(input)\n",
    "#         print(embedded.size())\n",
    "        context = self.attn(hidden, encoder_outputs, mask).view(batch_size, -1)\n",
    "#         print(context.size())\n",
    "        rnn_input = torch.cat((embedded, context), -1).view(batch_size, 1, -1)\n",
    "        \n",
    "#         print(\"RNN input\", rnn_input.size())\n",
    "        output, next_hidden = self.gru(rnn_input, hidden)\n",
    "        output = self.out(output).view(batch_size, self.output_size)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        \n",
    "        return output, next_hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        result = Variable(torch.zeros(\n",
    "            self.num_layers * self.num_directions, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, source_lang, target_lang, hp):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.source_lang = source_lang\n",
    "        self.target_lang = target_lang\n",
    "        self.encoder = EncoderRNN(source_lang.input_size(), hp)\n",
    "        self.decoder = DecoderRNN(target_lang.input_size(), target_lang.input_size(), hp)\n",
    "        self.max_length = hp.max_length\n",
    "        self.criterion = nn.NLLLoss(reduce=False, size_average=False)\n",
    "        \n",
    "#     def translate(self, input_seq):\n",
    "\n",
    "# #         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "# #             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "# #         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "# #         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "# #         mask = get_mask(encoder_output_lengths)\n",
    "        \n",
    "# #         batch_size = input_batch.size(0)\n",
    "        \n",
    "#         dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "#         if use_cuda:\n",
    "#             dec_input = dec_input.cuda()\n",
    "# #         max_length = min(self.max_length, 2 * encoder_output_lengths[0])\n",
    "#         hidden = None\n",
    "#         translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "#         for i in range(max_length):\n",
    "#             output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "#             _, output_idx = torch.max(output, -1)\n",
    "#             for j in range(batch_size):\n",
    "#                 if translations[j][-1] != target_lang.get_eos():\n",
    "#                     translations[j].append(output_idx[j].data[0])\n",
    "#             dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "#             if use_cuda:\n",
    "#                 dec_input = dec_input.cuda()\n",
    "#         return [' '.join(map(target_lang.get_word, elem)) for elem in translations]\n",
    "\n",
    "    def translate(self, input_batch, mask):\n",
    "        batch_size = input_batch.size()[0]\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "        word_indices = []\n",
    "#         outputs = []\n",
    "        \n",
    "        dec_input = Variable(torch.LongTensor([BOS_TOKEN] * batch_size))\n",
    "        \n",
    "        MAX_LENGTH = 100\n",
    "        translations = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "        converged = np.zeros(shape=(batch_size, ))\n",
    "        for i in range(MAX_LENGTH):     \n",
    "            output, hidden = self.decoder(dec_input, encoder_outputs, mask=mask, hidden=hidden)\n",
    "            _, output_idx = torch.max(output, -1)\n",
    "                \n",
    "            for j in range(batch_size):\n",
    "                if translations[j][-1] != self.target_lang.get_eos():\n",
    "                    translations[j].append(output_idx[j].data[0])\n",
    "                else:\n",
    "                    converged[j] = True\n",
    "            dec_input = Variable(torch.LongTensor([tr[-1] for tr in translations]))\n",
    "            \n",
    "            \n",
    "            if np.all(converged):\n",
    "                break\n",
    "            \n",
    "         \n",
    "            \n",
    "#         return translations\n",
    "        return [' '.join(map(self.target_lang.get_word, elem)) for elem in translations]\n",
    "    \n",
    "    def forward(self, input_batch, mask, output_batch, out_mask):\n",
    "#         input_batch, input_lengths = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "#             input_seq, batch_first=True, padding_value=PAD_TOKEN)\n",
    "#         encoder_outputs, encoder_output_lengths = self.encoder(input_batch, input_lengths)\n",
    "        encoder_outputs = self.encoder(input_batch)\n",
    "#         encoder_output_lengths = torch.LongTensor(encoder_output_lengths)\n",
    "#         mask = get_mask(encoder_output_lengths)\n",
    "#         batch_size = input_batch.size(0)\n",
    "        \n",
    "        if use_cuda:\n",
    "            dec_input = dec_input.cuda()\n",
    "        \n",
    "        hidden = None\n",
    "        \n",
    "        logits = []\n",
    "#         output_batch, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(output_seq,\n",
    "#                                                                               batch_first=True,\n",
    "#                                                                               padding_value=PAD_TOKEN)\n",
    "#         output_lengths = torch.LongTensor(output_lengths)\n",
    "#         out_mask = get_mask(output_lengths)\n",
    "        loss = 0\n",
    "        outputs = []\n",
    "        for i in range(out_mask.size()[1] - 1):\n",
    "           \n",
    "            output, hidden = self.decoder(output_batch[:, i], encoder_outputs, mask=mask, hidden=hidden)\n",
    "            loss += (self.criterion(output, output_batch[:, i + 1]) * out_mask[:, i + 1]).sum()\n",
    "        \n",
    "        loss /= out_mask.sum()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def trainS2S(s2s, batch_sampler, hp):\n",
    "    s2s.train()\n",
    "    losses = []\n",
    "#     hp.batch_size = 100\n",
    "#     assert(len(src) == len(trg))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(s2s.parameters(), lr=hp.learning_rate)\n",
    "    \n",
    "    for epoch_id in range(hp.n_epochs):\n",
    "#         batch_sampler.reset()\n",
    "        for batch_id, ((input, input_mask), (output, output_mask)) in tqdm.tqdm(enumerate(batch_sampler)):\n",
    "#         for i in tqdm.tqdm(range(0, len(src), hp.batch_size)):\n",
    "#             src_batch = form_batch_variable(source_lang, src[i : i + hp.batch_size])\n",
    "#             trg_batch = form_batch_variable(target_lang, trg[i : i + hp.batch_size])\n",
    "\n",
    "\n",
    "            loss = s2s(input, input_mask, output, output_mask)\n",
    "#             if (batch_id // hp.batch_size) % 100 == 0:\n",
    "#                 print(loss.data[0])\n",
    "            losses.append(loss.data[0])\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(s2s.parameters(), hp.clip)\n",
    "            optimizer.step()\n",
    "    return losses\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy_dataset = {\n",
    "    \"train\": ( [\"'a 'a d y r\", \"'a 'a h b ckh\"], [\"a a d i r\", \"e a h a v k h a\"]),\n",
    "    \"test\":None,\n",
    "    \"dev\":None\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(dummy_dataset, src, tgt, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "1it [00:00, 11.31it/s]\n",
      "1it [00:00,  9.46it/s]\n",
      "1it [00:00,  9.57it/s]\n",
      "1it [00:00,  9.44it/s]\n",
      "1it [00:00, 10.97it/s]\n",
      "1it [00:00,  9.48it/s]\n",
      "1it [00:00,  8.72it/s]\n",
      "1it [00:00, 10.21it/s]\n",
      "1it [00:00,  9.98it/s]\n",
      "1it [00:00,  9.55it/s]\n",
      "1it [00:00,  9.13it/s]\n",
      "1it [00:00,  9.98it/s]\n",
      "1it [00:00, 10.38it/s]\n",
      "1it [00:00, 10.30it/s]\n",
      "1it [00:00,  9.91it/s]\n",
      "1it [00:00,  9.63it/s]\n",
      "1it [00:00,  9.30it/s]\n",
      "1it [00:00, 10.33it/s]\n",
      "1it [00:00, 10.37it/s]\n",
      "1it [00:00, 10.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.002084732055664,\n",
       " 2.6538538932800293,\n",
       " 2.3275082111358643,\n",
       " 2.0254383087158203,\n",
       " 1.7580164670944214,\n",
       " 1.5345267057418823,\n",
       " 1.3483034372329712,\n",
       " 1.1852436065673828,\n",
       " 1.0418860912322998,\n",
       " 0.919980525970459,\n",
       " 0.8147149085998535,\n",
       " 0.7196149826049805,\n",
       " 0.632966160774231,\n",
       " 0.5549482703208923,\n",
       " 0.48462098836898804,\n",
       " 0.42104572057724,\n",
       " 0.3653680384159088,\n",
       " 0.3198111057281494,\n",
       " 0.2834157645702362,\n",
       " 0.250639945268631]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.batch_size = 100\n",
    "hp.n_epochs = 20\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 128, padding_idx=0)\n",
       "    (gru): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 128, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(384, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_sampler = BatchSampler(d, src, tgt, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "1it [00:00,  4.35it/s]\u001b[A\n",
      "2it [00:00,  4.45it/s]\u001b[A\n",
      "3it [00:00,  4.66it/s]\u001b[A\n",
      "4it [00:00,  5.11it/s]\u001b[A\n",
      "5it [00:00,  5.43it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "hp = HyperParameters()\n",
    "hp.n_epochs = 1\n",
    "s2s = Seq2Seq(src, tgt, hp)\n",
    "losses = trainS2S(s2s, batch_sampler, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2f98414470>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f926a06a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(90, 32, padding_idx=0)\n",
       "    (gru): GRU(32, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(32, 32, padding_idx=0)\n",
       "    (attn): Attn(\n",
       "      (attn): Linear(in_features=512, out_features=1)\n",
       "    )\n",
       "    (gru): GRU(288, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "    (out): Linear(in_features=256, out_features=32)\n",
       "  )\n",
       "  (criterion): NLLLoss(\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itasarom/.programs/anaconda2/envs/torch/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<S> a a d i r </S>', '<S> e a h a v k h a </S>']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2s.translate(*for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     1     6     6    17    88    49     3\n",
       "     1     6     6    24    14    15     3\n",
       " [torch.LongTensor of size 2x7], Variable containing:\n",
       "     1     1     1     1     1     1     1\n",
       "     1     1     1     1     1     1     1\n",
       " [torch.FloatTensor of size 2x7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_translation(*src.convert_batch([\"'a 'a d y r\".split(\" \"), \"'a 'a h b ckh\".split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_translation(x, x_mask):\n",
    "    x = Variable(torch.from_numpy(x.astype(np.int64))).contiguous()\n",
    "    x_mask = Variable(torch.from_numpy(x_mask.astype(np.float32))).contiguous()\n",
    "    \n",
    "    \n",
    "    return x, x_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dummy_dataset[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [torch]",
   "language": "python",
   "name": "Python [torch]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
